{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb6b301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "sheet='C2'\n",
    "df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\n",
    "# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\n",
    "df.dropna(subset=['Date'],inplace=True)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "last_date=df.loc[:,'Date']\n",
    "last_date=last_date.iat[-1]\n",
    "last_date=last_date.strftime('%Y-%m-%d')\n",
    "last_date\n",
    "\n",
    "df=df[df['Date']<=last_date].reset_index(drop=True)\n",
    "df.tail()\n",
    "df['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\n",
    "df['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\n",
    "\n",
    "df.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\n",
    "first_column = df.pop('Year')\n",
    "df.insert(0, 'Year', first_column)\n",
    "second_column = df.pop('Month')\n",
    "df.insert(1, 'Month', second_column)\n",
    "first_column = df.pop('PortQyt')\n",
    "df.insert(0, 'PortQyt', first_column)\n",
    "\n",
    "df.shape\n",
    "print(len(list(df)[:]))\n",
    "# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112a78c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 108)\n",
      "    var1(t-5)  var2(t-5)  var3(t-5)  var4(t-5)  var5(t-5)  var6(t-5)  /\n",
      "37   0.511673   0.666687   0.727273   0.932474   0.717169   0.588889   \n",
      "38   0.591440   0.666687   0.818182   0.938020   0.694739   0.677778   \n",
      "39   0.618677   0.666687   0.909091   0.917436   0.446890   0.744444   \n",
      "40   0.521401   0.666687   1.000000   0.802304   0.492244   0.766667   \n",
      "41   0.680934   1.000000   0.000000   0.930982   0.561927   0.822222   \n",
      "\n",
      "    var7(t-5)  var8(t-5)  var9(t-5)  var10(t-5)  ...   var9(t)  var10(t)  /\n",
      "37   0.012658   0.741105   0.919374    0.107143  ...  0.967284  0.026786   \n",
      "38   0.012658   0.819652   1.000000    0.098214  ...  0.960880  0.008929   \n",
      "39   0.012658   0.828126   0.980065    0.062500  ...  0.947854  0.008929   \n",
      "40   0.012658   0.848302   0.983663    0.035714  ...  0.946481  0.008929   \n",
      "41   0.012658   0.863193   0.966805    0.044643  ...  0.958188  0.008929   \n",
      "\n",
      "    var11(t)  var12(t)  var13(t)  var14(t)  var15(t)  var16(t)  var17(t)  /\n",
      "37  0.975176  0.412419  1.000000  0.918027  0.220363  0.990576  1.000000   \n",
      "38  0.886155  0.228628  0.900844  0.873644  0.178282  0.912010  0.915206   \n",
      "39  0.862346  0.356677  0.921073  0.849528  0.199142  0.865093  0.876255   \n",
      "40  0.888543  0.335313  0.921073  0.832526  0.144730  0.899140  0.876255   \n",
      "41  0.730303  0.408285  0.838706  0.730955  0.270332  0.774483  0.865289   \n",
      "\n",
      "    var18(t)  \n",
      "37  0.960996  \n",
      "38  0.897479  \n",
      "39  0.866671  \n",
      "40  0.887940  \n",
      "41  0.781520  \n",
      "\n",
      "[5 rows x 108 columns]\n",
      "(37, 108)\n",
      "(1, 108)\n",
      "(36, 6, 18) (36, 1) (1, 6, 18) (1, 1)\n",
      "[[0.6712063]] (1, 1)\n",
      ">1, MAE: 0.061\n",
      "[[0.6712063]] (1, 1)\n",
      ">2, MAE: 0.066\n",
      "[[0.6712063]] (1, 1)\n",
      ">3, MAE: 0.036\n",
      "[[0.6712063]] (1, 1)\n",
      ">4, MAE: 0.054\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002DA256D2A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[0.6712063]] (1, 1)\n",
      ">5, MAE: 0.056\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002DA27A5EB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[0.6712063]] (1, 1)\n",
      ">6, MAE: 0.001\n",
      "[[0.6712063]] (1, 1)\n",
      ">7, MAE: 0.003\n",
      "[[0.6712063]] (1, 1)\n",
      ">8, MAE: 0.067\n",
      "[[0.6712063]] (1, 1)\n",
      ">9, MAE: 0.012\n",
      "[[0.6712063]] (1, 1)\n",
      ">10, MAE: 0.000\n",
      "[[0.6712063]] (1, 1)\n",
      ">11, MAE: 0.034\n",
      "[[0.6712063]] (1, 1)\n",
      ">12, MAE: 0.005\n",
      "[[0.6712063]] (1, 1)\n",
      ">13, MAE: 0.033\n",
      "[[0.6712063]] (1, 1)\n",
      ">14, MAE: 0.029\n",
      "[[0.6712063]] (1, 1)\n",
      ">15, MAE: 0.016\n",
      "[[0.6712063]] (1, 1)\n",
      ">16, MAE: 0.000\n",
      "[[0.6712063]] (1, 1)\n",
      ">17, MAE: 0.033\n",
      "[[0.6712063]] (1, 1)\n",
      ">18, MAE: 0.007\n",
      "[[0.6712063]] (1, 1)\n",
      ">19, MAE: 0.021\n",
      "[[0.6712063]] (1, 1)\n",
      ">20, MAE: 0.066\n",
      "[[0.6712063]] (1, 1)\n",
      ">21, MAE: 0.076\n",
      "[[0.6712063]] (1, 1)\n",
      ">22, MAE: 0.022\n",
      "[[0.6712063]] (1, 1)\n",
      ">23, MAE: 0.078\n",
      "[[0.6712063]] (1, 1)\n",
      ">24, MAE: 0.021\n",
      "[[0.6712063]] (1, 1)\n",
      ">25, MAE: 0.013\n",
      "(25, 1)\n",
      "95% prediction interval: [643.3, 653.5]\n",
      "True value: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>95%CI.Min</th>\n",
       "      <th>95%CI.Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648.402222</td>\n",
       "      <td>643.271084</td>\n",
       "      <td>653.533359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction   95%CI.Min   95%CI.Max\n",
       "0  648.402222  643.271084  653.533359"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "values=df.values\n",
    "#\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# # # print(values[:,0]) #PortQyt Value\n",
    "# values[:,0]=encoder.fit_transform(values[:,0])\n",
    "# print(values[:,0])\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # print(values[:,4].shape)\n",
    "# # print(values[:,4])\n",
    "values = values.astype('float32')\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_months = 5\n",
    "n_features = len(list(df)[:])\n",
    "\n",
    "#Normalize the first feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\n",
    "# train_y = scaler2.transform(values[:,-n_features])\n",
    "# scaled2 = scaler2.fit_transform(values) #try\n",
    "\n",
    "\n",
    "# # normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# len(list(dataset.columns))-3\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_months, 1)\n",
    "# print(reframed.shape)\n",
    "\n",
    "\n",
    "# print(reframed.tail())\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_months = 36\n",
    "train = values[:n_train_months, :]\n",
    "test = values[n_train_months:, :]\n",
    "print(values.shape)\n",
    "# split into input and outputs\n",
    "n_obs = ((n_months+1))* n_features #the following fourth month\n",
    "train.shape\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+4):-n_features*(1+4)+1] \n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features*(1+4):-n_features*(1+4)+1]\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(train_y)\n",
    "# pp.show()\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "# prediction interval for mlps on the housing regression dataset\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\n",
    "    return model\n",
    "\n",
    "\t\n",
    " \n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        model = fit_model(X_train, y_train) # define and fit the model on the training set\n",
    "        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\n",
    "        print(y_test.shape,yhat.shape)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        ensemble.append(model) # store the model\n",
    "    return ensemble\n",
    "\n",
    "n_members = 25\n",
    "ensemble = list()\n",
    "for i in range(n_members):\n",
    "  model = fit_model(train_X, train_y) # define and fit the model on the training set\n",
    "  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\n",
    "  print(test_y,yhat.shape)\n",
    "  mae = mean_absolute_error(test_y, yhat)\n",
    "  print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "  ensemble.append(model) # store the model\n",
    "    \n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X,n_members):\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    yhat = np.reshape(yhat,[n_members,1])\n",
    "    print(yhat.shape)\n",
    "    # yhat = scaled2.inverse_transform(yhat)\n",
    "    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\n",
    "    yhat = yhat[:,0] \n",
    "    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper\n",
    "\n",
    "n_members=len(ensemble)\n",
    "# make predictions with prediction interval\n",
    "newX = asarray([test_X[0, :]])\n",
    "lower, mean, upper = predict_with_pi(ensemble, newX,n_members)\n",
    "# print(test_y)\n",
    "# print('Point prediction: %.1f' % mean)\n",
    "print('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\n",
    "print('True value: %.1f' % test_y[0])\n",
    "outcome = {'Prediction': [mean],\n",
    "           '95%CI.Min': [lower],\n",
    "           '95%CI.Max': [upper]\n",
    "           }\n",
    "\n",
    "\n",
    "outcome2= pd.DataFrame(outcome)\n",
    "outcome2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b08cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save ensemble\n",
    "for i,i_model in enumerate(ensemble):\n",
    "  i_model.save(f'ModeC2//2//ensemble_corr_{i}.h5')\n",
    "\n",
    "#save model\n",
    "model.save('ModelC2//2//model_corr.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
