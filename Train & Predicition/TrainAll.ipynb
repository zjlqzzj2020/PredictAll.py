{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Product Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# sheet='C1'\n",
    "# sheet='C2'\n",
    "# sheet='BYX'\n",
    "# sheet='BZX'\n",
    "# sheet='EDGA'\n",
    "# sheet='EDGX_Equities'\n",
    "sheet='EXO_EDGX_Options'\n",
    "# sheet='OPT_BZX_BATS'\n",
    "# sheet='CFE'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(37, 108)\n",
      "(1, 108)\n",
      "(36, 6, 18) (36, 1) (1, 6, 18) (1, 1)\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:00:51.628145: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-07 00:00:51.628295: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-09-07 00:00:52.073044: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-09-07 00:00:53.183065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:00:53.458185: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:00:55.592695: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:00:58.838916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:00:58.931869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">1, MAE: 0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:00.425569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:00.692575: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:00.797763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:02.693918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:02.780923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">2, MAE: 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:04.032562: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:04.299088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:04.391925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:07.951920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:08.215586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">3, MAE: 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:10.513361: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:10.775480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:10.871853: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:12.856805: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:12.944158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">4, MAE: 0.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:14.273200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:14.537723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:14.634892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1638fd160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:16.634930: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:16.723764: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">5, MAE: 0.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:18.201052: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:18.464489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:18.564322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x16acc9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:20.701339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:20.788091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">6, MAE: 0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:22.132117: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:22.402276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:22.503741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:24.510000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:24.600467: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">7, MAE: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:26.111842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:26.377735: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:26.474885: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:28.540027: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:28.628490: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">8, MAE: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:30.143456: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:30.413782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:30.516915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:32.671937: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:32.761953: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">9, MAE: 0.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:34.051111: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:34.324953: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:34.439543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:36.478993: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:36.566441: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">10, MAE: 0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:38.070052: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:38.334746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:38.441277: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:40.420118: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:40.509012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">11, MAE: 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:41.777510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:42.041889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:42.151703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:44.113183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:44.201060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">12, MAE: 0.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:45.471410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:45.734606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:45.842090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:47.815762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:47.903907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">13, MAE: 0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:49.418088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:49.682920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:49.791745: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:51.771516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:51.868380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">14, MAE: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:53.161174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:53.430605: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:53.536261: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:55.527420: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:55.615469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">15, MAE: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:01:56.899381: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:57.162240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:57.298185: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:59.327049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:01:59.414700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">16, MAE: 0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:00.705844: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:00.968872: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:01.107195: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:03.164641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:03.252561: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">17, MAE: 0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:04.836422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:05.101882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:05.220881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:07.287070: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:07.374314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">18, MAE: 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:08.660808: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:08.934584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:09.073547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:11.150355: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:11.238215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">19, MAE: 0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:12.515738: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:12.781256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:12.915564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:15.011064: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:15.098445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.775463]] (1, 1)\n",
      ">20, MAE: 0.026\n",
      "(20, 1)\n",
      "95% prediction interval: [653.5, 660.1]\n",
      "True value: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Prediction   95%CI.Min   95%CI.Max\n0  656.793579  653.470549  660.116609",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Prediction</th>\n      <th>95%CI.Min</th>\n      <th>95%CI.Max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>656.793579</td>\n      <td>653.470549</td>\n      <td>660.116609</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# sheet='C1'\n",
    "# sheet='C2'\n",
    "# sheet='BYX'\n",
    "# sheet='BZX'\n",
    "# sheet='EDGA'\n",
    "# sheet='EDGX_Equities'\n",
    "# sheet='EXO_EDGX Options'\n",
    "# sheet='OPT_BZX BATS'\n",
    "# sheet='CFE'\n",
    "\n",
    "#load ensemble\n",
    "import os\n",
    "from keras.models import load_model\n",
    "\n",
    "df= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\n",
    "# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\n",
    "df.dropna(subset=['Date'],inplace=True)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "last_date=df.loc[:,'Date']\n",
    "last_date=last_date.iat[-1]\n",
    "last_date=last_date.strftime('%Y-%m-%d')\n",
    "last_date\n",
    "\n",
    "df=df[df['Date']<=last_date].reset_index(drop=True)\n",
    "df.tail()\n",
    "df['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\n",
    "df['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\n",
    "\n",
    "df.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\n",
    "first_column = df.pop('Year')\n",
    "df.insert(0, 'Year', first_column)\n",
    "second_column = df.pop('Month')\n",
    "df.insert(1, 'Month', second_column)\n",
    "first_column = df.pop('PortQyt')\n",
    "df.insert(0, 'PortQyt', first_column)\n",
    "\n",
    "df.shape\n",
    "print(len(list(df)[:]))\n",
    "# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\n",
    "\n",
    "values=df.values\n",
    "#\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # encoder = LabelEncoder()\n",
    "# # # # print(values[:,0]) #PortQyt Value\n",
    "# # values[:,0]=encoder.fit_transform(values[:,0])\n",
    "# # print(values[:,0])\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # print(values[:,4].shape)\n",
    "# # print(values[:,4])\n",
    "values = values.astype('float32')\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_months = 5\n",
    "n_features = len(list(df)[:])\n",
    "\n",
    "#Normalize the first feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\n",
    "# train_y = scaler2.transform(values[:,-n_features])\n",
    "# scaled2 = scaler2.fit_transform(values) #try\n",
    "\n",
    "\n",
    "# # normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# len(list(dataset.columns))-3\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_months, 1)\n",
    "# print(reframed.shape)\n",
    "\n",
    "\n",
    "# print(reframed.tail())\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_months = 36\n",
    "train = values[:n_train_months, :]\n",
    "test = values[n_train_months:, :]\n",
    "print(values.shape)\n",
    "# split into input and outputs\n",
    "n_obs = ((n_months+1))* n_features #the following fourth month\n",
    "train.shape\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+5):-n_features*(1+5)+1]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features*(1+5):-n_features*(1+5)+1]\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(train_y)\n",
    "# pp.show()\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# prediction interval for mlps on the housing regression dataset\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        model = fit_model(X_train, y_train) # define and fit the model on the training set\n",
    "        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\n",
    "        print(y_test.shape,yhat.shape)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        ensemble.append(model) # store the model\n",
    "    return ensemble, model\n",
    "\n",
    "n_members = 20\n",
    "ensemble = list()\n",
    "for i in range(n_members):\n",
    "  model = fit_model(train_X, train_y) # define and fit the model on the training set\n",
    "  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\n",
    "  print(test_y,yhat.shape)\n",
    "  mae = mean_absolute_error(test_y, yhat)\n",
    "  print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "  ensemble.append(model) # store the model\n",
    "\n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X,n_members):\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    yhat = np.reshape(yhat,[n_members,1])\n",
    "    print(yhat.shape)\n",
    "    # yhat = scaled2.inverse_transform(yhat)\n",
    "    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\n",
    "    yhat = yhat[:,0]\n",
    "    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper\n",
    "\n",
    "n_members=len(ensemble)\n",
    "# make predictions with prediction interval\n",
    "newX = asarray([test_X[0, :]])\n",
    "lower, mean, upper = predict_with_pi(ensemble, newX,n_members)\n",
    "# print(test_y)\n",
    "# print('Point prediction: %.1f' % mean)\n",
    "print('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\n",
    "print('True value: %.1f' % test_y[0])\n",
    "outcome = {'Prediction': [mean],\n",
    "           '95%CI.Min': [lower],\n",
    "           '95%CI.Max': [upper]\n",
    "           }\n",
    "\n",
    "\n",
    "outcome1= pd.DataFrame(outcome)\n",
    "outcome1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "#save ensemble\n",
    "for i,i_model in enumerate(ensemble):\n",
    "    i_model.save(path.join(sheet, '1',f'ensemble_corr_{i}.h5'))\n",
    "#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\n",
    "\n",
    "\n",
    "\n",
    "#save model\n",
    "# model.save(f'/1/model_corr.h5')\n",
    "model.save(path.join(sheet, '1','model_corr.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(37, 108)\n",
      "(1, 108)\n",
      "(36, 6, 18) (36, 1) (1, 6, 18) (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:17.692098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:17.957146: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:18.091292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:21.814967: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:21.911445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">1, MAE: 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:23.172055: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:23.433594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:23.569315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:25.690345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:25.778473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">2, MAE: 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:27.054417: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:27.317888: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:27.453981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:29.679857: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:29.766653: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">3, MAE: 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:31.039167: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:31.301285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:31.441809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:33.517032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:33.604735: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">4, MAE: 0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:34.901210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:35.167102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:35.304513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:37.404488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:37.493356: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">5, MAE: 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:38.941242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:39.204621: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:39.339219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:41.438663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:41.527482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">6, MAE: 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:42.801790: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:43.067379: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:43.204463: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:45.290002: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:45.380191: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">7, MAE: 0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:46.651816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:46.920328: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:47.054873: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:49.329116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:49.418217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">8, MAE: 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:50.709481: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:50.970001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:51.107391: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:53.221071: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:53.309891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">9, MAE: 0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:54.596927: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:54.862615: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:54.997088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:57.073607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:57.162495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">10, MAE: 0.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:02:58.669593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:58.934791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:02:59.070752: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:01.258791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:01.345785: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">11, MAE: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:02.615190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:02.884101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:03.013008: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:05.140205: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:05.227587: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">12, MAE: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:06.558959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:06.825809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:06.960664: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:09.250166: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:09.340237: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">13, MAE: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:10.674217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:10.948647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:11.138442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:16.768407: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:16.978004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">14, MAE: 0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:19.485086: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:19.746369: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:19.875476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:22.084654: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:22.171464: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">15, MAE: 0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:23.455044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:23.719273: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:23.905669: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:26.096972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:26.185539: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">16, MAE: 0.029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:27.506921: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:27.789964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:28.097345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:30.396400: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:30.484766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">17, MAE: 0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:31.804595: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:32.068573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:32.252817: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:34.508767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:34.597581: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">18, MAE: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:36.238809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:36.503402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:36.688114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:38.938292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:39.032342: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">19, MAE: 0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:40.389086: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:40.660944: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:40.851964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:43.186306: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:43.275400: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8796296]] (1, 1)\n",
      ">20, MAE: 0.038\n",
      "(20, 1)\n",
      "95% prediction interval: [648.3, 655.6]\n",
      "True value: 0.9\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# sheet='BYX'\n",
    "df= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\n",
    "# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\n",
    "df.dropna(subset=['Date'],inplace=True)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "last_date=df.loc[:,'Date']\n",
    "last_date=last_date.iat[-1]\n",
    "last_date=last_date.strftime('%Y-%m-%d')\n",
    "last_date\n",
    "\n",
    "df=df[df['Date']<=last_date].reset_index(drop=True)\n",
    "df.tail()\n",
    "df['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\n",
    "df['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\n",
    "\n",
    "df.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\n",
    "first_column = df.pop('Year')\n",
    "df.insert(0, 'Year', first_column)\n",
    "second_column = df.pop('Month')\n",
    "df.insert(1, 'Month', second_column)\n",
    "first_column = df.pop('PortQyt')\n",
    "df.insert(0, 'PortQyt', first_column)\n",
    "\n",
    "df.shape\n",
    "print(len(list(df)[:]))\n",
    "# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\n",
    "\n",
    "\n",
    "values=df.values\n",
    "#\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# # # print(values[:,0]) #PortQyt Value\n",
    "# values[:,0]=encoder.fit_transform(values[:,0])\n",
    "# print(values[:,0])\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # print(values[:,4].shape)\n",
    "# # print(values[:,4])\n",
    "values = values.astype('float32')\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_months = 5\n",
    "n_features = len(list(df)[:])\n",
    "\n",
    "#Normalize the first feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\n",
    "# train_y = scaler2.transform(values[:,-n_features])\n",
    "# scaled2 = scaler2.fit_transform(values) #try\n",
    "\n",
    "\n",
    "# # normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# len(list(dataset.columns))-3\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_months, 1)\n",
    "# print(reframed.shape)\n",
    "\n",
    "\n",
    "# print(reframed.tail())\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_months = 36\n",
    "train = values[:n_train_months, :]\n",
    "test = values[n_train_months:, :]\n",
    "print(values.shape)\n",
    "# split into input and outputs\n",
    "n_obs = ((n_months+1))* n_features #the following fourth month\n",
    "train.shape\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+4):-n_features*(1+4)+1] \n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features*(1+4):-n_features*(1+4)+1]\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(train_y)\n",
    "# pp.show()\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "# prediction interval for mlps on the housing regression dataset\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\n",
    "    return model\n",
    "\n",
    "\t\n",
    " \n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        model = fit_model(X_train, y_train) # define and fit the model on the training set\n",
    "        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\n",
    "        print(y_test.shape,yhat.shape)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        ensemble.append(model) # store the model\n",
    "    return ensemble\n",
    "\n",
    "n_members = 20\n",
    "ensemble = list()\n",
    "for i in range(n_members):\n",
    "  model = fit_model(train_X, train_y) # define and fit the model on the training set\n",
    "  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\n",
    "  print(test_y,yhat.shape)\n",
    "  mae = mean_absolute_error(test_y, yhat)\n",
    "  print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "  ensemble.append(model) # store the model\n",
    "    \n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X,n_members):\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    yhat = np.reshape(yhat,[n_members,1])\n",
    "    print(yhat.shape)\n",
    "    # yhat = scaled2.inverse_transform(yhat)\n",
    "    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\n",
    "    yhat = yhat[:,0] \n",
    "    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper\n",
    "\n",
    "n_members=len(ensemble)\n",
    "# make predictions with prediction interval\n",
    "newX = asarray([test_X[0, :]])\n",
    "lower, mean, upper = predict_with_pi(ensemble, newX,n_members)\n",
    "# print(test_y)\n",
    "# print('Point prediction: %.1f' % mean)\n",
    "print('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\n",
    "print('True value: %.1f' % test_y[0])\n",
    "outcome = {'Prediction': [mean],\n",
    "           '95%CI.Min': [lower],\n",
    "           '95%CI.Max': [upper]\n",
    "           }\n",
    "\n",
    "\n",
    "outcome2= pd.DataFrame(outcome)\n",
    "outcome2\n",
    "\n",
    "from os import path\n",
    "#save ensemble\n",
    "for i,i_model in enumerate(ensemble):\n",
    "    i_model.save(path.join(sheet, '2',f'ensemble_corr_{i}.h5'))\n",
    "#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\n",
    "\n",
    "\n",
    "\n",
    "#save model\n",
    "# model.save(f'/1/model_corr.h5')\n",
    "model.save(path.join(sheet, '2','model_corr.h5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(37, 108)\n",
      "(1, 108)\n",
      "(36, 6, 18) (36, 1) (1, 6, 18) (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:45.973514: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:46.247409: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:46.462662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:48.876532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:48.967410: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">1, MAE: 0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:50.314142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:50.578258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:50.770891: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:53.201426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:53.290469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">2, MAE: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:03:56.465720: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:56.748464: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:56.939577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:59.380361: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:03:59.469291: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">3, MAE: 0.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:00.797903: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:01.064648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:01.257916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:03.590978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:03.681845: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">4, MAE: 0.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:05.171740: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:05.442797: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:05.635142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:07.958179: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:08.046508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">5, MAE: 0.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:09.363508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:09.629981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:09.821065: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:12.159940: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:12.250397: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">6, MAE: 0.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:13.574113: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:13.842589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:14.033914: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:16.534766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:16.626128: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">7, MAE: 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:17.943546: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:18.208769: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:18.402063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:20.732110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:20.820799: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">8, MAE: 0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:22.129122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:22.395749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:22.587774: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:24.928007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:25.018638: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">9, MAE: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:26.331606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:26.605889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:26.800061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:29.399454: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:29.490058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">10, MAE: 0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:30.824112: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:31.093311: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:31.288092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:33.633285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:33.722969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">11, MAE: 0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:35.057062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:35.324459: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:35.519368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:37.867225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:37.957109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">12, MAE: 0.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:39.294267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:39.568339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:39.758797: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:42.102230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:42.191157: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">13, MAE: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:43.806540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:44.074591: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:44.267088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:46.593911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:46.683806: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">14, MAE: 0.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:48.036396: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:48.306161: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:48.500823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:50.844208: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:50.934203: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">15, MAE: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:52.268992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:52.538892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:52.728693: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:55.039121: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:55.133775: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">16, MAE: 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:04:56.787687: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:57.057498: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:57.246928: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:59.580798: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:04:59.669161: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">17, MAE: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:00.991661: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:01.261945: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:01.452664: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:03.773167: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:03.862858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">18, MAE: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:05.184448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:05.455672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:05.640046: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:07.959694: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:08.052139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">19, MAE: 0.087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:09.384893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:09.669861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:09.856651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:12.162688: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:12.257003: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9305556]] (1, 1)\n",
      ">20, MAE: 0.068\n",
      "(20, 1)\n",
      "95% prediction interval: [670.4, 676.5]\n",
      "True value: 0.9\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# sheet='BYX'\n",
    "df= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\n",
    "# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\n",
    "df.dropna(subset=['Date'],inplace=True)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "last_date=df.loc[:,'Date']\n",
    "last_date=last_date.iat[-1]\n",
    "last_date=last_date.strftime('%Y-%m-%d')\n",
    "last_date\n",
    "\n",
    "df=df[df['Date']<=last_date].reset_index(drop=True)\n",
    "df.tail()\n",
    "df['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\n",
    "df['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\n",
    "\n",
    "df.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\n",
    "first_column = df.pop('Year')\n",
    "df.insert(0, 'Year', first_column)\n",
    "second_column = df.pop('Month')\n",
    "df.insert(1, 'Month', second_column)\n",
    "first_column = df.pop('PortQyt')\n",
    "df.insert(0, 'PortQyt', first_column)\n",
    "\n",
    "df.shape\n",
    "print(len(list(df)[:]))\n",
    "# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\n",
    "\n",
    "\n",
    "values=df.values\n",
    "#\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# # # print(values[:,0]) #PortQyt Value\n",
    "# values[:,0]=encoder.fit_transform(values[:,0])\n",
    "# print(values[:,0])\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # print(values[:,4].shape)\n",
    "# # print(values[:,4])\n",
    "values = values.astype('float32')\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_months = 5\n",
    "n_features = len(list(df)[:])\n",
    "\n",
    "#Normalize the first feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\n",
    "# train_y = scaler2.transform(values[:,-n_features])\n",
    "# scaled2 = scaler2.fit_transform(values) #try\n",
    "\n",
    "\n",
    "# # normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# len(list(dataset.columns))-3\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_months, 1)\n",
    "# print(reframed.shape)\n",
    "\n",
    "\n",
    "# print(reframed.tail())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_months = 36\n",
    "train = values[:n_train_months, :]\n",
    "test = values[n_train_months:, :]\n",
    "print(values.shape)\n",
    "# split into input and outputs\n",
    "n_obs = (n_months+1)* n_features #the following fourth month\n",
    "train.shape\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+3):-n_features*(1+3)+1] \n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features*(1+3):-n_features*(1+3)+1]\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(train_y)\n",
    "# pp.show()\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# prediction interval for mlps on the housing regression dataset\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\n",
    "    return model\n",
    "\n",
    "\t\n",
    " \n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        model = fit_model(X_train, y_train) # define and fit the model on the training set\n",
    "        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\n",
    "        print(y_test.shape,yhat.shape)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        ensemble.append(model) # store the model\n",
    "    return ensemble\n",
    "\n",
    "n_members = 20\n",
    "ensemble = list()\n",
    "for i in range(n_members):\n",
    "  model = fit_model(train_X, train_y) # define and fit the model on the training set\n",
    "  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\n",
    "  print(test_y,yhat.shape)\n",
    "  mae = mean_absolute_error(test_y, yhat)\n",
    "  print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "  ensemble.append(model) # store the model\n",
    "    \n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X,n_members):\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    yhat = np.reshape(yhat,[n_members,1])\n",
    "    print(yhat.shape)\n",
    "    # yhat = scaled2.inverse_transform(yhat)\n",
    "    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\n",
    "    yhat = yhat[:,0] \n",
    "    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper\n",
    "\n",
    "n_members=len(ensemble)\n",
    "# make predictions with prediction interval\n",
    "newX = asarray([test_X[0, :]])\n",
    "lower, mean, upper = predict_with_pi(ensemble, newX,n_members)\n",
    "# print(test_y)\n",
    "# print('Point prediction: %.1f' % mean)\n",
    "print('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\n",
    "print('True value: %.1f' % test_y[0])\n",
    "outcome = {'Prediction': [mean],\n",
    "           '95%CI.Min': [lower],\n",
    "           '95%CI.Max': [upper]\n",
    "           }\n",
    "\n",
    "\n",
    "outcome3= pd.DataFrame(outcome)\n",
    "outcome3\n",
    "\n",
    "from os import path\n",
    "#save ensemble\n",
    "for i,i_model in enumerate(ensemble):\n",
    "    i_model.save(path.join(sheet, '3',f'ensemble_corr_{i}.h5'))\n",
    "#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\n",
    "\n",
    "\n",
    "\n",
    "#save model\n",
    "# model.save(f'/1/model_corr.h5')\n",
    "model.save(path.join(sheet, '3','model_corr.h5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(37, 108)\n",
      "(1, 108)\n",
      "(36, 6, 18) (36, 1) (1, 6, 18) (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:16.713955: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:17.031963: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:17.232750: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:19.713855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:19.801678: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">1, MAE: 0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:21.130293: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:21.399549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:21.611484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:23.956969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:24.044036: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">2, MAE: 0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:25.507069: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:25.776062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:25.972069: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:28.298769: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:28.385532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">3, MAE: 0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:29.691359: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:29.957310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:30.130883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:32.436668: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:32.524799: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">4, MAE: 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:34.003210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:34.278302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:34.462138: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:36.792924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:36.882841: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">5, MAE: 0.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:38.261696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:38.532766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:38.719150: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:41.076721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:41.165451: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">6, MAE: 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:42.490609: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:42.769042: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:42.954909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:45.356532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:45.444698: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">7, MAE: 0.066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:46.940242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:47.204688: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:47.388495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:50.041006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:50.129106: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">8, MAE: 0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:51.529474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:51.801922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:51.986595: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:54.396747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:54.487585: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">9, MAE: 0.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:05:55.907641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:56.185840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:56.375665: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:59.021906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:05:59.112363: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">10, MAE: 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:00.675743: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:00.945097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:01.191495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:03.553987: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:03.641522: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">11, MAE: 0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:04.962863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:05.232137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:05.437584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:07.991641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:08.080248: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">12, MAE: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:09.494356: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:09.761736: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:09.953301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:12.419608: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:12.509588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">13, MAE: 0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:14.227014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:14.503934: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:14.735051: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:17.309932: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:17.400097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">14, MAE: 0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:18.732643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:19.003313: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:19.304353: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:21.845813: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:21.935265: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">15, MAE: 0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:23.388216: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:23.651448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:23.825098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:26.429462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:26.517190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">16, MAE: 0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:27.862271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:28.132245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:28.427015: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:31.080896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:31.179061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">17, MAE: 0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:34.358370: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:34.746023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:35.086079: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:39.751058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:39.900794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">18, MAE: 0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:42.328252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:42.694141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:42.950883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:47.532569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:47.711399: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">19, MAE: 0.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:51.209257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:51.617266: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:51.829777: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:57.005719: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:06:57.093735: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9768518]] (1, 1)\n",
      ">20, MAE: 0.082\n",
      "(20, 1)\n",
      "95% prediction interval: [693.9, 701.6]\n",
      "True value: 1.0\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# sheet='BYX'\n",
    "df= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\n",
    "# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\n",
    "df.dropna(subset=['Date'],inplace=True)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "last_date=df.loc[:,'Date']\n",
    "last_date=last_date.iat[-1]\n",
    "last_date=last_date.strftime('%Y-%m-%d')\n",
    "last_date\n",
    "\n",
    "df=df[df['Date']<=last_date].reset_index(drop=True)\n",
    "df.tail()\n",
    "df['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\n",
    "df['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\n",
    "\n",
    "df.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\n",
    "first_column = df.pop('Year')\n",
    "df.insert(0, 'Year', first_column)\n",
    "second_column = df.pop('Month')\n",
    "df.insert(1, 'Month', second_column)\n",
    "first_column = df.pop('PortQyt')\n",
    "df.insert(0, 'PortQyt', first_column)\n",
    "\n",
    "df.shape\n",
    "print(len(list(df)[:]))\n",
    "# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\n",
    "\n",
    "\n",
    "values=df.values\n",
    "# #\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# # # print(values[:,0]) #PortQyt Value\n",
    "# values[:,0]=encoder.fit_transform(values[:,0])\n",
    "# print(values[:,0])\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # print(values[:,4].shape)\n",
    "# # print(values[:,4])\n",
    "values = values.astype('float32')\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_months = 5\n",
    "n_features = len(list(df)[:])\n",
    "\n",
    "#Normalize the first feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\n",
    "# train_y = scaler2.transform(values[:,-n_features])\n",
    "# scaled2 = scaler2.fit_transform(values) #try\n",
    "\n",
    "\n",
    "# # normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# len(list(dataset.columns))-3\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_months, 1)\n",
    "# print(reframed.shape)\n",
    "\n",
    "\n",
    "# print(reframed.tail())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_months = 36\n",
    "train = values[:n_train_months, :]\n",
    "test = values[n_train_months:, :]\n",
    "print(values.shape)\n",
    "# split into input and outputs\n",
    "n_obs = (n_months+1)* n_features #the following fourth month\n",
    "train.shape\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+2):-n_features*(1+2)+1] \n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features*(1+2):-n_features*(1+2)+1]\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(train_y)\n",
    "# pp.show()\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# prediction interval for mlps on the housing regression dataset\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\n",
    "    return model\n",
    "\n",
    "\t\n",
    " \n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        model = fit_model(X_train, y_train) # define and fit the model on the training set\n",
    "        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\n",
    "        print(y_test.shape,yhat.shape)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        ensemble.append(model) # store the model\n",
    "    return ensemble\n",
    "\n",
    "n_members = 20\n",
    "ensemble = list()\n",
    "for i in range(n_members):\n",
    "  model = fit_model(train_X, train_y) # define and fit the model on the training set\n",
    "  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\n",
    "  print(test_y,yhat.shape)\n",
    "  mae = mean_absolute_error(test_y, yhat)\n",
    "  print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "  ensemble.append(model) # store the model\n",
    "    \n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X,n_members):\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    yhat = np.reshape(yhat,[n_members,1])\n",
    "    print(yhat.shape)\n",
    "    # yhat = scaled2.inverse_transform(yhat)\n",
    "    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\n",
    "    yhat = yhat[:,0] \n",
    "    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper\n",
    "\n",
    "n_members=len(ensemble)\n",
    "# make predictions with prediction interval\n",
    "newX = asarray([test_X[0, :]])\n",
    "lower, mean, upper = predict_with_pi(ensemble, newX,n_members)\n",
    "# print(test_y)\n",
    "# print('Point prediction: %.1f' % mean)\n",
    "print('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\n",
    "print('True value: %.1f' % test_y[0])\n",
    "outcome = {'Prediction': [mean],\n",
    "           '95%CI.Min': [lower],\n",
    "           '95%CI.Max': [upper]\n",
    "           }\n",
    "\n",
    "\n",
    "outcome4= pd.DataFrame(outcome)\n",
    "outcome4\n",
    "\n",
    "from os import path\n",
    "#save ensemble\n",
    "for i,i_model in enumerate(ensemble):\n",
    "    i_model.save(path.join(sheet, '4',f'ensemble_corr_{i}.h5'))\n",
    "#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\n",
    "\n",
    "\n",
    "\n",
    "#save model\n",
    "# model.save(f'/1/model_corr.h5')\n",
    "model.save(path.join(sheet, '4','model_corr.h5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(37, 108)\n",
      "(1, 108)\n",
      "(36, 6, 18) (36, 1) (1, 6, 18) (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:06:59.989270: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:00.272458: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:00.596090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:03.444697: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:03.699547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">1, MAE: 0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:07:11.828877: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:12.379544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:13.053911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:19.170183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:19.347560: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">2, MAE: 0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:07:21.924283: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:22.343038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:22.644225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:27.867750: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:28.024092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">3, MAE: 0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:07:29.908336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:30.169542: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:30.404169: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:35.156700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:35.380271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">4, MAE: 0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:07:37.469820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:37.886742: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:38.247819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:44.148379: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:44.373574: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">5, MAE: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:07:48.330713: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:48.745902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:49.064838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:54.915949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:55.073903: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">6, MAE: 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:07:57.485139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:57.756434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:07:58.081364: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:00.872699: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:00.966262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">7, MAE: 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:02.367338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:02.730013: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:03.204393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:13.949405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:14.117003: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">8, MAE: 0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:16.841919: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:17.112513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:17.413842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:20.219862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:20.310414: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">9, MAE: 0.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:21.691780: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:21.962714: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:22.263981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:25.095909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:25.183639: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">10, MAE: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:26.563643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:26.842459: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:27.188592: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:30.143931: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:30.237109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">11, MAE: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:31.625330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:31.898730: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:32.208963: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:34.915225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:35.002392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">12, MAE: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:36.373231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:36.652038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:36.945653: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:39.634576: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:39.722923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">13, MAE: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:41.110715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:41.384165: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:41.687970: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:44.413518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:44.501145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">14, MAE: 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:46.154316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:46.416338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:46.725535: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:49.545011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:49.632819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">15, MAE: 0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:51.019168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:51.293143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:51.600518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:54.321099: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:54.409074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">16, MAE: 0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:08:55.794771: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:56.065515: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:56.383700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:59.131214: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:08:59.219089: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">17, MAE: 0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:00.627374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:00.893687: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:01.209520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:03.925979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:04.012473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">18, MAE: 0.030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:05.816870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:06.085761: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:06.427485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:09.133200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:09.221487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">19, MAE: 0.019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:10.613182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:10.873876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:11.186843: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:13.921085: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:14.009884: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]] (1, 1)\n",
      ">20, MAE: 0.030\n",
      "(20, 1)\n",
      "95% prediction interval: [714.2, 721.8]\n",
      "True value: 1.0\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# sheet='BYX'\n",
    "df= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\n",
    "# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\n",
    "df.dropna(subset=['Date'],inplace=True)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "last_date=df.loc[:,'Date']\n",
    "last_date=last_date.iat[-1]\n",
    "last_date=last_date.strftime('%Y-%m-%d')\n",
    "last_date\n",
    "\n",
    "df=df[df['Date']<=last_date].reset_index(drop=True)\n",
    "df.tail()\n",
    "df['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\n",
    "df['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\n",
    "\n",
    "df.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\n",
    "first_column = df.pop('Year')\n",
    "df.insert(0, 'Year', first_column)\n",
    "second_column = df.pop('Month')\n",
    "df.insert(1, 'Month', second_column)\n",
    "first_column = df.pop('PortQyt')\n",
    "df.insert(0, 'PortQyt', first_column)\n",
    "\n",
    "df.shape\n",
    "print(len(list(df)[:]))\n",
    "# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\n",
    "\n",
    "\n",
    "values=df.values\n",
    "#\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# # # print(values[:,0]) #PortQyt Value\n",
    "# values[:,0]=encoder.fit_transform(values[:,0])\n",
    "# print(values[:,0])\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # print(values[:,4].shape)\n",
    "# # print(values[:,4])\n",
    "values = values.astype('float32')\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_months = 5\n",
    "n_features = len(list(df)[:])\n",
    "\n",
    "#Normalize the first feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\n",
    "# train_y = scaler2.transform(values[:,-n_features])\n",
    "# scaled2 = scaler2.fit_transform(values) #try\n",
    "\n",
    "\n",
    "# # normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# len(list(dataset.columns))-3\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_months, 1)\n",
    "# print(reframed.shape)\n",
    "\n",
    "\n",
    "# print(reframed.tail())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m=6-5\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_months = 36\n",
    "train = values[:n_train_months, :]\n",
    "test = values[n_train_months:, :]\n",
    "print(values.shape)\n",
    "# split into input and outputs\n",
    "n_obs = (n_months+1)* n_features #the following fourth month\n",
    "train.shape\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(train_y)\n",
    "# pp.show()\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# prediction interval for mlps on the housing regression dataset\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\n",
    "    return model\n",
    "\n",
    "\t\n",
    " \n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        model = fit_model(X_train, y_train) # define and fit the model on the training set\n",
    "        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\n",
    "        print(y_test.shape,yhat.shape)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        ensemble.append(model) # store the model\n",
    "    return ensemble\n",
    "\n",
    "n_members = 20\n",
    "ensemble = list()\n",
    "for i in range(n_members):\n",
    "  model = fit_model(train_X, train_y) # define and fit the model on the training set\n",
    "  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\n",
    "  print(test_y,yhat.shape)\n",
    "  mae = mean_absolute_error(test_y, yhat)\n",
    "  print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "  ensemble.append(model) # store the model\n",
    "    \n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X,n_members):\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    yhat = np.reshape(yhat,[n_members,1])\n",
    "    print(yhat.shape)\n",
    "    # yhat = scaled2.inverse_transform(yhat)\n",
    "    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\n",
    "    yhat = yhat[:,0] \n",
    "    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper\n",
    "\n",
    "n_members=len(ensemble)\n",
    "# make predictions with prediction interval\n",
    "newX = asarray([test_X[0, :]])\n",
    "lower, mean, upper = predict_with_pi(ensemble, newX,n_members)\n",
    "# print(test_y)\n",
    "# print('Point prediction: %.1f' % mean)\n",
    "print('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\n",
    "print('True value: %.1f' % test_y[0])\n",
    "outcome = {'Prediction': [mean],\n",
    "           '95%CI.Min': [lower],\n",
    "           '95%CI.Max': [upper]\n",
    "           }\n",
    "\n",
    "\n",
    "outcome5= pd.DataFrame(outcome)\n",
    "outcome5\n",
    "\n",
    "from os import path\n",
    "#save ensemble\n",
    "for i,i_model in enumerate(ensemble):\n",
    "    i_model.save(path.join(sheet, '5',f'ensemble_corr_{i}.h5'))\n",
    "#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\n",
    "\n",
    "\n",
    "\n",
    "#save model\n",
    "# model.save(f'/1/model_corr.h5')\n",
    "model.save(path.join(sheet, '5','model_corr.h5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(37, 108)\n",
      "(1, 108)\n",
      "(36, 6, 18) (36, 1) (1, 6, 18) (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:16.911862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:17.185792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:17.504462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:20.309613: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:20.398067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">1, MAE: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:21.835274: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:22.098403: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:22.427569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:25.182544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:25.269580: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">2, MAE: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:28.734865: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:29.087662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:29.424615: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:32.560314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:32.681995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">3, MAE: 0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:34.101959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:34.376745: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:34.691954: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:37.433394: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:37.523405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">4, MAE: 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:39.153267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:39.415312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:39.731635: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:42.494181: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:42.583233: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">5, MAE: 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:43.955521: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:44.237154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:44.549380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:47.268911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:47.357432: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">6, MAE: 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:48.935624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:49.199842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:49.515292: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:52.250618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:52.339573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">7, MAE: 0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:53.718230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:53.985604: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:54.299913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:57.041360: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:57.133254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">8, MAE: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:09:58.507942: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:58.785655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:09:59.094534: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:01.833218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:01.921492: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">9, MAE: 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:03.539554: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:03.813897: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:04.136401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:06.881918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:06.970913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">10, MAE: 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:08.361462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:08.649419: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:08.967255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:11.716862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:11.805397: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">11, MAE: 0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:13.198285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:13.476030: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:13.833004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:16.568091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:16.657310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">12, MAE: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:18.049764: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:18.322009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:18.640917: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:21.660315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:21.750573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">13, MAE: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:23.116663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:23.392472: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:23.708291: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:26.419893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:26.507631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">14, MAE: 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:28.345448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:28.651826: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:28.959492: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:31.677239: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:31.766229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">15, MAE: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:33.187956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:33.459354: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:33.767267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:36.563317: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:36.649832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">16, MAE: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:38.375759: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:38.650634: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:38.958985: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:41.705495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:41.797747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">17, MAE: 0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:43.199710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:43.473511: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:43.782857: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:46.520376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:46.609551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">18, MAE: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:47.994366: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:48.271699: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:48.580354: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:51.400004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:51.490062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">19, MAE: 0.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:10:52.893948: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:53.160784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:53.464426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:56.193564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:10:56.290768: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]] (1, 1)\n",
      ">20, MAE: 0.002\n",
      "(20, 1)\n",
      "95% prediction interval: [723.9, 730.2]\n",
      "True value: 1.0\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# sheet='BYX'\n",
    "df= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\n",
    "# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\n",
    "df.dropna(subset=['Date'],inplace=True)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "last_date=df.loc[:,'Date']\n",
    "last_date=last_date.iat[-1]\n",
    "last_date=last_date.strftime('%Y-%m-%d')\n",
    "last_date\n",
    "\n",
    "df=df[df['Date']<=last_date].reset_index(drop=True)\n",
    "df.tail()\n",
    "df['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\n",
    "df['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\n",
    "\n",
    "df.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\n",
    "first_column = df.pop('Year')\n",
    "df.insert(0, 'Year', first_column)\n",
    "second_column = df.pop('Month')\n",
    "df.insert(1, 'Month', second_column)\n",
    "first_column = df.pop('PortQyt')\n",
    "df.insert(0, 'PortQyt', first_column)\n",
    "\n",
    "df.shape\n",
    "print(len(list(df)[:]))\n",
    "# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\n",
    "\n",
    "\n",
    "values=df.values\n",
    "#\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# # # print(values[:,0]) #PortQyt Value\n",
    "# values[:,0]=encoder.fit_transform(values[:,0])\n",
    "# print(values[:,0])\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # print(values[:,4].shape)\n",
    "# # print(values[:,4])\n",
    "values = values.astype('float32')\n",
    "\n",
    "# specify the number of lag hours\n",
    "n_months = 5\n",
    "n_features = len(list(df)[:])\n",
    "\n",
    "#Normalize the first feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\n",
    "# train_y = scaler2.transform(values[:,-n_features])\n",
    "# scaled2 = scaler2.fit_transform(values) #try\n",
    "\n",
    "\n",
    "# # normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# len(list(dataset.columns))-3\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_months, 1)\n",
    "# print(reframed.shape)\n",
    "\n",
    "\n",
    "# print(reframed.tail())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m=6-6\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_months = 36\n",
    "train = values[:n_train_months, :]\n",
    "test = values[n_train_months:, :]\n",
    "print(values.shape)\n",
    "# split into input and outputs\n",
    "n_obs = (n_months+1)* n_features #the following fourth month\n",
    "train.shape\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(train_y)\n",
    "# pp.show()\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# prediction interval for mlps on the housing regression dataset\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\n",
    "    return model\n",
    "\n",
    "\t\n",
    " \n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        model = fit_model(X_train, y_train) # define and fit the model on the training set\n",
    "        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\n",
    "        print(y_test.shape,yhat.shape)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        ensemble.append(model) # store the model\n",
    "    return ensemble\n",
    "\n",
    "n_members = 20\n",
    "ensemble = list()\n",
    "for i in range(n_members):\n",
    "  model = fit_model(train_X, train_y) # define and fit the model on the training set\n",
    "  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\n",
    "  print(test_y,yhat.shape)\n",
    "  mae = mean_absolute_error(test_y, yhat)\n",
    "  print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "  ensemble.append(model) # store the model\n",
    "    \n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X,n_members):\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    yhat = np.reshape(yhat,[n_members,1])\n",
    "    print(yhat.shape)\n",
    "    # yhat = scaled2.inverse_transform(yhat)\n",
    "    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\n",
    "    yhat = yhat[:,0] \n",
    "    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper\n",
    "\n",
    "n_members=len(ensemble)\n",
    "# make predictions with prediction interval\n",
    "newX = asarray([test_X[0, :]])\n",
    "lower, mean, upper = predict_with_pi(ensemble, newX,n_members)\n",
    "# print(test_y)\n",
    "# print('Point prediction: %.1f' % mean)\n",
    "print('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\n",
    "print('True value: %.1f' % test_y[0])\n",
    "outcome = {'Prediction': [mean],\n",
    "           '95%CI.Min': [lower],\n",
    "           '95%CI.Max': [upper]\n",
    "           }\n",
    "\n",
    "\n",
    "outcome6= pd.DataFrame(outcome)\n",
    "outcome6\n",
    "\n",
    "from os import path\n",
    "#save ensemble\n",
    "for i,i_model in enumerate(ensemble):\n",
    "    i_model.save(path.join(sheet, '6',f'ensemble_corr_{i}.h5'))\n",
    "#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\n",
    "\n",
    "\n",
    "\n",
    "#save model\n",
    "# model.save(f'/1/model_corr.h5')\n",
    "model.save(path.join(sheet, '6','model_corr.h5'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 12m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "(19, 432)\n",
      "(2, 432)\n",
      "(17, 12, 18) (17, 1) (2, 12, 18) (2, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:01.670788: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:01.964699: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:02.688312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:06.478762: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:06.577329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">1, MAE: 0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:08.045117: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:08.310233: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:08.632971: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:11.109880: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:11.197269: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">2, MAE: 0.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:12.774884: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:13.046930: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:13.365468: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:15.916770: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:16.008666: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">3, MAE: 0.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:17.448658: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:17.734383: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:18.067067: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:20.497285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:20.585867: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">4, MAE: 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:22.142516: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:22.413387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:22.748794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:25.296722: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:25.392902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">5, MAE: 0.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:27.592101: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:27.881345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:28.272207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:34.105517: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:34.371880: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">6, MAE: 0.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:37.098109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:37.648871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:38.307646: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:42.066411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:42.192568: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">7, MAE: 0.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:44.801066: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:45.261936: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:45.753253: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:48.721393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:48.813599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">8, MAE: 0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:50.983333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:51.381204: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:51.734310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:55.564727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:55.759172: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">9, MAE: 0.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:11:59.259633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:59.601632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:11:59.964434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:06.866916: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:07.105342: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">10, MAE: 0.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:12:08.989354: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:09.372442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:09.727875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:13.418362: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:13.556583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">11, MAE: 0.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:12:16.416646: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:16.881436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:17.377297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:22.752319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:22.881134: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">12, MAE: 0.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:12:26.513301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:27.210557: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:28.197103: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:34.394711: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:34.574104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">13, MAE: 0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:12:39.526171: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:40.222433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:41.755099: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:48.836902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:49.068823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">14, MAE: 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:12:53.149777: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:53.757159: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:12:54.568989: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:02.899936: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:03.109484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">15, MAE: 0.068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:13:06.147423: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:06.672640: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:07.399926: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:14.479577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:14.755465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">16, MAE: 0.052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:13:18.544951: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:18.945047: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:19.547332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:25.997031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:26.177325: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">17, MAE: 0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:13:29.261685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:29.758567: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:30.101573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:36.173982: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:36.281442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">18, MAE: 0.108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:13:39.378564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:39.798191: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:40.206144: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:45.273637: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:45.369811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">19, MAE: 0.072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:13:48.014338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:48.460140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:48.944417: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:55.759445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-07 00:13:55.861254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9976852]\n",
      " [1.       ]] (2, 1)\n",
      ">20, MAE: 0.019\n",
      "(20, 1)\n",
      "95% prediction interval: [739.5, 749.7]\n",
      "True value: 1.0\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# sheet='OPT_BZX BATS'\n",
    "df= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\n",
    "# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\n",
    "df.dropna(subset=['Date'],inplace=True)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "last_date=df.loc[:,'Date']\n",
    "last_date=last_date.iat[-1]\n",
    "last_date=last_date.strftime('%Y-%m-%d')\n",
    "last_date\n",
    "\n",
    "df=df[df['Date']<=last_date].reset_index(drop=True)\n",
    "df.tail()\n",
    "df['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\n",
    "df['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\n",
    "\n",
    "df.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\n",
    "first_column = df.pop('Year')\n",
    "df.insert(0, 'Year', first_column)\n",
    "second_column = df.pop('Month')\n",
    "df.insert(1, 'Month', second_column)\n",
    "first_column = df.pop('PortQyt')\n",
    "df.insert(0, 'PortQyt', first_column)\n",
    "\n",
    "df.shape\n",
    "print(len(list(df)[:]))\n",
    "# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\n",
    "\n",
    "\n",
    "values=df.values\n",
    "#\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # encoder = LabelEncoder()\n",
    "# # # # print(values[:,0]) #PortQyt Value\n",
    "# # values[:,0]=encoder.fit_transform(values[:,0])\n",
    "# # print(values[:,0])\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(values[:,0])\n",
    "# pp.show()\n",
    "\n",
    "# # print(values[:,4].shape)\n",
    "# # print(values[:,4])\n",
    "values = values.astype('float32')\n",
    "\n",
    "# specify the number of lag hours\n",
    "# n_months = 11\n",
    "n_months = 23\n",
    "n_features = len(list(df)[:])\n",
    "\n",
    "#Normalize the first feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\n",
    "# train_y = scaler2.transform(values[:,-n_features])\n",
    "# scaled2 = scaler2.fit_transform(values) #try\n",
    "\n",
    "\n",
    "# # normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "# len(list(dataset.columns))-3\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_months, 1)\n",
    "# print(reframed.shape)\n",
    "\n",
    "\n",
    "# print(reframed.tail())\n",
    "\n",
    "\n",
    "\n",
    "m=6-6\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_months =17\n",
    "train = values[:n_train_months, :]\n",
    "test = values[n_train_months:, :]\n",
    "print(values.shape)\n",
    "# split into input and outputs\n",
    "n_obs = ((n_months+1)//2)* n_features #the following 12\n",
    "# n_obs = (n_months+1)* n_features #the following \n",
    "train.shape\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as pp\n",
    "# pp.plot(train_y)\n",
    "# pp.show()\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], (n_months+1)//2, n_features))\n",
    "# train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], (n_months+1)//2, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# prediction interval for mlps on the housing regression dataset\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "# define and fit the model\n",
    "def fit_model(X_train, y_train):\n",
    "    features = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\n",
    "    return model\n",
    "\n",
    "\t\n",
    " \n",
    "# fit an ensemble of models\n",
    "def fit_ensemble(n_members, X_train, X_test, y_train, y_test):\n",
    "    ensemble = list()\n",
    "    for i in range(n_members):\n",
    "        model = fit_model(X_train, y_train) # define and fit the model on the training set\n",
    "        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\n",
    "        print(y_test.shape,yhat.shape)\n",
    "        mae = mean_absolute_error(y_test, yhat)\n",
    "        print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "        ensemble.append(model) # store the model\n",
    "    return ensemble\n",
    "\n",
    "n_members = 20\n",
    "ensemble = list()\n",
    "for i in range(n_members):\n",
    "  model = fit_model(train_X, train_y) # define and fit the model on the training set\n",
    "  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\n",
    "  print(test_y,yhat.shape)\n",
    "  mae = mean_absolute_error(test_y, yhat)\n",
    "  print('>%d, MAE: %.3f' % (i+1, mae))\n",
    "  ensemble.append(model) # store the model\n",
    "    \n",
    "# make predictions with the ensemble and calculate a prediction interval\n",
    "def predict_with_pi(ensemble, X,n_members):\n",
    "    yhat = [model.predict(X, verbose=0) for model in ensemble]\n",
    "    yhat = asarray(yhat)\n",
    "    yhat = np.reshape(yhat,[n_members,1])\n",
    "    print(yhat.shape)\n",
    "    # yhat = scaled2.inverse_transform(yhat)\n",
    "    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\n",
    "    yhat = yhat[:,0] \n",
    "    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\n",
    "    lower, upper = yhat.mean() - interval, yhat.mean() + interval\n",
    "    return lower, yhat.mean(), upper\n",
    "\n",
    "n_members=len(ensemble)\n",
    "# make predictions with prediction interval\n",
    "newX = asarray([test_X[0, :]])\n",
    "lower, mean, upper = predict_with_pi(ensemble, newX,n_members)\n",
    "# print(test_y)\n",
    "# print('Point prediction: %.1f' % mean)\n",
    "print('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\n",
    "print('True value: %.1f' % test_y[0])\n",
    "outcome = {'Prediction': [mean],\n",
    "           '95%CI.Min': [lower],\n",
    "           '95%CI.Max': [upper]\n",
    "           }\n",
    "\n",
    "\n",
    "outcome12= pd.DataFrame(outcome)\n",
    "outcome12\n",
    "\n",
    "from os import path\n",
    "#save ensemble\n",
    "for i,i_model in enumerate(ensemble):\n",
    "    i_model.save(path.join(sheet, '12',f'ensemble_corr_{i}.h5'))\n",
    "#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\n",
    "\n",
    "\n",
    "\n",
    "#save model\n",
    "# model.save(f'/1/model_corr.h5')\n",
    "model.save(path.join(sheet, '12','model_corr.h5'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediciton Chart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz8AAANVCAYAAABWOkB/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAD5OElEQVR4nOzdd3hU1fr28e+kkgSSkISQ0ELvndB7ERDEhoA06dIRASsWLOABRZCOgHTEhqioIL333ntvoaWQnpn9/jEv+YmAUnYyKffnunKd7D07z3omHHVu9l5rWQzDMBAREREREcngnBzdgIiIiIiISGpQ+BERERERkUxB4UdERERERDIFhR8REREREckUFH5ERERERCRTUPgREREREZFMQeFHREREREQyBYUfERERERHJFBR+REREREQkU1D4ERFxsFmzZmGxWB74tWbNGo4ePYqnpyft2rW75+dv3bpF7ty5qVq1KlarFQDDMFiwYAENGjQge/bsuLu7U7BgQfr27cv58+cfucc1a9b8a4+zZs1KvrZevXrJ552cnMiWLRuFCxemVatW/Pjjj9hstvuOER8fz8SJE6lbty7+/v64urri7+9PvXr1mDp1KlFRUcnXrl27FicnJ95999176pw8eZKsWbPy0ksvPfL7PHz4MJ07dyZfvny4ubkREBBAs2bN+PPPPx+51t8tWLCAsWPH3vc1i8XCsGHDnqi+iIg8HBdHNyAiInYzZ86kePHi95wvWbIk3t7ejBgxgtdff52WLVvSsmXL5Nf79OnDzZs3WblyJc7OzthsNtq1a8d3331H27ZtmTVrFj4+Puzbt4/PP/+cBQsWsGTJEmrWrPnIPY4YMYL69evfc75QoUJ3HRcsWJD58+cDEB0dzenTp1m8eDGtWrWidu3a/Pbbb/j4+CRff+3aNZo2bcqBAwfo1KkTAwYMIDAwkBs3brBq1SrefPNNNmzYwNy5cwGoW7cuAwYMYNSoUTz//PNUqVIFAJvNRqdOnfD09GTy5MmP9N4WLVpEu3btKFiwIO+//z7FihXj6tWrzJw5k2bNmvHGG28watSoR6p5x4IFCzhw4AADBw6857XNmzeTJ0+ex6orIiKPyBAREYeaOXOmARjbt2//1+tsNptRp04dI0eOHMbVq1cNwzCM77//3gCM0aNHJ183YsQIAzD+97//3VPjypUrRkhIiJEzZ07j1q1bD93j6tWrDcD44Ycf/vPaunXrGqVKlbrva998840BGK1bt77rfOPGjQ1XV1dj7dq19/2569evG3Pnzr3rXExMjFG0aFGjePHiRmxsrGEYhjFy5EgDMH766aeHeVvJTpw4YXh6ehqhoaHG7du373m9V69eBmB8++23j1T3jubNmxshISGP9bMiImIehR8REQd72PBjGIZx8uRJw8vLy3jhhReMy5cvG/7+/kbt2rUNq9VqGIZhxMfHG9mzZzdKlChh2Gy2+9ZYsGCBARhffPHFQ/doVvgxDMNo1qyZYbFYjDNnzhiGYRjbtm0zAKNv374P3c8dmzZtMpycnIzXX3/d2L9/v+Hu7m60b9/+kev07dvXAIzNmzff9/Xo6GjD19fXKF26dPK5O39uf/31l9G5c2cje/bshqenp/HMM88YJ0+eTL6ubt26BnDP1x2A8eGHH9413v79+41nn33W8PX1Ndzd3Y1y5coZs2bNuuuaO38mCxYsMN59910jODjYyJYtm9GwYUPjyJEjd127a9cuo3nz5kaOHDkMNzc3Izg42GjWrJlx/vz5R/5diYikZ5rzIyKSRlitVpKSku76ujOH546CBQvy+eef8/PPP1OrVi3i4uKYOXMmTk72f53v3LmTW7du8eyzz2KxWO47TosWLXBycmL58uWP3KPNZrunx6SkpEeq8eyzz2IYBuvXrwdI7uPZZ5995H6qV6/OkCFD+Oqrr3j22Wfx9/dn/Pjxj1xn+fLl5MyZk2rVqt33dU9PTxo3bsyBAwe4cuXKXa9169YNJyen5Hk927Zto169eoSHhwMwadIkatasSVBQEJs3b07+epCjR49So0YNDh48yLhx41i0aBElS5akc+fO933s7t133+Xs2bNMnz6dr7/+muPHj9OiRYvk/+9ER0fz1FNPcfXqVSZOnMjy5csZO3Ys+fLlu2selYhIZqA5PyIiacT9Png7OzvfEy569erFuHHjOHLkCF988cVd823OnTsHQIECBR44TtasWcmRI0fytY+iTZs29z1//vz5h563EhISAsClS5eSf/bv5+8wDOOu8GexWHB2dr6n3kcffcTUqVM5ffo0P/74I9mzZ3+oPv7u3LlzlC9f/l+vufM7PXfuHEFBQcnnQ0NDmTFjRvJxqVKlqFmzJhMnTmTo0KGULFkSX19f3N3dHxiu/m7YsGEkJCSwevVq8ubNC0CzZs0IDw/no48+omfPnnfNlypZsiTz5s1LPnZ2dqZ169Zs376datWqceTIEW7cuMGMGTN47rnnkq9r3br1f/YiIpLR6M6PiEgaMWfOHLZv337X19atW++5bunSpRw5cgQnJydWrFjxWGMZhvHAO0P/ZuTIkff0uH37dnLmzPlIYz+MX375BVdX1+Svv3/g/7uZM2cSERHx2HezHtadvv/5e2vfvv1dxzVq1CAkJITVq1c/1jirVq2iYcOGycHnjs6dOxMTE3PPXaN/3jErW7YsAGfPngWgcOHCZM+enbfeeospU6Zw6NChx+pLRCQjUPgREUkjSpQoQWho6F1flSpVuuua8PBwunfvTuXKlZk6dSpLly69665Dvnz5ADh9+vQDx4mOjub69ev3fLh+GAULFrynx9DQUFxdXR+6xp0P5bly5bqr5zvn76hXr15yuHrmmWfuW+vUqVO88cYbvPDCC7z//vtMnTr1sQJhvnz5/vV3BnDmzBmAe35vf78L9PdzN27ceOQ+AG7cuEFwcPA95+/8vv5Z19/f/65jd3d3AGJjYwHw8fFh7dq1lC9fnnfffZdSpUqRK1cuPvzwQxITEx+rRxGR9ErhR0QkHenfvz83b95k9uzZdO/enWbNmjFo0CAuXLgAQKVKlciePTu//vrrA++w/Prrr9hsNp566qnUbP2u8S0WC3Xq1AFI7uPXX3+96zpfX9/kcPXPD/hgvxPTpUsXPDw8mDJlCkOHDqVcuXJ07979keey3JkTs2XLlvu+HhMTw/LlyylduvQ9Yeefc4DunLtfzw/D39+fy5cv33P+zmOCAQEBj1yzTJkyLFy4kBs3brBnzx7atGnDxx9/zOjRox+rRxGR9ErhR0Qknfjll1+YN28en3zyCSVKlADg66+/xsnJiR49egDg5ubGG2+8weHDh/n888/vqREWFsY777xDzpw56d69e6r2D/ZH1P7880/atm2bfMcnNDSUxo0bM23atORFEB7GV199xbp165g8eTKBgYG4uroya9YsLl26xBtvvPFIfb3++ut4eHjQv39/oqOj73l9yJAh3Lp1i/fee++e1+7sZ3THpk2bOHv2LPXq1Us+5+7unnwn5r80bNiQVatWJYedO+bMmYOnp+dDzRt6EIvFQrly5RgzZgy+vr7s2rXrsWuJiKRHWvBARCSNOHDgwH1XTitUqBAWi4WePXtSo0YNBg0alPxa7ty5GTNmDF26dGHGjBl069aNt956i7179yb/b5s2be7a5DQqKoolS5Y8cA7Nvzl+/Ph9747kyZPnrgUPYmNjk6+LjY3l1KlTLF68mCVLllC3bl2mTJly18/PmzePJk2a0KhRIzp37kyTJk0IDAwkMjKSffv2sWLFCry9vZOvP3bsGO+++y4vv/wyL730UvL5O492ffTRR7z00ks0atTood5XoUKFmDt3Lu3bt6dy5coMGjQoeZPTb775hj///JMhQ4bcd8GHHTt20L17d1q1asX58+cZOnQouXPnpk+fPsnXlClThkWLFjF58mQqVaqEk5MToaGh9+3lww8/ZMmSJdSvX58PPvgAPz8/5s+fz++//86oUaMe+c9tyZIlTJo0ieeff56CBQtiGAaLFi0iPDzcYXf/REQcxnGrbIuIiGH8334xD/qaNm2a0apVK8PT09M4duzYfWs0a9bM8Pb2Ns6dO2cYhn1D1Pnz5xv16tUzfH19DTc3N6NAgQJG7969jbNnzz5yj3f2lHnQ19ChQ5Ov/ee+Nl5eXkbBggWNl156yfjhhx+S9yT6p7i4OGP8+PFGrVq1DF9fX8PFxcXw8/MzateubYwcOdK4ceOGYRiGYbVajerVqxtBQUHJ5/4uISHBKFeunBESEmJERkY+0vs8ePCg0alTJyNPnjyGq6ur4efnZzRt2tT4/fff77n27/v8dOzY0fD19TU8PDyMZs2aGcePH7/r2ps3bxovvfSS4evra1gslofa56dFixaGj4+P4ebmZpQrV86YOXPmXdc8aO+l06dPG0Dy9UeOHDHatm1rFCpUyPDw8DB8fHyMKlWq3LNvkIhIZmAxjIdcdkdERESSzZo1iy5durB9+/YH3sUREZG0RXN+REREREQkU9CcHxGRTMz4x0ai9+Ps7PxYewKlBRn9/YmIyKPRnR8RkUxs9uzZd20ker+vtWvXOrrNx5aS769z584YhqFH3kRE0hHN+RERycRu3Ljxn5t7FitWjGzZsqVSR+bK6O9PREQejcKPiIiIiIhkCnrsTUREREREMoV0ueCBzWbj0qVLZMuWTZNURUREREQyMcMwiIqKIleuXDg5/fu9nXQZfi5dukTevHkd3YaIiIiIiKQR58+fJ0+ePP96TboMP3cmpp4/fx5vb28HdyMiIiIiIo4SGRlJ3rx5H2rxmnQZfu486ubt7a3wIyIiIiIiDzUdRgseiIiIiIhIpqDwIyIiIiIimYLCj4iIiIiIZArpcs7PwzAMg6SkJKxWq6NbkVTi7OyMi4uLlj8XERERkfvKkOEnISGBy5cvExMT4+hWJJV5enoSHByMm5ubo1sRERERkTQmw4Ufm83G6dOncXZ2JleuXLi5uelOQCZgGAYJCQlcu3aN06dPU6RIkf/c5EpEREREMpcMF34SEhKw2WzkzZsXT09PR7cjqcjDwwNXV1fOnj1LQkICWbJkcXRLIiIiIpKGZNi/Gtff+mdO+nMXERERkQfRJ0UREREREckUFH5ERERERCRTUPjJhIYNG0b58uWTjzt37szzzz//RDXNqCEiIiIikpIUftKQzp07Y7FYsFgsuLq6UrBgQYYMGUJ0dHSKjvvVV18xa9ash7r2zJkzWCwW9uzZ89g1REREREQcIcOt9pbeNW3alJkzZ5KYmMj69evp3r070dHRTJ48+a7rEhMTcXV1NWVMHx+fNFFDRERERCQlZYo7P4ZhEJOQ5JAvwzAeqVd3d3eCgoLImzcv7dq1o3379ixevDj5UbVvvvmGggUL4u7ujmEYRERE8OqrrxIYGIi3tzcNGjRg7969d9X83//+R86cOcmWLRvdunUjLi7urtf/+ciazWZj5MiRFC5cGHd3d/Lly8fw4cMBKFCgAAAVKlTAYrFQr169+9aIj49nwIABBAYGkiVLFmrVqsX27duTX1+zZg0Wi4WVK1cSGhqKp6cnNWrU4OjRo4/0+xIREREReViZ4s5PbKKVkh8sc8jYhz5ugqfb4/+aPTw8SExMBODEiRN8//33/PTTTzg7OwPQvHlz/Pz8+OOPP/Dx8WHq1Kk0bNiQY8eO4efnx/fff8+HH37IxIkTqV27NnPnzmXcuHEULFjwgWO+8847TJs2jTFjxlCrVi0uX77MkSNHANi2bRtVqlRhxYoVlCpVCjc3t/vWePPNN/npp5+YPXs2ISEhjBo1iiZNmnDixAn8/PySrxs6dCijR48mR44c9OrVi65du7Jx48bH/n2JiIiIiDxIpgg/6dW2bdtYsGABDRs2BOwbuM6dO5ccOXIAsGrVKvbv309YWBju7u4AfPHFFyxevJgff/yRV199lbFjx9K1a1e6d+8OwKeffsqKFSvuuftzR1RUFF999RUTJkygU6dOABQqVIhatWoBJI/t7+9PUFDQfWvceUxv1qxZPP300wBMmzaN5cuXM2PGDN54443ka4cPH07dunUBePvtt2nevDlxcXHaoFRERERETJcpwo+HqzOHPm7isLEfxZIlS8iaNStJSUkkJiby3HPPMX78eCZNmkRISEhy+ADYuXMnt2/fxt/f/64asbGxnDx5EoDDhw/Tq1evu16vXr06q1evvu/4hw8fJj4+PjlwPY6TJ0+SmJhIzZo1k8+5urpSpUoVDh8+fNe1ZcuWTf4+ODgYgLCwMPLly/fY44uIiIiI3E+mCD8Wi+WJHj1LTfXr12fy5Mm4urqSK1euuxY18PLyuutam81GcHAwa9asuaeOr6/vY43v4eHxWD/3d3fmOVkslnvO//Pc39/fnddsNtsT9yAiIiIi8k+ZYsGD9MTLy4vChQsTEhLyn6u5VaxYkStXruDi4kLhwoXv+goICACgRIkSbNmy5a6f++fx3xUpUgQPDw9Wrlx539fvzPGxWq0PrFG4cGHc3NzYsGFD8rnExER27NhBiRIl/vU9iYiIiIiklPRxO0Tuq1GjRlSvXp3nn3+ekSNHUqxYMS5dusQff/zB888/T2hoKK+99hqdOnUiNDSUWrVqMX/+fA4ePPjABQ+yZMnCW2+9xZtvvombmxs1a9bk2rVrHDx4kG7duhEYGIiHhwdLly4lT548ZMmS5Z5lrr28vOjduzdvvPEGfn5+5MuXj1GjRhETE0O3bt1S41cjIiIiInIPhZ90zGKx8McffzB06FC6du3KtWvXCAoKok6dOuTMmROANm3acPLkSd566y3i4uJo2bIlvXv3ZtmyB69+9/777+Pi4sIHH3zApUuXCA4OTp435OLiwrhx4/j444/54IMPqF279n0fu/vf//6HzWajY8eOREVFERoayrJly8iePXuK/C5ERERERP6LxXjUjWjSgMjISHx8fIiIiMDb2/uu1+Li4jh9+jQFChTQimGZkP78RURERDKXf8sG/6Q5PyIiIiIikiko/IiIiIiISKag8CMiIiIiIpmCwo+IiIiIiGQKCj8iIiIiIpIpKPyIiIiIiEimoPAjIiIiIiKZgsKPiIiIiIhkCgo/IiIiIiLySHaH7WbpmaWObuORuTi6Acnc6tWrR/ny5Rk7dqyjWxERERGRh3Am4gz9V/UnIj4CV4srDUMaOrqlh6Y7P2lMVFQUAwcOJCQkBA8PD2rUqMH27duTX+/cuTMWi+Wur2rVqt1VY9CgQfj5+ZEvXz4WLlx412vff/89LVq0uO/YJ06coEuXLuTJkwd3d3cKFChA27Zt2bFjR/I1FouFxYsXP7D/O/316tXrntf69OmDxWKhc+fOyecWLVrEJ5988m+/EhERERFJI27E3qD3it5ExEdQJqAMNXLXcHRLj0ThJ43p3r07y5cvZ+7cuezfv5/GjRvTqFEjLl68mHxN06ZNuXz5cvLXH3/8kfzab7/9xoIFC/jrr78YOXIkXbp04caNGwCEh4czdOhQJk6ceM+4O3bsoFKlShw7doypU6dy6NAhfv75Z4oXL87gwYMf6T3kzZuXhQsXEhsbm3wuLi6Ob7/9lnz58t11rZ+fH9myZXuk+iIiIiKS+mKTYhmwagAXbl8gT9Y8jG8wHg8XD0e39Ugyx2NvhgGJMY4Z29UTLJaHujQ2NpaffvqJX375hTp16gAwbNgwFi9ezOTJk/n0008BcHd3Jygo6L41Dh8+TL169QgNDSU0NJSBAwdy6tQp/P39efPNN+nTp889AcQwDDp37kyRIkVYv349Tk7/l4nLly/Pa6+99khvuWLFipw6dYpFixbRvn17wH6HJ2/evBQsWPCua//52Fv+/Pl59dVXOXHiBD/88APZs2fnvffe49VXX32kHkRERETEPFablbfXvc2+6/vwcfdhUqNJ+Hv4O7qtR5Y5wk9iDIzI5Zix370Ebl4PdWlSUhJWq5UsWbLcdd7Dw4MNGzYkH69Zs4bAwEB8fX2pW7cuw4cPJzAwEIBy5crx9ddfc+vWLU6dOkVsbCyFCxdmw4YN7Nq1i8mTJ98z7p49ezh48CALFiy4K/jc4evr+whv2K5Lly7MnDkzOfx88803dO3alTVr1vznz44ePZpPPvmEd999lx9//JHevXtTp04dihcv/sh9iIiIiMiT+3zH56w6vwo3JzfG1R9HAZ8Cjm7pseixtzQkW7ZsVK9enU8++YRLly5htVqZN28eW7du5fLlywA8/fTTzJ8/n1WrVjF69Gi2b99OgwYNiI+PB6BJkyZ06NCBypUr07lzZ2bPno2Xlxe9e/dm6tSpTJ48mWLFilGzZk0OHjwIwPHjxwFMDRcdO3Zkw4YNnDlzhrNnz7Jx40Y6dOjwUD/brFkz+vTpQ+HChXnrrbcICAh4qNAkIiIiIuabe2gu8w/PB2BE7RFUzFnRwR09vsxx58fV034HxlFjP4K5c+fStWtXcufOjbOzMxUrVqRdu3bs2rULgDZt2iRfW7p0aUJDQwkJCeH333/nxRdfBOyPyg0bNiz5umHDhtGoUSNcXV359NNP2b9/P0uWLOGVV15h586dGIYB2BczMEtAQADNmzdn9uzZGIZB8+bNCQgIeKifLVu2bPL3FouFoKAgwsLCTOtNRERERB7O8rPL+Xz75wAMrjSYJvmbOLijJ5M5wo/F8tCPnjlaoUKFWLt2LdHR0URGRhIcHEybNm0oUOD+txaDg4MJCQlJvnvzT0eOHGH+/Pns3r2bb775hjp16pAjRw5at25N165diYyMpGjRooB9vlD58uVNey9du3alX79+APddZOFBXF1d7zq2WCzYbDbT+hIRERGR/7YnbA/vrH8HA4M2xdrQqVQnR7f0xPTYWxrl5eVFcHAwt27dYtmyZTz33HP3ve7GjRucP3+e4ODge14zDINXX32V0aNHkzVrVqxWK4mJiQDJ/2uz2ShfvjwlS5Zk9OjR9w0Z4eHhj/UemjZtSkJCAgkJCTRpkr7/lkBEREQkMzkbeZb+q/oTb42nXp56vF3lbVOfEnIUhZ80ZtmyZSxdupTTp0+zfPly6tevT7FixejSpQu3b99myJAhbN68mTNnzrBmzRpatGhBQEAAL7zwwj21pk2bRmBgIM8++ywANWvWZNWqVWzZsoUxY8ZQsmRJfH19sVgszJw5k2PHjlGnTh3++OMPTp06xb59+xg+fPgDgxdAw4YNmTBhwn1fc3Z25vDhwxw+fBhnZ2dzfkEiIiIikqJuxd2iz4o+hMeHU8q/FCPrjMTFKWM8MJYx3kUGEhERwTvvvMOFCxfw8/OjZcuWDB8+HFdXV5KSkti/fz9z5swhPDyc4OBg6tevz3fffXfPXjlXr15lxIgRbNq0KflclSpVGDx4MM2bNycwMJDZs2ff9dqOHTsYPnw4PXr04Pr16wQHB1OjRo3kZajv5+TJk1y/fv2Br3t7ez/+L0NEREREUlVcUhz9V/XnXNQ5cmfNzYSGE/B8xDnsaZnFuDPbPR2JjIzEx8eHiIiIez5cx8XFcfr0aQoUKHDPktGS8enPX0REROTx2AwbQ9YOYfnZ5Xi7eTP36bkU9C343z/oYP+WDf5Jj72JiIiIiAijd4xm+dnluDq58lX9r9JF8HlUCj8iIiIiIpnc/MPzmXNoDgCf1vyU0KBQB3eUMhR+REREREQysVXnVjFy20gAXqv4Gs0KNnNwRylH4UdEREREJJPad20fb617CwODVkVb0a10N0e3lKIUfkREREREMqHzkefpv6o/cdY4aueuzbtV380Qe/n8G4UfEREREZFMJjwunD4r+3Az7iYl/ErwRd0vMsxePv9G4UdEREREJBOJt8YzYPUAzkSeIdgrmIkNJ2aovXz+jcKPiIiIiEgmYTNsDN0wlN1hu8nmmo1JDSeRwzOHo9tKNQo/IiIiIiKZxNidY1l2ZhkuTi6MrT+WwtkLO7qlVKXwIyIiIiKSCSw8spCZB2cC8HGNj6kSXMXBHaU+hZ80JioqioEDBxISEoKHhwc1atRg+/btya937twZi8Vy11e1atXuqjFo0CD8/PzIly8fCxcuvOu177//nhYtWtx37BMnTtClSxfy5MmDu7s7BQoUoG3btuzYsSP5GovFwuLFix/Y/53+evXqdc9rffr0wWKx0Llz54f4TYiIiIiIWdacX8Nn2z4DoH+F/rQodP/Pgxmdwk8a0717d5YvX87cuXPZv38/jRs3plGjRly8eDH5mqZNm3L58uXkrz/++CP5td9++40FCxbw119/MXLkSLp06cKNGzcACA8PZ+jQoUycOPGecXfs2EGlSpU4duwYU6dO5dChQ/z8888UL16cwYMHP9J7yJs3LwsXLiQ2Njb5XFxcHN9++y358uV71F+JiIiIiDyBg9cP8ua6N7EZNloWaUmPMj0c3ZLDZIrwYxgGMYkxDvkyDOOh+4yNjeWnn35i1KhR1KlTh8KFCzNs2DAKFCjA5MmTk69zd3cnKCgo+cvPzy/5tcOHD1OvXj1CQ0Np27Yt3t7enDp1CoA333yTPn363BNADMOgc+fOFClShPXr19O8eXMKFSpE+fLl+fDDD/nll18e6fddsWJF8uXLx6JFi5LPLVq0iLx581KhQoW7rl26dCm1atXC19cXf39/nnnmGU6ePJn8+pw5c8iaNSvHjx9PPte/f3+KFi1KdHT0I/UlIiIiktlciLpAn5V9iE2KpWaumgytNjTD7+XzbzL+Yt5AbFIsVRdUdcjYW9ttfeilA5OSkrBarWTJkuWu8x4eHmzYsCH5eM2aNQQGBuLr60vdunUZPnw4gYGBAJQrV46vv/6aW7ducerUKWJjYylcuDAbNmxg165dd4WoO/bs2cPBgwdZsGABTk735mFfX99HeMd2Xbp0YebMmbRv3x6Ab775hq5du7JmzZq7rouOjmbQoEGUKVOG6OhoPvjgA1544QX27NmDk5MTr7zyCkuWLKF9+/Zs2rSJFStWMHXqVDZu3IiXl9cj9yUiIiKSWUTERyTv5VPcrzij643G1cnV0W05VKa485NeZMuWjerVq/PJJ59w6dIlrFYr8+bNY+vWrVy+fBmAp59+mvnz57Nq1SpGjx7N9u3badCgAfHx8QA0adKEDh06ULlyZTp37szs2bPx8vKid+/eTJ06lcmTJ1OsWDFq1qzJwYMHAZLvqhQvXty099KxY0c2bNjAmTNnOHv2LBs3bqRDhw73XNeyZUtefPFFihQpQvny5ZkxYwb79+/n0KFDyddMnTqVy5cvM2DAADp37syHH35I5cqVTetVREREJKNJsCbw2urXOB1xmpyeOZnYcCJervqL40xx58fDxYOt7bY6bOxHMXfuXLp27Uru3LlxdnamYsWKtGvXjl27dgHQpk2b5GtLly5NaGgoISEh/P7777z44osADBs2jGHDhiVfN2zYMBo1aoSrqyuffvop+/fvZ8mSJbzyyivs3Lkz+dE8M2+BBgQE0Lx5c2bPno1hGDRv3pyAgIB7rjt58iTvv/8+W7Zs4fr169hsNgDOnTtH6dKlAciePTszZsygSZMm1KhRg7ffftu0PkVEREQyGpth470N77Hz6k6yumZlUqNJBHoGOrqtNCFThB+LxZJudq0tVKgQa9euJTo6msjISIKDg2nTpg0FChS47/XBwcGEhITcNSfm744cOcL8+fPZvXs333zzDXXq1CFHjhy0bt2arl27EhkZSdGiRQH7fKHy5cub9l66du1Kv379AO67yAJAixYtyJs3L9OmTSNXrlzYbDZKly5NQkLCXdetW7cOZ2dnLl26RHR0NN7e3qb1KSIiIpKRjNs1jj/P/ImLxYUx9cdQNHtRR7eUZuixtzTKy8uL4OBgbt26xbJly3juuefue92NGzc4f/48wcHB97xmGAavvvoqo0ePJmvWrFitVhITEwGS/9dms1G+fHlKlizJ6NGjk++8/F14ePhjvYemTZuSkJBAQkICTZo0uW/vhw8f5r333qNhw4aUKFGCW7du3XPdpk2bGDVqFL/99hve3t7079//sfoRERERyei+P/o9Mw7MAGBYjWFUC672Hz+RuSj8pDHLli1j6dKlnD59muXLl1O/fn2KFStGly5duH37NkOGDGHz5s2cOXOGNWvW0KJFCwICAnjhhRfuqTVt2jQCAwN59tlnAahZsyarVq1iy5YtjBkzhpIlS+Lr64vFYmHmzJkcO3aMOnXq8Mcff3Dq1Cn27dvH8OHDHxi8ABo2bMiECRPu+5qzszOHDx/m8OHDODs73/N69uzZ8ff35+uvv+bEiROsWrWKQYMG3XVNVFQUHTt2pH///jz99NMsWLCA77//nh9++OFRfq0iIiIiGd66C+sYvnU4AH3K9eG5wg/+DJdZZYrH3tKTiIgI3nnnHS5cuICfnx8tW7Zk+PDhuLq6kpSUxP79+5kzZw7h4eEEBwdTv359vvvuO7Jly3ZXnatXrzJixAg2bdqUfK5KlSoMHjyY5s2bExgYyOzZs+96bceOHQwfPpwePXpw/fp1goODqVGjBmPHjn1gvydPnuT69esPfP3fHk9zcnJi4cKFDBgwgNKlS1OsWDHGjRtHvXr1kq957bXX8PLyYsSIEQCUKlWKkSNH0qtXL2rUqEHu3LkfWF9EREQkszh04xBD1g7BZth4rtBz9Cp374bzAhbjUTaiSSMiIyPx8fEhIiLing/XcXFxnD59mgIFCtyzZLRkfPrzFxERkczm0u1LtP+jPddjr1M9uDoTG03MVEta/1s2+Cc99iYiIiIikk5FJkTSZ0Ufrsdep0j2InxZ78tMFXwelcKPiIiIiEg6lGBNYODqgZyMOEmgZyCTGk4iq1vWVBn7+NUoVh6+mipjmUnhR0REREQknTEMgw83fcj2K9vxcvViUsNJBHkFpcrYp69H0276VnrO3cmao2GpMqZZFH5ERERERNKZCXsmsOTUEpwtznxZ90uK+RVLlXHP34yh3bQtXIuKp3BgVsrl8U2Vcc2SYcNPOlzHQUygP3cRERHJ6H469hNf7/sagA+rf0iN3DVSZdxL4bG0nbaFyxFxFA7MyrzuVcnu5ZYqY5slw4UfV1f7BK+YmBgHdyKOcOfP/c7/D0REREQyko0XN/LJlk8A6Fm2Jy8UuXevx5QQFhlHu2lbuHArlvz+nszvXpWArO6pMraZMtw+P87Ozvj6+hIWZn/+0NPTE4vF4uCuJKUZhkFMTAxhYWH4+vred1NVERERkfTsyM0jDFozCKthpUXBFvQt3zdVxr1+O55207dy5kYMebJ7sKBHNXJ6p88tRTJc+AEICrJP9roTgCTz8PX1Tf7zFxEREckorkRfoe+KvsQkxVA1qCof1fgoVf6CPzwmgQ7Tt3Ii7DbBPln4tkc1cvl6pPi4KSVDhh+LxUJwcDCBgYEkJiY6uh1JJa6urrrjIyIiIhlOVEIUvVf0Jiw2jMK+hfmy/pe4Oqf8I/6RcYl0nLGNI1eiyJHNnfndq5LXzzPFx01JGTL83OHs7KwPwyIiIiKSbiVaE3l9zeucCD9BDo8cTGo4CW837xQf93Z8Ep2/2cb+ixH4ebmxoHtVCuZInT2EUlKGW/BARERERCQjMAyDYZuHsfXyVjxcPJjYcCLBWYNTfNzYBCtdZ21n17lwfDxcmdetKkVyZkvxcVODwo+IiIiISBo0ee9kfj35K84WZ0bXHU0J/xIpPmZcopUec3aw7fRNsrm7MLdbFUrmSvk7TalF4UdEREREJI1ZfGIxk/dOBuC9au9RO0/tFB8zIclG73k72XDiOp5uzszqWoWy6WwT0/+i8CMiIiIikoZsurSJjzZ9BECPMj14qehLKT5motVG/293sfroNbK4OvFN58pUCsme4uOmNoUfEREREZE04ujNowxaM4gkI4lmBZrRv0L/FB/TajN4/bs9LDt4FTcXJ6a9Ekq1gv4pPq4jKPyIiIiIiKQBV6Kv0GdlH6ITownNGconNT9J8b18bDaDN37cy5J9l3F1tjC5fUVqF8mRomM6ksKPiIiIiIiD3U64Td+VfQmLCaOgT0HG1h+Lm7Nbio5pGAZDF+9n0a6LODtZGN+2Ag1L5EzRMR1N4UdERERExIESbYkMXjuYY7eO4Z/Fn0mNJuHj7pOiYxqGwUe/HeLbbedxssCYNuVpWjrll9F2NIUfEREREREHMQyDTzZ/wqZLm+x7+TSaSO6suVN8zM/+PMKsTWcAGPVSOZ4tlytFx0wrFH5ERERERBxk6r6p/HziZ5wsTnxe53NK+ZdK8THHLD/G1+tOATDihTK8VClPio+ZVij8iIiIiIg4wK8nf2XinokADK06lLp566b4mBNXn2DcqhMAfNiiJO2q5kvxMdMShR8RERERkVS29fJWPtz4IQBdSnehdbHWKT7m9PWn+HzZUQDeebo4XWoWSPEx0xqFHxERERGRVHT81nFeX/06SUYSTfM3ZWDFgSk+5pzNZ/j098MADHqqKD3rFkrxMdMihR8RERERkVQSFhNGn5V9iEqMomJgRT6t9SlOlpT9SP7d9nN88MtBAPrWL0T/BoVTdLy0TOFHRERERCQVRCdG029lP65EXyG/d37GNRiHu7N7io758+4LvL1oPwDdaxVgSONiKb5xalqm8CMiIiIiksKSbEkMXjuYwzcP45fFL1X28vl932UGf78Xw4CO1UIY2rxEpg4+oPAjIiIiIpKiDMPg0y2fsvHiRrI4Z2Fiw4nkzZY3Rcf86+AVXlu4G5sBrUPz8NGzpTJ98AGFHxERERGRFDXjwAx+Ov4TThYnRtUZRemA0ik63uqjYfRdsIskm8Hz5XPx2YtlcXJS8AGFHxERERGRFPP7qd/5atdXALxV+S3q56ufouNtPHGdXnN3kmg1aFYmiC9alcNZwSeZwo+IiIiISArYfmU77298H4BOJTvRrkS7FB1v2+mbdJ+9g/gkG41K5OSrlyvg4qyP+3+n34aIiIiIiMlOhp/ktdWvkWhL5KmQpxgUOihFx9t97hZdZm4jNtFK3aI5mNi+Aq4KPvd4pN9I/vz5sVgs93z17dv3nmt79uyJxWJh7Nixd52Pj4+nf//+BAQE4OXlxbPPPsuFCxee6E2IiIiIiKQV12Ov02dFH6ISoiifozwjao1I0b18DlyM4JVvthGdYKV6QX+mdqyEu4tzio2Xnj3Sn8L27du5fPly8tfy5csBaNWq1V3XLV68mK1bt5IrV657agwcOJCff/6ZhQsXsmHDBm7fvs0zzzyD1Wp9grchIiIiIuJ4MYkx9FnRh0vRlwjxDmFcg3FkccmSYuMduRJJxxlbiYpLonL+7MzoHEoWVwWfB3mk8JMjRw6CgoKSv5YsWUKhQoWoW7du8jUXL16kX79+zJ8/H1dX17t+PiIighkzZjB69GgaNWpEhQoVmDdvHvv372fFihXmvCMREREREQdIsiXxxro3OHzzMNndszO54WSyZ8meYuOdCLtNh+lbuRWTSLm8vnzTuTKebi4pNl5G8Nj33xISEpg3bx5du3ZNXjPcZrPRsWNH3njjDUqVKnXPz+zcuZPExEQaN26cfC5XrlyULl2aTZs2PXCs+Ph4IiMj7/oSEREREUkrDMPgf9v+x7oL63B3dmd8w/Hk9U65vXzOXI+m3bQtXL+dQKlc3szpUoVsWVz/+wczuccOP4sXLyY8PJzOnTsnnxs5ciQuLi4MGDDgvj9z5coV3NzcyJ797gScM2dOrly58sCxPvvsM3x8fJK/8uZN2U2hREREREQexcyDM/nu6HdYsDCy9kjK5SiXYmNduBVD++lbCYuKp1jObMztVhUfTwWfh/HY4WfGjBk8/fTTyfN6du7cyVdffcWsWbMeefdYwzD+9WfeeecdIiIikr/Onz//uG2LiIiIiJhq6emljNk5BoA3K79Jw5CGKTbW5YhY2k3bysXwWArm8GJe96r4ebml2HgPFHkJTq1N/XGf0GOFn7Nnz7JixQq6d++efG79+vWEhYWRL18+XFxccHFx4ezZswwePJj8+fMDEBQUREJCArdu3bqrXlhYGDlz5nzgeO7u7nh7e9/1JSIiIiLiaDuv7uTdDe8C0KFEBzqU7JBiY4VFxdF+2lbO3Ywhn58nC7pXI0c29xQb74FunIQZTWBBazi3JfXHfwKPFX5mzpxJYGAgzZs3Tz7XsWNH9u3bx549e5K/cuXKxRtvvMGyZcsAqFSpEq6ursmrxAFcvnyZAwcOUKNGjSd8KyIiIiIiqedUxCkGrBpAoi2RhvkaMiR0SIqNdeN2PO2nbeXU9Why+3qwoEdVgnxSbhW5B7q8F2Y0hohz4J0LsgWnfg9P4JGXg7DZbMycOZNOnTrh4vJ/P+7v74+/v/9d17q6uhIUFESxYsUA8PHxoVu3bgwePBh/f3/8/PwYMmQIZcqUoVGjRk/4VkREREREUsedvXwiEyIpm6Msn9X+DGenlFliOjwmgY4ztnE87DY5vd1Z0KMqebJ7pshY/+r0evi2LSREQVBZ6PATZA1M/T6ewCOHnxUrVnDu3Dm6du36WAOOGTMGFxcXWrduTWxsLA0bNmTWrFk4O2s9chERERFJ+2ISY+i/sj8Xb18kb7a8jG8wHg8XjxQZKzIukU7fbOPQ5UgCsrqzoEc1Qvy9UmSsf3Xkd/ihC1jjIaQWtF0AWXxSv48nZDEMw3B0E48qMjISHx8fIiIiNP9HRERERFKN1WZl4JqBrDm/Bl93X+Y+PZf8PvlTZKzo+CRe+WYbO8/eIrunKwtfrU6xoGwpMta/2j0Pfu0Phg2KPwMtZ4CrAx65e4BHyQaPvdqbiIiIiEhmcmcvnzXn1+Dm5Mb4BuNTLPjEJljpNns7O8/ewjuLC3O7VXVM8Nn4FfzS1x58yneAVrPTVPB5VNoCVkRERETkIcw5NIeFRxdiwcJntT+jfGD5FBknLtHKq3N3sOXUTbK6uzCnW1VK507lR8wMA1Z8aA8/ADUGwFMfwyNuaZPWKPyIiIiIiPyHZWeW8cWOLwAYHDqYxvkbp8g4CUk2+i3Yxfrj1/F0c2ZWl8qUz+ubImM9kDUJlgyE3XPtx40+gloDU7eHFKLwIyIiIiLyL3aH7ebd9fa9fNoWb8srJV9JkXGSrDZeW7ibFYfDcHdxYnqnUELz+6XIWA+UGAc/dYMjS8DiBC2+goop834dQeFHREREROQBzkScYcCqASTYEqiXtx5vVX4LSwo8+mW1GQz+YS9/HriCm7MTUztWokahANPH+VdxkbCwHZxZD87u8NIMKNEidXtIYQo/IiIiIiL3cTPuJr1X9CY8PpzS/qUZVWdUiuzlY7MZvP3TPn7ZcwkXJwsT21ekXrFU3j/n9jWY39K+ialbNvtS1gXqpG4PqUDhR0RERETkH2KTYum/sj8Xbl8gd9bcjG+YMnv5GIbB+78c4IedF3CywLi2FXiqZE7Tx/lX4edgzvNw8yR4Btg3L81VPnV7SCUKPyIiIiIif2O1WXln/Tvsu74PbzdvJjeaTICH+Y+gGYbBx0sOMX/rOSwW+LJ1eZqVCTZ9nH8VdhjmvghRl8AnL3RcDAGFU7eHVKTwIyIiIiLyN1/s+IKV51bi6uTKuAbjKOBTwPQxDMNg5NKjzNx4BoCRL5bl+Qq5TR/nX53fDvNfgrhwyFEcOiwCn1TuIZUp/IiIiIiI/H9zD81l3uF5AIyoNYJKOSulyDhfrTzOlLUnAfjk+dK0rpw3RcZ5oBMr4LuOkBgDeSpDu+/BM5VXlnMAhR8REREREWDF2RV8vv1zAF6v9DpNCzRNkXEmrznJ2BXHAXiveQk6VgtJkXEeaP+P8HMvsCVCoYbQZi64eaVuDw7i5OgGREREREQcbe+1vby9/m0MDNoUa0OXUl1SZJxvNpxm5NIjALzZtBjdaxdMkXEeaNs0+Km7PfiUehHaLsw0wQd050dEREREMrlzkefov7I/8dZ46uSpw9tV3k6RvXzmbTnLx0sOAfBawyL0qZeKCwsYBqwdBWtG2I8rd4enR0EKLN2dlin8iIiIiEimdSvuFr1X9OZW/C1K+pfk8zqf4+Jk/kfk73ec573FBwDoWbcgAxsVMX2MB7LZYOnbsG2q/bjuW1DvHUiBgJfWKfyIiIiISKYUlxTHgFUDOBd1jlxeuZjYcCKerp6mj/PLnou89dM+ADrXyM/bTYunyJ2l+7ImwuLesP8H+/HTo6Bqz9QZOw1S+BERERGRTMdm2Hh3w7vsubaHbG7ZmNRoUors5fPn/ssM+n4vhgHtqubjwxYlUy/4JETD953gxHJwcoHnp0DZVqkzdhql8CMiIiIimc6XO75k+dnluDq58lX9ryjkW8j0MVYcukr/b3djtRm8VCkPnz5XOvWCT8xNWNAGLmwDFw/7im5FnkqdsdMwhR8RERERyVQWHF7A7EOzAfik5idUDqps+hjrjl2jz/xdJNkMWpTLxciWZXFySqXgE3kZ5r0IYYcgiw+0+wHyVU2dsdM4hR8RERERyTRWnVvFyO0jAXit4ms0L9jc9DE2n7xBjzk7SLDaaFoqiC9bl8M5tYLPjZMw93kIPwdZg6DjIshZKnXGTgcUfkREREQkU9h/bT9vrXsLm2GjZZGWdCvdzfQxdpy5SbfZ24lPstGgeCDj2lbA1TmVtta8vBfmtYToa5C9ALyyGLLnT52x0wmFHxERERHJ8M5Hnaffqn7EWeOombsm71V7z/T5N3vOh9N55nZiEqzULhLApPYVcXNJpeBzZgN82xbiIyGoDHRYBFkDU2fsdEThR0REREQytPC4cPqs6MPNuJuU8CvB6LqjTd/L5+ClCF6ZsZXb8UlULeDH1x1DyeKaShuIHvkDfugM1ngIqQltv7XP9ZF7pFIUFRERERFJffHWeF5b/RpnIs8Q5BXEhIYT8HL1MnWMY1ej6DhjG5FxSVQKyc43nSvj4ZZKwWf3fPiugz34FGsGHX5S8PkXCj8iIiIikiHZDBvvbXiPXWG7yOaajckNJxPoae6jYKeu3abdtK3cjE6gbB4fZnapjJd7Kj1ctWk8/NIHDCuUawet54KrR+qMnU7psTcRERERyZDG7hrL0jNLcXFyYUz9MRTOXtjU+uduxNBu2lau346nRLA3c7pWwTuLq6lj3JdhwMqPYMMY+3H1fvDUJ+Ck+xr/ReFHRERERDKc7458x8wDMwH4uMbHVA02d5+bi+GxtJ22hSuRcRQJzMq8blXw9XQzdYz7sllhyUDYNcd+3GgY1BwIqbV5ajqn8CMiIiIiGcra82sZsW0EAH3L96VFoRam1r8aGUe7aVu4GB5LgQAv5nevin9Wd1PHuK/EOFjUHQ7/BhYneGYsVOqU8uNmIAo/IiIiIpJhHLx+kDfWvYHNsPFC4RfoWbanqfWvRcXTbtoWzt6IIa+fBwt6VCXQO4upY9xXXCQsbAdn1oOzG7ScASWfTflxMxiFHxERERHJEC7evkjflX2JTYqlRq4avF/9fVP38rkZnUCH6Vs5eS2aXD5ZWNC9GsE+qbDAQPR1++all/eAW1Z4eQEUrJvy42ZACj8iIiIiku5FxEfQZ0UfbsTdoGj2ooyuOxpXJ/MWH4iITaTjjK0cvRpFYDZ35veoRl4/T9PqP1D4eZj7PNw4AZ7+0P5HyF0x5cfNoBR+RERERCRdS7AmMHD1QE5FnCKnZ04mNZxEVresptWPikuk0zfbOHgpEn8vNxb0qEqBAHP3CrqvsCMw9wWIugTeeeCVxRBQJOXHzcAUfkREREQk3bIZNt7b+B47ru7Ay9WLiQ0nktMrp2n1YxKS6DprO3vOh+Pr6cq87lUpHJjNtPoPdGEHzH8JYm9BQDHo+DP45E75cTM4hR8RERERSbfG7x7Pn6f/xMXiwpf1vqSYXzHTasclWuk+ewfbz9wiWxYX5natSolgb9PqP9CJlfBdR0iMhtyh0P4H8PRL+XEzAYUfEREREUmXfjj2A9P3TwfgwxofUiNXDdNqxydZ6Tl3J5tO3sDLzZnZXatQJo+PafUf6MAiWPQq2BKhYH1oMw/czXuEL7PTNrAiIiIiku6sv7Ce4VuGA9C7XG+eL/y8abUTrTb6LdjN2mPXyOLqxDedK1MxX3bT6j/Q9unwY1d78Cn1ArT7TsHHZLrzIyIiIiLpyqEbhxi8djBWw8qzhZ6ld7neptVOstoYuHAPyw9dxc3FiemvVKZqQX/T6t+XYcC6L2D1p/bj0K7Q7Atwck7ZcTMhhR8RERERSTcu376cvJdP1eCqDKs+zLS9fKw2gzd+3Mfv+y/j6mxhaodK1CoSYErtB7LZYNm7sHWy/bjOm1D/XTBxfyL5Pwo/IiIiIpIuRCZE0mdlH67HXqewb2HG1BuDq7M5e/nYbAZDf97Pz7sv4uxkYUK7itQvHmhK7QeyJsIvfWHfd/bjpiOhWq+UHTOTU/gRERERkTQv0ZrI66tf50T4CQI9ApncaDLZ3MxZctowDIb9dpCF28/jZIGxbcrTpFSQKbUfKCEGfugEx/8CJxd4fjKUbZ2yY4rCj4iIiIikbYZh8OGmD9l2ZRueLp5MbDSRIC9zwolhGAz//TBzNp/FYoEvWpWjRblcptR+oNhbsOBlOL8FXDyg9Rwo2jhlxxRA4UdERERE0riJeyby26nfcLY482W9LynuV9y02qP/Osb0DacBGPFCGV6smMe02vcVdQXmvghhByGLD7T7HvJVS9kxJZnCj4iIiIikWT8f/5mp+6YC8H6196mZu6ZptcevPM6E1ScA+OjZUrStks+02vd18xTMeR7Cz0LWnNBhEQSVTtkx5S4KPyIiIiKSJm28uJGPNn8EwKtlX6Vl0Zam1Z669iSjlx8DYGizEnSqkd+02vd1eR/MawnRYZC9AHT8GfwKpOyYcg+FHxERERFJc47cPMKgNYOwGlaeKfgM/cr3M632rI2n+ezPIwAMaVyUHnUKmlb7vs5shG9fhvhIyFkGOvwE2XKm7JhyXwo/IiIiIpKmXIm+Qt8VfYlJiqFKUBU+rvGxaXv5LNh6jmG/HQKgX/3C9GtQxJS6D3T0T/ihMyTFQb4a0PZb8PBN2THlgRR+RERERCTNiEqIos/KPoTFhlHIpxBj6pu3l89POy8wdPF+AHrULsDgxkVNqftAe7617+NjWKHo09BqJrh6pOyY8q+cHN2AiIiIiAhAoi2RQWsGcfzWcQI8ApjUaBLebt6m1P5t7yXe+HEvhgGvVA/h3WYlTLubdF+bJ8LiXvbgU64ttJmr4JMG6M6PiIiIiDicYRh8tOkjtlzegoeLBxMbTiRXVnP221l64AoDv9uDzYCXK+dlWItSKRd8DANWfQLrR9uPq/eDpz4BJ91zSAsUfkRERETE4absncIvJ3/ByeLEF3W/oKR/SVPqrj4SRv9vd2G1GbxYITfDXyiDk1MKBR+bFX4fBDtn2Y8bfgi1XoeUvMMkj0ThR0REREQc6pcTvzBp7yQA3qv2HnXy1DGl7obj1+k5byeJVoPmZYMZ9VJZnFMq+CTFw0/d4fCvYHGCZ8ZApc4pM5Y8NoUfEREREXGYzZc2M2zTMAC6le5Gq6KtTKm79dQNus/ZTkKSjadK5mRsm/K4OKfQo2fxUbCwPZxeC85u0HI6lHwuZcaSJ6LwIyIiIiIOcezWMQatGUSSkcTTBZ5mQMUBptTdefYWXWdtJy7RRr1iOZjQrgKuKRV8om/A/JZwaTe4ZYWX50PBeikzljwxhR8RERERSXVXo6/SZ0UfbifeplLOSnxa81OcLE8eUPZdCKfzN9uITrBSs7A/UzpUwt3F2YSO7yP8PMx9AW4cB09/aP8D5K6UMmOJKRR+RERERCRV3U64Td+Vfbkac5UCPgX4qv5XuDm7PXHdQ5ci6ThjG1HxSVTJ78e0V0LJ4ppCwefaUXvwibwI3nmg48+QI4X3DZInpvAjIiIiIqkm0ZbIkLVDOHrrKH5Z/JjUcBI+7j5PXPf41Sg6zthKRGwi5fP68k2Xyni6pdBH3Qs7Yf5LEHsTAorag49PnpQZS0yl8CMiIiIiqcIwDD7d8ikbL23Ew8WDSQ0nkSfbk4eG09ejaTd9KzeiEyid25vZXauQ1T2FPuaeXG1f3CAxGnJVhPY/gpd/yowlplP4EREREZFU8fW+r1l0fBFOFidG1RlFqYBST1zz/M0Y2k3bwrWoeIoHZWNu16r4eLia0O19HFxsX87almhf1KDNPHDPljJjSYrQVrMiIiIikuJ+O/kbE/ZMAOCdKu9QL2+9J655KTyWdtO3cDkijkI5vJjbrSrZvZ587tB97fgGfuhsDz4ln4N23yv4pEMKPyIiIiKSorZe3soHmz4AoEupLrxc/OUnrhkWGUf76Vs5fzOWEH9PFvSoRo5s7k9c9x6GAes+hyWvAwZU6gIvzQSXFBhLUpweexMRERGRFJFgTWDxicWM3TmWJFsSTfI3YWClgU9c9/rteNpN38rp69Hk9vVgQY9q5PTO8uQN/5PNBn8NhS2T7Md13oD6Q8FiMX8sSRUKPyIiIiJiqnhrPIuOL2LG/hlcjbkKQMXAigyvNfyJ9/IJj0mgw/StnAi7TZB3Fr7tUY3cvh5mtH03ayL80hf2fWc/bvIZVO9j/jiSqhR+RERERMQUcUlx/HjsR7458A3XYq8BEOgRSNcyXXmp6Eu4Oz/Zo2KRcYl0nLGNI1eiCMjqzoIeVcnn72lG63dLiLHP7zm+DCzO8PwkKPfkj+qJ4yn8iIiIiMgTiUmM4YdjPzDzwExuxN0AIKdnTrqX6c4LRV544tADcDs+ic7fbGP/xQj8vNxY0KMqBXNkfeK694gNh29fhnObwSULtJoNxZqaP444hMKPiIiIiDyW6MRoFh5ZyOyDs7kVfwuAXF656F62O88Veg43Z3NWXotNsNJ11nZ2nQvHx8OVed2qUjRnCqy0FnUV5r0IVw+Auw+0+w5Cqps/jjiMwo+IiIiIPJLbCbf59si3zD40m4j4CADyZM3Dq2Vf5ZlCz+DqZN4+O3GJVnrM2cG20zfJ5u7CnK5VKJnL27T6yW6egrkvwK0zkDUndFgEQaXNH0ccSuFHRERERB5KZEIk8w/PZ+6huUQlRAEQ4h1CjzI9aFawmamhByAhyUbveTvZcOI6nm7OzOxSmXJ5fU0dA4Ar+2HuixAdBtnzQ8efwa+g+eOIwyn8iIiIiMi/ioiPYO6hucw/PJ/bibcBKOBTgFfLvkrT/E1xcTL/I2Wi1Ub/b3ex+ug13F2cmNGpMqH5/Uwfh7ObYUEbiI+AnKWhw0+QLcj8cSRNUPgRERERkfu6FXeLOYfmsODwAmKSYgAo7FuYnmV78lTIUzg7OafIuFabwaDv97Ls4FXcnJ2Y9koo1Qv5mz/QsWXw/SuQFAf5qkPbheDha/44kmYo/IiIiIjIXa7HXmfOwTksPLqQ2KRYAIpmL0qvcr1omK/hE+/V829sNoM3f9zHb3sv4eJkYXKHitQpmsP8gfYuhMV9wLBCkSbQaha4pcCy2ZKmKPyIiIiICADXYq4x8+BMfjj6A3HWOABK+JWgV7le1MtbL0VDD4BhGAxdfICfdl3A2cnC+LYVaFgip/kDbZ4Ey96xf1/2ZXhuAjibO19J0iaFHxEREZFM7kr0FWYemMmPx34kwZYAQJmAMvQq14vauWtjsVhSvAfDMPjot0N8u+0cFgt82bocT5cJNnsQWPUprP/CflytDzQeDk4pG+ok7VD4EREREcmkLt++zIwDM1h0fBGJtkQAyuUoR+9yvamRq0aqhB6wB5///XmEWZvOADCqZVmeK5/b3EFsVvh9MOycaT9u8D7UHgyp9B4lbVD4EREREclkLkRdYPr+6fxy8heSbEkAVAysSO/yvakaVDXVQs8dY1YcZ+q6UwAMf6E0rULzmjtAUjws6gGHfgEs8MyXENrV3DEkXVD4EREREckkzkWeY9r+afx28jeshhWAqkFV6VmuJ5WDKjukp4mrTzBu5XEAPnimJO2rhpg7QPxt+K49nFoDTq7QchqUesHcMSTdUPgRERERyeBOR5xm+v7p/H7q9+TQUyNXDXqW7UnFnBUd1tf09af4fNlRAN5+ujhdaxUwd4DoG7CgFVzcCa5e8PJ8KFTf3DEkXVH4EREREcmgToaf5Ot9X7P0zFJshg2A2rlr07NcT8rlKOfQ3uZsPsOnvx8GYGCjIvSqW8jcASIuwNwX4Pox8PCD9j9CnkrmjiHpjsKPiIiISAZz7NYxvt73NX+d+QsDA4B6eevRq2wvSgWUcnB38N32c3zwy0EAetcrxGsNi5g7wLVj9uATeQG8c0PHnyFHMXPHkHRJ4UdEREQkgzhy8whT905lxbkVyeca5WvEq2VfpYR/CQd29n9+3n2BtxftB6BrzQK82aSYuQssXNwJ816C2JvgX8QefHxNXkBB0i2FHxEREZF07uD1g0zZN4U159cAYMHCUyFP8WrZVynml3buePy+7zKDv9+LYUCHavl4/5kS5gafU2tgYXtIuA25KtgfdfMKMK++pHsKPyIiIiLp1L5r+5iydwrrL64H7KGnaYGmvFrmVQpnL+zg7u62/NBVXlu4G5sBrSrl4eNnS5sbfA79Aj91B2sCFKhrX9zAPZt59SVDUPgRERERSWd2h+1myt4pbLq0CQAnixPNCzSne9nuFPQp6ODu7rXmaBh95+8iyWbwXPlc/K9lWZycTAw+O2fBktfBsEGJZ6HldHBxN6++ZBgKPyIiIiLpxPYr25m6dypbr2wFwNniTItCLehRpgf5vPM5uLt73Y5PYsb600xac4IEq42nSwcxulU5nM0KPoYBG76ElR/bjyt1huZfgpOzOfUlw1H4EREREUnDDMNg25VtTN47mZ1XdwLgYnHhucLP0a1MN/JmS3uT+eOTrCzYeo4Jq05wIzoBgKdK5uSrlyvg4uxkziA2G/z1HmyZaD+uPRgavA9mPkonGY7Cj4iIiEgaZBgGmy9tZsq+KewO2w2Aq5MrLxZ5ka6lu5Iray4Hd3gvq83g590XGbP8GBfDYwEoEODF4MZFaVY62LxH3ayJ8Gt/2Put/bjxcKjRz5zakqEp/IiIiIikIYZhsP7ieqbuncq+6/sAcHNy46WiL9GldBeCvIIc3OG9DMNg+aGrfPHXUY5dvQ1ATm93XmtYlFaheXA1624PQGIs/NAFjv0JFmd4biKUb2tefcnQFH5ERERE0gDDMFhzfg1T9k3h0I1DAGRxzkKrYq3oUqoLOTxzOLbBB9hy6gYjlx5h97lwALyzuNCnfmE6Vc+Ph5vJc2/iImDBy3BuE7hkgVazoNjT5o4hGZrCj4iIiIgD2Qwbq86tYsreKRy9dRQADxcPXi72Mq+UeoUAj7S5T82BixF8vuwoa49dAyCLqxNdaxagZ51C+Hi6mj9g1FWY1xKu7gd3b2j3HYTUMH8cydAUfkREREQcwGqzsvzccqbuncqJ8BMAeLp40q5EOzqW7IhfFj8Hd3h/Z65HM3r5MX7bewkAFycLL1fJy4AGRQj0zpIyg948DXNfgFunwSsQOvwEwWVTZizJ0BR+RERERFKR1WZl6ZmlfL3va05FnAIgq2tW2pdoT4cSHfDN4uvYBh8gLDKOcauOs3DbeZJsBgDPlsvFoKeKkj/AK+UGvnIA5r0It6+Cbwi8shj80t5eRpI+KPyIiIiIpIIkWxJ/nP6DafumcSbyDADZ3LLRsURH2pVoh4+7j2MbfICI2ESmrj3JNxtPE5doA6BesRy80aQYpXKlcM/ntsCC1va5PoGloOMiyJb2FnyQ9EPhR0RERCQFJdoSWXJyCV/v+5oLty8A4OPuwyslX6Ft8bZkc8vm4A7vLzbByuzNZ5i85iQRsYkAVMzny5tNi1OtoH/KN3DsL/j+FUiKhbzVoN1C8Mie8uNKhqbwIyIiIpICEq2JLD65mBn7Z3Dx9kUAsrtnp1OpTrxc/GW8XFPwUbEnkGi18cOOC3y18hhXI+MBKJozK280KU6jEoFYUmMT0X3fw+LeYEuCIo2h1Wxw80z5cSXDU/gRERERMVG8NZ6fj//MjAMzuBJ9BQD/LP50Kd2FVkVb4emaNj/E22wGv++/zOi/jnLmRgwAuX09GPRUUZ6vkBtnszYo/S9bpsDSt+zfl21j38fHOQVWj5NMSeFHRERExARxSXH8dPwnvtn/DWGxYQDk8MhB19JdaVm0JR4uHg7u8P4Mw2Dd8euMWnqEg5ciAfD3cqNfg8K0q5oPdxeT9+p5cCOwegSsG2U/rtoLmnwGTiZukCqZnsKPiIiIyBOISYzhh2M/MPPATG7E3QAgp2dOupXpxotFXsTd2d3BHT7YrnO3GLX0CFtO3QQgq7sLPWoXpFvtAmR1T8WPiTYr/DEEdnxjP67/HtQZAqnxiJ1kKgo/IiIiIo8hJjGGhUcXMvvgbG7G2cNDsFcw3ct05/nCz+Pm7ObgDh/s+NUoPl92lL8OXQXAzdmJjtVD6FOvEP5ZUzmsJSXAz6/CwZ8BCzT/Aip3T90eJNNQ+BERERF5BLcTbieHnvD4cAByZ83Nq2VfpUXBFrim4fkpF27FMHbFcRbtuoDNACcLtKyYh4FPFSW3rwMey4u/Dd93hJOrwMkVXvwaSr+Y+n1IpqHwIyIiIvIQIhMiWXB4AXMPzSUywT43Jl+2fPQo24PmBZvj6pR2Q8+N2/FMXH2SeVvOkmC179XTpFROhjQuRpGcDlpqO+YmzG8FF3eAqxe8PA8KNXBML5JpKPyIiIiI/IuI+AjmHZ7H/EPziUqMAiC/d35eLfsqTxd4GhentPtx6nZ8EtPXn2LaulNEJ1gBqFbQj7eaFqdCPgfumRNxEea+ANeP2vfuaf8j5Al1XD+SaaTdf1pFREREHOhW3C3mHprLgiMLiE6MBqCQTyF6lutJ45DGODul0ipojyE+ycr8LeeYsPoEN6MTACid25s3mxSndpGA1Nmr50GuH7cHn4jzkC0XdPwZAos7rh/JVBR+RERERP7mRuwNZh+azcIjC4lNigWgaPai9Czbk0YhjXCypN2ll602g593X2TM8mNcDLf3XiDAi8GNi9KsdDBOqbVXz4Nc2g3zWkLMDfAvbA8+vvkc25NkKgo/IiIiIsD12OvMPDCT749+T5w1DoASfiXoWa4n9fPWT9OhxzAMlh+6yufLjnI87DYAOb3dGdioKC9VyoOrcxro/fQ6+LYtJNyG4PLQ4SfwCnB0V5LJKPyIiIhIpnY1+iozD87kx2M/Em+NB6C0f2l6letFnTx1HPuI2EPYcuoGI5ceYfe5cAB8PFzpU68QnWrkJ4trGnk079Cv8FM3sCZAgTrw8gJwd9BCC5KpKfyIiIhIpnT59mVmHJjBouOLSLQlAlA2R1l6l+tNzVw103zoOXAxgs+XHWXtsWsAZHF1olutArxapxA+Hmlk5bno67B6BOycCYYNSrSAF6eDaxZHdyaZlMKPiIiIZCoXb19k+v7pLD6xmCRbEgAVAyvSq1wvqgVXS/Oh58z1aEYvP8Zvey8B4OJkoW2VfPRvUJhA7zQSKpISYNtUWPs5xEfYz4V2hWZfQBpeKEIyPoUfERERyRTOR55n2v5p/HbyN5IMe+ipElSFXuV6EZozNM2HnquRcYxbeZzvtp8nyWYA8Fz5XAx6qigh/l4O7u7/Mww4+gf89R7cPGU/F1QWmn4G+Ws5tjcRFH5EREQkgzsTcYZp+6fx+6nfsRr2vW6qB1enZ7meVMpZycHd/beImESmrDvJzI2niUu0b1Bav1gOhjQpRqlcPg7u7m+uHIBl79gXNgDwCoSGH0D5drrbI2mGwo+IiIhkSKfCT/H1/q/58/Sf2Ax7aKiVuxY9y/akfGB5xzb3EGITrMzadIbJa04QGWe/U1UpJDtvNilG1YL+Du7ub25fg9Wfwq459nk9zu5QvS/UHqRFDSTNUfgRERGRDOX4reN8ve9rlp1ZhoH98bB6eerRs1xPSgeUdnB3/y3RauP7Hef5asVxwqLsq88Vy5mNN5oUo2GJwLTzeF5SPGydYp/XkxBlP1fqBWj0EWQPcWxvIg+g8CMiIiIZwpGbR/h639csP7s8+VyDvA3oWa4nJf1LOrCzh2OzGfy+/zKj/zrKmRsxAOTJ7sGgp4ryXPncODt6g9I7DAOOLLHP67l1xn4uuLx9Xk9IDUd2JvKfFH5EREQkXTt44yBT905l9fnVyeeeCnmKnmV7UsyvmAM7eziGYbDu+HVGLT3CwUuRAPh7udG/QWHaVs2Hu0sami9zeS8sfRfObrAfZw2CRh9C2ZfBKQ1spCryHxR+REREJF3af20/U/ZNYd0F+wR7Cxaa5m9Kj7I9KJK9iIO7ezi7zt1i1NIjbDl1E4Cs7i68WqcgXWsVIKt7GvqYFnUVVn0Cu+cBBrhkgRr9oeZAcM/q6O5EHloa+qdKRERE5L/tCdvDlL1T2HhpIwBOFieaFWhGj7I9KOhT0MHdPZxjV6P4YtlR/jp0FQA3FydeqRZCn/qF8fNyc3B3f5MYB1smwfrRkHDbfq50S2g0DHzzObQ1kceh8CMiIiLpwo4rO5iybwpbL28FwNnizDMFn6FH2R6EeKePCfYXbsUwdsVxFu26gM0AJwu8VCkPrzUqSm5fD0e3938MAw79Asvfh/Bz9nO5KkLT/0G+qo7tTeQJKPyIiIhImmUYBtuvbGfy3snsuLoDABeLC88Vfo5uZbqRN1teB3f4cG7cjmfi6pPM23KWBKt92e2mpYIY0qQohQPT2HLQl/bA0nfg3Cb7cbZc9js9ZVppXo+kewo/IiIikuYYhsHmy5uZuncqu8J2AeDi5MKLhV+kW5lu5Mqay8EdPpzb8UlMX3+KaetOEZ3w/zdYLejPm02LUSFfdgd39w9RV2DlJ7BnPvZ5PR5Q8zWoOQDcvBzdnYgpFH5EREQkzTAMgw0XNzBl3xT2XdsHgJuTGy2LtqRr6a4EeQU5uMOHE59kZd6Wc0xcfYKb0QkAlM7tzVtNi1OrcEDa2asHIDEWNk+E9V9CYrT9XJnW9lXcfPI4tjcRkyn8iIiISJpgM2y8ve5t/jzzJwDuzu60KtqKLqW7EOgZ6ODuHo7VZrBo1wXGrjjOxfBYAAoEeDGkcTGeLh2EU1rZqwfs83oOLoLlH0LEefu53KH2eT15Kzu2N5EUovAjIiIiacL43eP588yfuDi50L54ezqX7kyAR4Cj23oohmHw16GrfLHsKMfD7Kui5fR2Z2CjorxUKQ+uzmlsrszFnfb9es5vsR9754ZGH9lXctO8HsnAFH5ERETE4X49+SvT908H4OMaH9OiUAsHd/TwNp+8wcilR9hzPhwAHw9X+tQrRKca+cnimoY2KAWIvAQrP4a939qPXT3te/XU6A9ung5tTSQ1KPyIiIiIQ+26uothm4YB0L1M93QTfA5cjGDUsqOsO3YNAA9XZ7rWys+rdQrh4+Hq4O7+ISEGNk+ADWMgMcZ+rlxbaPgBeKePxSNEzKDwIyIiIg5zPuo8A1cPJNGWSKN8jehfob+jW/pPp69HM/qvoyzZdxkAFycLbavko3+DwgR6Z3Fwd/9gGHDgJ/u8nsgL9nN5q0KTzyBPJcf2JuIACj8iIiLiEFEJUfRf2Z9b8bco4VeC4bWG42RJu/NNrkbG8dXK43y3/TxWmwHAc+VzMeipooT4p8GloC/ssO/Xc2Gb/dgnLzz1EZR6EdLSanMiqUjhR0RERFJdki2JN9a9wcmIkwR6BDK+wXg8XdPmnJOImEQmrz3JrE2niUu0b1Bav1gOhjQpRqlcPg7u7j4iLsLKj2Dfd/ZjVy+o/TpU7weuHo7tTcTBFH5EREQk1X2+/XM2XtxIFucsjGs4jpxeOR3d0j1iE6zM3HSaKWtOEhmXBEClkOy82aQYVQv6O7i7+0iIho3jYONXkGRfZpvy7aHB++Ad7NjeRNIIhR8RERFJVd8d+Y4FRxYAMKL2CEr5l3JwR3dLtNr4bvt5xq08TlhUPADFcmbjjSbFaFgiMG1tUApgs8H+H2DFMIi6ZD+Xrzo0GQG5Kzq0NZG0RuFHREREUs2mS5v4bNtnAAyoMICnQp5ycEf/x2YzWLL/MqP/OsrZG/YV0fJk92Bw46I8Wy43zmlpg9I7zm+DpW/b9+0B8MkHjT+Gks9rXo/IfTzSrML8+fNjsVju+erbty+JiYm89dZblClTBi8vL3LlysUrr7zCpUuX7qoRHx9P//79CQgIwMvLi2effZYLFy6Y+qZEREQk7TkVcYoha4ZgNay0KNiC7mW6O7olwL5B6ZqjYTwzfgMDvt3N2RsxBGR146NnS7FycF1eqJAn7QWf8PPwYzeY8ZQ9+LhlhYYfQr/tUOoFBR+RB7AYhmE87MXXrl3DarUmHx84cICnnnqK1atXU6FCBV566SV69OhBuXLluHXrFgMHDiQpKYkdO3Yk/0zv3r357bffmDVrFv7+/gwePJibN2+yc+dOnJ0fbiOwyMhIfHx8iIiIwNvb+xHeroiIiDhCeFw47f5ox/mo81QIrMD0xtNxc3ZzdFvsPHuLUUuPsPX0TQCyurvQs05ButYqgJd7GnxAJv62fU7PpnGQFAdYoEIH+7yebGlv3pRIaniUbPBI4eefBg4cyJIlSzh+/Ph9n3/dvn07VapU4ezZs+TLl4+IiAhy5MjB3LlzadOmDQCXLl0ib968/PHHHzRp0uShxlX4ERERST8SrYn0WN6DnVd3kjtrbhY0X4BfFj+H9nTsahSfLzvK8kNXAXBzcaJT9RB61yuMn5fjQ9k9bDb76m0rP4Io+/5ChNSEpp9BcDnH9ibiYI+SDR77rzQSEhKYN28egwYNeuDEv4iICCwWC76+vgDs3LmTxMREGjdunHxNrly5KF26NJs2bXpg+ImPjyc+Pj75ODIy8nHbFhERkVRkGAYfb/mYnVd34uXqxYQGExwafC7cimHM8uMs2n0BwwAnC7SqlJfXGhUhl28aXQb63Bb7vJ5Lu+3HviHQ+FMo0UKPt4k8oscOP4sXLyY8PJzOnTvf9/W4uDjefvtt2rVrl5zArly5gpubG9mzZ7/r2pw5c3LlypUHjvXZZ5/x0UcfPW6rIiIi4iCzDs5i8YnFOFmc+LzO5xTOXtghfVy/Hc/E1SeYv+UcCVb7Xj1Plw5icOOiFA7M5pCe/lP4OVj+IRxcZD92ywZ1hkDVXuCaxbG9iaRTjx1+ZsyYwdNPP02uXLnueS0xMZGXX34Zm83GpEmT/rOWYRj/umzkO++8w6BBg5KPIyMjyZs37+M1LiIiIqli9bnVjNk5BoA3K79J7Ty1U72HqLhEpq8/zfT1p4hOsM9brlHInzebFqd8Xt9U7+ehxEfBhjGwaQJY4wELVHwFGrwHWQMd3Z1IuvZY4efs2bOsWLGCRYsW3fNaYmIirVu35vTp06xatequ5+6CgoJISEjg1q1bd939CQsLo0aNGg8cz93dHXd398dpVURERBzgyM0jvLX+LQwMWhdtTbvi7VJ1/LhEK/O3nmPi6hPcjE4AoExuH95qWpxaRQJStZeHZrPB3gWw8mO4bZ+LRP7a9v16gss6tjeRDOKxws/MmTMJDAykefPmd52/E3yOHz/O6tWr8fe/e/fjSpUq4erqyvLly2ndujUAly9f5sCBA4waNeox34KIiIikJddirtFvZT9ik2KpFlyNt6u+nWobg1ptBot2XWDsiuNcDI8FoGCAF0OaFOPp0kFpb4PSO85shGXvwOW99uPsBaDJcCjWTPN6REz0yOHHZrMxc+ZMOnXqhIvL//14UlISL730Ert27WLJkiVYrdbkeTx+fn64ubnh4+NDt27dGDx4MP7+/vj5+TFkyBDKlClDo0aNzHtXIiIi4hBxSXG8tvo1rsZcJb93fkbXG42rk2uKj2sYBn8dusoXy45yPOw2AEHeWRjYqAgvVcqDi/MjbW2Yem6dgeUfwKFf7Mfu3lD3TajyKrjoqRcRsz1y+FmxYgXnzp2ja9eud52/cOECv/76KwDly5e/67XVq1dTr149AMaMGYOLiwutW7cmNjaWhg0bMmvWrIfe40dERETSJpth472N77H/+n583H2Y2HAi3m4pvyXF5pM3GLn0CHvOhwPg4+FK3/qFeKV6frK4ptHPF3GRsOFL2DwRrAlgcYJKnaHeu5A1h6O7E8mwnmifH0fRPj8iIiJpz8Q9E5mydwouFhe+bvw1lYMqp+h4By5GMGrZUdYduwaAh6sz3WoVoEedgvh4pPzdpsdis8Ke+bDyE4gOs58rUNe+X0/OUo7tTSSdSpV9fkRERETu+OPUH0zZOwWA96u/n6LB5/T1aEb/dZQl++ybfbo4WWhXNR/9GhQmMFsaXgL69Hr7vJ4r++3HfoXs83qKNtW8HpFUovAjIiIiT2Tvtb28v/F9ADqX6syLRV5MkXGuRsbx1crjfLf9PFabgcUCz5XLxetPFSXE3ytFxjTFzVP2eT2Hf7Mfu/tAvbegcg9wcXNsbyKZjMKPiIiIPLZLty8xYNUAEmwJ1Mtbj4EVB5o+RkRMIpPXnmTmxtPEJ9k3KG1QPJAhjYtRMlcafvw9LgLWfQFbp/z/eT3OENrFPq/Hy/+/f15ETKfwIyIiIo8lOjGafqv6cTPuJsWyF2Nk7ZE4O5m3wEBMQhIzN55hytqTRMUlARAakp03mxanSgE/08Yxnc0Ku+bAqk8h5rr9XKEG9v16Aks4tjeRTE7hR0RERB6Z1WblrXVvcfzWcfyz+DO+wXg8XT1NqZ1otbFw+3nGrTzOtah4AIrlzMabTYvRoHhg2t2rB+DUWlj2Llw9YD/2L2IPPUWe0rwekTRA4UdEREQe2Zc7v2TthbW4ObkxrsE4grMGm1J344nrvPvzfs7eiAEgT3YPBjcuyrPlcuPslIbDw42T8Nf7cPR3+3EWX6j3DlTuBs5pdOU5kUxI4UdEREQeyU/HfmLOoTkADK81nLI5yppSd/+FCLrN3k5coo2ArG70b1CEtlXy4eaSRjcoBYgNh3Wfw9apYEu0z+up3B3qvQ2eafjRPJFMSuFHREREHtq2y9v4dMunAPQp14emBZqaUvdKRBzd59iDT52iOZjcviJe7mn4Y4o1CXbNhtXDIeaG/Vzhp+xLV+co5tjeROSB0vC/VURERCQtORt5ltfXvE6SkcTT+Z+mV7leptSNTbDSY84OrkbGUyQwKxPaVUjbwefkKlg2FMIO2Y8DitlDT5GnHNuXiPynNPxvFhEREUkrIuIj6LeyH5EJkZQNKMvHNT82ZeEBm81g0Pd72H8xAj8vN2Z0qox3ljQ6R+b6CfjrPTj2p/3YIzvUHwqVOmtej0g6ofAjIiIi/yrRlsjgNYM5E3mGIK8gvmrwFVlcsphS+8vlx/jzwBVcnS1M6VCJfP7mrBhnqthbsPZz2DYVbEng5AJVXoW6b9oDkIikGwo/IiIi8kCGYTBi6wi2XtmKh4sHExpMIMAjwJTaP+++wITVJwD47MWyaW/vHmsS7JwJq0dA7E37uaJNofGnEFDEsb2JyGNR+BEREZEHmnd4Hj8e+xELFkbVGUUxP3Mm8+88e5O3ftwPQK+6hXipUh5T6prmxAr7vJ5rR+zHOUrY5/UUbujYvkTkiSj8iIiIyH2tu7COL3Z8AcDg0MHUy1vPlLrnb8bw6pydJFhtNC6ZkzebpKHV0a4dg7+GwvG/7MceftBgKFTsDM762CSS3umfYhEREbnHsVvHeHPdm9gMGy8WeZFXSr5iSt2ouES6z97BjegESuXyZuzL5XFKC5uXxtyEtSNh2zQwrPZ5PVV7QZ03wMPX0d2JiEkUfkREROQuN2Jv0H9lf6ITownNGcp7Vd8zZWU3q81gwLe7OXo1isBs7kzvFIqnm4M/ilgTYcc39nk9ceH2c8WawVOfQEBhh7YmIuZT+BEREZFk8dZ4Xlv9GpeiL5EvWz7G1BuDq0nLOA///TCrj17D3cWJaa+EEuzjYUrdx3Z8OSx7F64fsx8HloKmI6BgPYe2JSIpR+FHREREAPvKbh9u+pC91/aSzS0bExpOwDeLrym1F2w9xzcbTwPwZevylMtrTt3HEnbEHnpOrrQfewZAg/eg4ivg5Oy4vkQkxSn8iIiICABf7/ua30/9jrPFmdF1R1PAp4ApdTeduM4HvxwAYNBTRWleNtiUuo8s+gas+cz+mJthBSdXqNYb6gyBLD6O6UlEUpXCj4iIiLDszDIm7JkAwLtV36V6ruqm1D117Ta95u0kyWbwXPlc9G/ggHk0SQmwfTqs/R/ERdjPFX8GnvoY/Aulfj8i4jAKPyIiIpncgesHeG/DewB0KNGB1sVam1I3PCaBbrN3EBmXRIV8voxsWdaUhRMemmHAsWX2patv2DdTJWcZ+7yeAnVSrw8RSTMUfkRERDKxK9FXGLBqAHHWOGrlrsWQ0CGm1E202ugzfxenr0eT29eDrzuGksU1FefTXD1kn9dzarX92CsHNHgfKnTQvB6RTEzhR0REJJOKSYxhwKoBXIu9RmHfwnxe53OcTQgGhmHwwS8H2XTyBl5uzkzvFEqObO4mdPwQoq/bl63eORMMGzi7QbU+UHswZPFOnR5EJM1S+BEREcmEbIaNd9a/w+Gbh/HL4seEhhPI6pbVlNrfbDzDt9vOYbHAuLYVKBGcCqEjKQG2TYW1n0P8/5/XU/I5aPQR+JmzcIOIpH8KPyIiIpnQuF3jWHV+Fa5OroytP5bcWXObUnfVkasM//0QAEOblaBhiZym1H0gw4Cjf8Bf78HNU/ZzQWWh6f8gf82UHVtE0h2FHxERkUxm8YnFzDgwA4CPanxEhcAKptQ9ciWS/gt2YzPg5cp56VYrhe+4XDkAy96B0+vsx1lzQsMPoFxbzesRkftS+BEREclEdl7dyUebPwKgR5ketCjUwpS612/H023WDqITrFQr6MfHz5VOuZXdbl+D1Z/Crjn/f16PO9ToB7VeB/dsKTOmiGQICj8iIiKZxPnI8wxcPZAkWxJPhTxFvwr9TKkbl2jl1Tk7uBgeS35/T6Z0qISbi5Mpte+SFA9bp8C6LyA+0n6u1Av2eT3ZQ8wfT0QyHIUfERGRTCAqIYp+q/oRHh9OSf+SDK81HCfLkwcUwzB4+6d97DoXjncWF2Z0royvp5sJHd81CBxZYp/Xc+uM/Vxwefu8nhBzNmMVkcxB4UdERCSDS7IlMWTtEE5FnCLQM5DxDcbj4eJhSu2Jq0+weM8lnJ0sTGpfiUI5zFkxLtnlvbD0XTi7wX6cNQgafQhlXwanFLi7JCIZmsKPiIhIBjdq+yg2XdqEh4sH4xuMJ9Az0JS6f+y/zBd/HQPgo2dLUatIgCl1AYi6Cqs+gd3zAANcskCNAVDzNXA3OWCJSKah8CMiIpKBfXvkW7498i0AI2qNoKR/SVPq7rsQzqDv9wDQuUZ+OlQzac5NYhxsmQTrR0PCbfu50i9Bo2Hgm9ecMUQk01L4ERERyaA2XdzEyG0jAXit4ms0CmlkSt0rEXH0mLODuEQbdYvm4L3mJUypS1I8zHsRzm60H+euBE0+g3xVzakvIpmewo+IiEgGdDL8JIPXDsZqWHm20LN0K93NlLoxCUl0n7Odq5HxFM2ZlfHtKuDibMLcG8OA3wbag4+7NzT7Asq00rweETGVwo+IiEgGcyvuFv1W9uN24m0qBlbkw+ofmrLnjs1mMOi7vRy4GImflxszOlXGO4urCR0DG8fC3gVgcYZWs6BwQ3Pqioj8jf46RUREJANJsCYwcPVALty+QO6suRlTfwxuzuYsPf3FX0dZevAKbs5OfN2xEnn9PE2py+ElsMK+8SpPj1TwEZEUo/AjIiKSQRiGwcebP2ZX2C6yumZlYsOJ+GXxM6X2TzsvMGnNSQD+17IMofnNqcvlvbCoB2BA5R5QpYc5dUVE7kPhR0REJIOYeXAmv5z8BSeLE5/X/ZxCvoVMqbv9zE3eWbQfgD71CvFixTym1CXqCnzbFhJjoFAD+6alIiIpSOFHREQkA1h5biVjd44F4K3Kb1Erdy1T6p6/GUPPuTtJsNpoWiqIIY2LmVKXxFh78Im8CAFF4aWZ4KypyCKSshR+RERE0rnDNw7zzvp3MDBoU6wN7Uq0M6VuVFwi3WZv52Z0AqVze/Nlm3I4OT35wgnYbLC4N1zaBR5+0O478PB98roiIv9B4UdERCQdC4sJo9+qfsQmxVI9uDpvV3nblLpJVhv9v93Nsau3CczmzvRXKuPpZtKdmbX/g4M/g5MrtJkHfgXNqSsi8h8UfkRERNKp2KRYBqwaQFhMGAV8CvBFvS9wcTInoAz/4zBrjl4ji6sT0zuFEuSTxZS67P8R1to3XuWZMZC/pjl1RUQegsKPiIhIOmQzbLy34T0O3jiIr7svExtMxNvN25Ta87eeZebGMwB82bo8ZfP4mlKXCztgcR/79zX6Q8WO5tQVEXlICj8iIiLp0KQ9k/jr7F+4OLkwpt4Y8nrnNaXuxhPX+eCXgwAMaVyUZmWCTalL+Hn7AgfWeCjWDBp9ZE5dEZFHoPAjIiKSziw5tYSp+6YC8EG1DwgNCjWl7slrt+k9bydWm8ELFXLTt35hU+oSf9sefKLDIGdpeHEaODmbU1tE5BEo/IiIiKQje8L28OHGDwHoUroLLxR5wZS6t6IT6DZrO5FxSVQKyc5nL5bBYjFjZTerfRPTq/vBKxDaLgT3rE9eV0TkMSj8iIiIpBMXb1/ktdWvkWBLoH7e+gysONCUuglJNnrP38mZGzHk9vVgasdKZHE16c7MimFw9A9wdoeXF4CvOY/niYg8DoUfERGRdOB2wm36rezHzbibFMtejP/V/h9Olif/z7hhGHzwywG2nLqJl5szMzqHEpDV3YSOgd3zYNM4+/fPT4K8lc2pKyLymBR+RERE0jirzcpb69/iRPgJAjwCmNBwAp6unqbUnrHhNAu3n8fJAuPbVaB4kDkrxnFmA/w20P593begzEvm1BUReQIKPyIiImnc6J2jWXdhHe7O7oxvMJ4gryBT6q48fJXhfxwG4N1mJWhQPKcpdbl5Cr7rALZEKPUC1DVn41URkSel8CMiIpKG/XDsB+YemgvAp7U+pXRAaVPqHr4cyYBvd2MY0LZKXrrVKmBKXWLDYUEbiL0FuSrC85PBSR83RCRt0L+NRERE0qitl7cyYssIAPqW70vT/E1NqXstKp7us3cQnWClekF/Pn6utDkru1mT4McucP0YZMsFbb8FV48nrysiYhKFHxERkTToTMQZXl/zOklGEs0KNKNn2Z6m1I1LtNJz7g4uhsdSIMCLyR0q4ups0seBZe/AyVXg6gntFkI2cx7PExExi8KPiIhIGhMRH0G/Vf2ISoiibI6yfFzzY1PuzBiGwVs/7WPXuXB8PFyZ0SkUX083EzoGtk2DbV/bv3/xawguZ05dERETKfyIiIikIYm2RAatGcTZyLMEewXzVf2vcHc2Z+npCatO8MueS7g4WZjcviIFc5i02ejJVfDnW/bvG34IJVqYU1dExGQKPyIiImmEYRgM3zKcbVe24eniyYSGEwjwCDCl9pJ9lxi9/BgAHz9XmhqFzanLtWPwfWcwrFCuLdR63Zy6IiIpQOFHREQkjZh7aC4/Hf8JCxZG1RlF0exFTam793w4g7/fC0DXmgVoVzWfKXWJuQkLWkN8BOSrDi2+AjMWThARSSEKPyIiImnA2vNr+WLHFwAMCR1C3bx1Tal7OSKWHnN2EJ9ko36xHAxtXsKUuiQl2PfyuXUafEOgzTxwMefxPBGRlKLwIyIi4mBHbx7lzXVvYmDQskhLOpbsaErdmIQkus/eQVhUPMVyZmNc2wo4O5lwZ8Yw4PfX4exGcPeGdt+Bl0mP0YmIpCCFHxEREQe6Hnud/qv6E5MUQ5WgKgytNtSUld1sNoOBC/dw8FIk/l5uTO8USrYsriZ0DGwaD7vngcUJXpoJgSbdTRIRSWEKPyIiIg4Sb43ntdWvcTn6MiHeIXxZ70tcncwJKJ//dZS/Dl3FzdmJqR0rkdfP05S6HPkDln9g/77JZ1CkkTl1RURSgcKPiIiIAxiGwfsb32fftX14u3kzocEEfNx9TKn9484LTF5zEoCRL5UhNL+fKXW5sh9+6g4YUKkLVDVn41URkdSi8CMiIuIAU/dN5c/Tf+JiceHLel+S3ye/KXW3n7nJO4v2AdC3fiFeqJDHlLpEXYUFL0NiNBSoC80+18puIpLuKPyIiIiksqVnljJxz0QA3q32LlWDq5pS99yNGHrO3Umi1eDp0kEMfqqYKXVJjIPv2kPkBfAvDK1ng7NJ84dERFKRwo+IiEgq2n9tP+9teA+AjiU70qpoK1PqRsYl0m32dm5GJ1Amtw9fti6Pk1kru/3SFy5shyy+0O578Mj+5HVFRBxA4UdERCSVXIm+woDVA4i3xlMnTx0GVxpsSt0kq41+C3ZzPOw2Ob3dmfZKKB5uzqbUZt3ncOBHcHKBNnPBv5A5dUVEHEDhR0REJBXEJMbQf1V/rsdep7BvYUbWHomzkzkB5dPfD7Pu2DWyuDox/ZXKBPlkMaUuBxbB6uH275uPhgJ1zKkrIuIgCj8iIiIpzGbYeHv92xy5eQS/LH5MaDiBrG5ZTak9d8tZZm06A8DYNuUpk8ecFeO4uBMW97Z/X60vVOpsTl0REQdS+BEREUlhY3eNZfX51bg5ufFV/a/InTW3KXXXH7/GsF8PAvBGk2I0LR1sSl0iLsK37SApDoo0gcafmFNXRMTBFH5ERERS0M/Hf2bmgZkAfFTzI8oHljel7omw2/SZvwurzeDFCrnpU8+kuTgJ0fDty3D7CgSWhJbTwaTH80REHE3hR0REJIVsv7Kdj7d8DEDPsj15puAzptS9FZ1At9nbiYpLolJIdj5rWQaLGXvu2Gyw6FW4sg88A6DtQsji/eR1RUTSCIUfERGRFHA+8jyvr3mdJFsSjUMa06d8H1PqJiTZ6DVvJ2dvxJAnuwdTO1bC3cWkOzOrPoYjS8DZDV5eANlDzKkrIpJGKPyIiIiYLDIhkr6r+hIRH0Ep/1J8WutTnCxP/p9cwzB4f/EBtp6+SVZ3F2Z0qkxAVncTOgb2LIANY+zfPzsB8pmz8aqISFqi8CMiImKiJFsSQ9YM4XTEaXJ65mR8g/F4uHiYUnv6+tN8t+M8ThYY37YCxYKymVKXs5vh1wH272sPhnJtzKkrIpLGKPyIiIiY6H/b/sfmy5vxcPFgfIPx5PDMYUrdFYeuMuLPwwC817wk9YsHmlKXW2fgu/ZgS4QSz0L998ypKyKSBin8iIiImGTB4QV8d/Q7LFj4rPZnlPAvYUrdQ5ciGbBwN4YB7armo0vN/KbUJS4SFrwMMTcguBy8MAWc9NFARDIu/RtORETEBBsubmDk9pEADKw0kIb5GppSNywqju6ztxOTYKVmYX8+eraUOSu7WZPgx65w7TBkC7av7Obm9eR1RUTSMIUfERGRJ3Qy/CRvrH0Dm2Hj+cLP06VUF1PqxiVaeXXOTi5FxFEwwItJ7Srh6mzSf7r/eg9OLAcXD2j7LXjnMqeuiEgapvAjIiLyBG7G3aTvyr7cTrxNxcCKfFDtA1PuzBiGwZs/7mPP+XB8PFyZ0bkyPp6uJnQM7PgGtk62f//CFMhVwZy6IiJpnMKPiIjIY0qwJvD66te5ePsiebLmYWz9sbg6mxNQxq08wa97L+HiZGFyh4oUCDDpkbRTa+D3IfbvG7wHpZ43p66ISDqg8CMiIvIYDMPgo80fsStsF9lcszGx4USyZ8luSu0l+y4xZsUxAD55vjQ1CgWYUpfrx+H7V8CwQtk2UHuIOXVFRNIJhR8REZHHMOPADH49+SvOFme+qPsFBX0LmlJ3z/lwBn+/F4ButQrQtko+U+oScxMWtIG4CMhTBVqMAzMWThARSUcUfkRERB7RirMr+GrXVwC8VeUtauSuYUrdS+Gx9Jizg/gkGw2KB/JuM3OWysaaaL/jc/Mk+OSFl+eDaxZzaouIpCMKPyIiIo/g0I1DvLvhXQDaFm9L2+JtTakbHZ9E99k7uBYVT/GgbIxrWwFnJxPuzBgG/D4YzqwHt6zQ7jvIatIGqSIi6YzCj4iIyEMKiwmj/8r+xCbFUjNXTd6s/KYpdW02g4Hf7eHQ5UgCsroxvVMoWd1dTKnNlsmwazZggZYzIGcpc+qKiKRDCj8iIiIPITYplv6r+hMWG0ZBn4J8XvdzXJzMCSgjlx1h+aGruLk4MbVjKHmye5pSl2N/wV9D7d83/hSKNTWnrohIOqXwIyIi8h9sho2hG4Zy6MYhfN19mdBwAtncsplS+4cd55m69hQAo1qWpVKIOSvGcfUQ/NgVDBtUfAWq9zWnrohIOqbwIyIi8h8m7J7A8rPLcXFyYWz9seTNlteUultP3eDdn/cD0L9BYZ6vkNuUuty+Zl/ZLSEK8teGZqO1spuICAo/IiIi/+q3k78xbf80AIZVH0alnJVMqXv2RjS95u0k0WrQrEwQrzcqakpdEuPgu/YQcQ78CkLrOeDiZk5tEZF0TuFHRETkAXaH7ebDTR8C0K10N54r/JwpdSPjEuk2ewe3YhIpm8eH0a3K42TWym6/DYDzWyGLD7T7Hjz9nryuiEgGofAjIiJyHxdvX2Tg6oEk2hJpmK8hAyoOMKVuktVG3/m7OBF2myDvLEx7JRQPN2dTarN+NOz7DizO0Go2BBQxp66ISAah8CMiIvIPtxNu029lP27G3aSEXwlG1BqBk8Wc/2R+suQQ649fx8PVmemdQsnpbdJmo4d+gVWf2L9v9jkUqm9OXRGRDEThR0RE5G+SbEm8se4NToSfIIdHDsY1GIenqzlLT8/dfIbZm88CMKZNOUrn9jGlLpd2w6Ke9u+r9ITK3cypKyKSwSj8iIiI/M3oHaPZcHEDWZyzML7BeIK8gkypu+7YNYb9dgiAN5sWo2npYFPqEnkZvm0LSbFQqCE0GWFOXRGRDEjhR0RE5P/7/uj3zDs8D4DhtYZTKqCUKXVPhEXRd/4urDaDFyvmpnfdQqbUJSEGvn0Zoi5DjuLQaiY4m7PxqohIRqTwIyIiAmy+tJkRW+13TfpX6E/j/I1NqXszOoGus3YQFZ9E5fzZ+ezFMljM2HPHZoPFveDyHvD0h7YL7Su8iYjIAyn8iIhIpnc64jSD1w7Galh5puAz9CjTw5S6CUk2es3bybmbMeT182BKh0q4u5i0stuaEfZFDpxcoc088CtgTl0RkQxM4UdERDK18Lhw+q3sR1RCFOVzlGdYjWGm3JkxDIOhP+9n2+mbZHN3YUanyvhndTehY2Df97Duc/v3z46DkBrm1BURyeAUfkREJNNKtCYyaO0gzkWdI5dXLsbWH4u7szkB5et1p/hh5wWcLDC+XQWK5sxmSl3Ob4Nf+tm/rzkQyrczp66ISCag8CMiIpmSYRh8uvVTtl/ZjperFxMaTsDfw9+U2ssPXeV/S48A8P4zJalXLNCUuoSfg4XtwBoPxZ+Bhh+aU1dEJJNQ+BERkUxpzqE5LDq+CCeLE6PqjKJI9iKm1D14KYLXFu7GMKB91Xx0rpHflLrER8GCNhB9DYLKwAtTwUn/GRcReRT6t6aIiGQ6a86vYfSO0QAMCR1CnTx1TKkbFhVHj9k7iEmwUrOwP8OeLWXSym5W+LEbhB2CrDntK7u5Z33yuiIimcz/Y+++w6Mo+zWOf3fTE5JAQgKh9957U0BBwQIKUlRQX7siCIIigoACYkEELCh25UVQEQEVFJXeW+iE3hMSSEghdXfn/LEaX46NmSyk3Z/r4rrmsDv3/nJyTsLtM/OMyo+IiBQrMYkxPLPqGQwM+tTqw4C6AzySm5nj5KHPtnImOZNqpYN4567m+Hh56NfssrFw8Efw9of+X0BoBc/kiogUMyo/IiJSbJzLOMcTvz5BhiOD1lGtGdV6lMd2dhvx1Q52nLxAyUAfPryvJaGBPh6YGNj6Kax/y3182ztQoblnckVEiiGVHxERKRYyHZk8+euTxF2Mo0pIFV7v+Do+ds8UlGk/H+S7nbF4223MvLs5VUsHeSSXo6vh+6fcx51GQYPenskVESmmVH5ERKTIMwyDsWvHsvPcTkJ8Q3jr+rcI9Qv1SPaiHWeY/stBACbd3oC21T2zYxznD8OXA8HlcJeejiM9kysiUoyp/IiISJH37o53WXJsCd42b6Z1nkblkMoeyd1+IokRX+0A4KFrqtKvZSWP5JKR5N7ZLSMJyreAnm+DJzZOEBEp5lR+RESkSFt6dCnv7HgHgDFtxtCybEuP5J6+kMFDn20l2+Hi+jqRPNu9rkdycebAV/fB+YMQUgH6zwGfAM9ki4gUcyo/IiJSZO1M2MmYtWMAuLfevfSu5Zl7Zi5mOXjw0y2cS8uiTtlgpt/ZFC+7B1ZmDAOWjIQjK8AnCO6aC8Fl8p4rIiKAyo+IiBRRsWmxDPl1CFnOLDpW6Miw5sM8kut0GTw5N5p9sSmULuHLB/e2oISft0ey2TQLtnwI2KD3B+6HmYqIiMeo/IiISJGTnpPO4F8Hcz7zPLVK1eKVa1/By+7lkexXl+7n531n8fW2M+ueFlQoFeiRXA7+DEufdR93fQHq3OSZXBERyaXyIyIiRYrT5WTk6pHEJMUQ7h/Om9e9SZCPZ7ae/nLLSd5bdQSA1+5oRLNKpTySS/x++Po/YLigyQBoN8QzuSIicgmVHxERKVKmbZvGipMr8LX7Mv266ZQrUc4juRuOnGf0gl0ADLmuBj2blPdILhfPwZy+kJUCldrBLW9oZzcRkStE5UdERIqMbw5+wyd7PgFgQvsJNI5o7JHcY+cu8ujsreQ4DW5uFMXQLrU8kosjC+YNgAvHoVQV6DcbvH09ky0iIn+i8iMiIkXC5rjNTFg/AYBHGz/KTdU8c89MckYOD3y6mQvpOTSuEMrrfRpj99TObt8NgxPrwS8E7pwHQR56QKqIiPwllR8RESn0TqScYNiKYTgMB92qdOPxxo97JNfhdPHEnG0cTrhIVKg/79/TAn8fz2ycwNrpEP1fsNmhz8cQWcczuSIi8rdUfkREpFBLzkpm0C+DSM5KpmHphkxoPwGbh+6ZeWHxXlYfPEeAjxfv39OCyBB/j+Sy7zv4ebz7uNsrUKOLZ3JFROQfqfyIiEihlePKYcTKERxLOUaZwDJM7zwdf2/PFJRP1x3j8w3HsdlgWv8mNCgf6pFcYnfCNw8BBrR8EFo/7JlcERH5Vyo/IiJSKBmGwSubXmFD7AYCvAN46/q3iAiM8Ej2ygMJvLB4DwDP3FiHG+uX9UguqXHwRX/ISYdqnd2rPiIictWo/IiISKG09NhS5sXMw4aNV655hTphnrln5uDZVJ747zZcBvRuVoFHO1bzSC45GTD3Lkg5DaVrQZ9PwMvbM9kiInJZVH5ERKTQSUhPYNLGSQA80vgROlfq7JHcxIvZPPDpFlKzHLSqEsZLvRp45v4hw4BvH4fTWyGgFNw5FwJK5j1XRERMUfkREZFCxTAMXlj/AslZydQNq8vDjTxzz0yWw8mjn2/lRGI6FcMCeHdgc/y8PbSz24qXYc83YPd2P8snvLpnckVExBSVHxERKVQWHl7IylMr8bH7MKnDJHzsPnnONAyD0Qt2s+lYIsF+3nx0b0vCgjz0sNFdX8PKl93Ht7wBVTp4JldERExT+RERkUIj7mIcr2xybxLweJPHqVmqpkdy31t1hK+3nsJug7fubkbNMsEeyeXUFvflbgBtn4Bm93gmV0RELFH5ERGRQsEwDMauHUtaThqNIhpxX/37PJL74544Xlm6H4Bxt9anYy3P7BhH8in44k5wZkGtbtD1Rc/kioiIZSo/IiJSKHx14CvWx67Hz8uPie0n4m3P+05pu08nM3RuNIYBA9tU5t52VfI+KEBWGszpDxfjoUwD6P0B2D10/5CIiFim8iMiIgXeydSTTNkyBYChzYZSNbRqnjPjUzJ56LMtZOQ4uaZmacbdWi/PmQC4XPDNw3B2FwRFwJ1fgJ+HLqMTEZE8MVV+qlSpgs1m+9OfQYMGAe5LEsaPH0+5cuUICAigU6dO7Nmz55KMrKwsBg8eTOnSpQkKCqJHjx6cOnXKc1+RiIgUKS7DxZg1Y8hwZNCiTAvuqntXnjMzc5w89NkWYpMzqR4RxFt3NcPby0P/PfCX8RDzPXj5Qf8voGQlz+SKiEiemfpJv3nzZmJjY3P/LFu2DIA+ffoA8OqrrzJ16lTeeustNm/eTNmyZenatSupqam5GUOHDmXBggXMnTuXNWvWkJaWxi233ILT6fTglyUiIkXF7L2z2Ra/jQDvAF5s/yJ2W95KistlMPyrHew4lUzJQB8+vLcloQF53zEOgO3/hbXT3cc934aKLT2TKyIiHmHqN0hERARly5bN/fPdd99RvXp1OnbsiGEYTJs2jdGjR9OrVy8aNGjAp59+Snp6OnPmzAEgOTmZDz/8kNdff50uXbrQtGlTZs+eza5du/j555+vyBcoIiKF19Hko8zYPgOAES1GUDG4Yp4zp/1ykO93xuLjZePdAc2pUjooz5kAHFsLi590H1/7DDTq45lcERHxGMv/+Sw7O5vZs2dz//33Y7PZOHr0KHFxcdxwww257/Hz86Njx46sW7cOgK1bt5KTk3PJe8qVK0eDBg1y3/NXsrKySElJueSPiIgUbQ6XgzFrxpDlzKJduXb0qZX3MrEw+jQzfjkIwKTbGtKmWnieMwFIPALzBoArB+rdBp1GeSZXREQ8ynL5+fbbb7lw4QL33XcfAHFxcQCUKVPmkveVKVMm97W4uDh8fX0pVarU377nr0yePJnQ0NDcPxUr5v2//ImISMH2yZ5P2HluJ8E+wbzQ7gVsNlue8radSOLpr3cC8PC11ejb0kO/SzKT3Tu7ZSRCuaZw20ywaz8hEZGCyPJP5w8//JDu3btTrly5S/7+//9yMgzjX39h/dt7Ro0aRXJycu6fkydPWh1bREQKgQNJB3g7+m0ARrYaSdmgsnnKO30hg4c/20q2w0WXumUY2a2OJ8YEpwO+ug/OxUBwOfcGB76BnskWERGPs1R+jh8/zs8//8yDDz6Y+3dly7p/Mf3/FZz4+Pjc1aCyZcuSnZ1NUlLS377nr/j5+RESEnLJHxERKZpynDmMWTMGh8tBpwqd6FG9R57y0rIcPPDJZs6lZVE3KoTp/ZvgZc/bKlKuH0fB4V/BJ9C9pXVIlGdyRUTkirBUfj7++GMiIyO5+eabc/+uatWqlC1bNncHOHDfF7Ry5UratWsHQPPmzfHx8bnkPbGxsezevTv3PSIiUrzN2jWLfYn7CPULZVy7cXm63M3pMnjyi+3sj0uldAk/Pri3BUF+eX84KgCb3odNs9zHt78H5Zp4JldERK4Y078BXC4XH3/8Mffeey/e3n+cbrPZGDp0KC+99BI1a9akZs2avPTSSwQGBnLXXe5nMoSGhvLAAw8wfPhwwsPDCQsLY8SIETRs2JAuXbp47qsSEZFCac/5Pby/830AxrQeQ+mA0nnKe3nJPn7ZH4+vt53372lO+ZIBnhjTvdqzZKT7+PqxUC9vq1MiInJ1mC4/P//8MydOnOD+++//02vPPPMMGRkZPP744yQlJdG6dWt++ukngoP/eLL1G2+8gbe3N3379iUjI4Prr7+eTz75BC8vr7x9JSIiUqhlObMYvXo0TsPJDZVvoFvVbnnKm7f5BO+vPgrAlD6NaVqp1L+ccZkSDsCX94HhhMZ3QoenPJMrIiJXnM0wDCO/hzArJSWF0NBQkpOTdf+PiEgRMXXrVD7e/TFh/mF82/NbSvlbLyvrD59n4IcbcbgMnry+JsO61vLMkOmJ8P51kHQUKraBexeBt59nskVExBIz3UB7cYqISL6Ljo/m0z2fAjCu7bg8FZ9j5y7y2H+34nAZ3NIoiqFdanpmSEc2zBvoLj4lK0H//6r4iIgUMio/IiKSrzIcGYxZOwaX4aJH9R5cV+k6y1nJ6Tnc/+lmLqTn0LhiSab0aZzn5wMBYBjw/VNwfA34BsNdX0JQ3u5HEhGRq0/lR0RE8tX0bdM5nnKcyMBIRrYaaTknx+li0JxtHEm4SFSoP+8PbI6/j4fuJ13/Fmz/HGx26PMxRNb1TK6IiFxVKj8iIpJvNsVu4r/7/gvAC+1eIMTX2n2chmHwwuI9rDl0jkBfLz64twWRIf6eGTJmCfz0vPv4xpegZlfP5IqIyFWn8iMiIvniYs5Fxq4bC8Adte6gQ/kOlrM+XXeM2RtOYLPBtH5NqF8u1DNDxu2G+Q8CBjS/D1o/6plcERHJFyo/IiKSL6ZsmcLptNOUL1GeES1GWM5ZHhPPi9/tBeDZbnW4oX5ZzwyYFg9f9IfsNKh6Ldw0BTxx/5CIiOQblR8REbnq1pxew9cHvgZgQvsJBPkEWco5cDaVwXO24zKgT/MKPHxtNc8MmJMJc++C5JMQVh36fApePp7JFhGRfKPyIyIiV1VKdgrj1o0D4O66d9OybEtLOcnpOTzw6WbSshy0qhrGpNsbem5nt0VPwKnN4F/SvbNbYFjec0VEJN+p/IiIyFX1yqZXiE+Pp3JIZZ5s9qTlnDELd3MyMYOKYQG8O6A5vt4e+pW2agrs+grs3tD3MyhdwzO5IiKS71R+RETkqvn1xK8sOrwIu83OxPYTCfAOsJSzMPo0i3ecwctu4807mxEW5OuZAfcsgOUT3cc3TYFqHT2TKyIiBYLKj4iIXBVJmUm8sP4FAO6tfy9NIptYyjl9IYMx3+4GYPB1NWhSsaRnBjy9DRY85j5u8zi0+I9nckVEpMBQ+RERkati4oaJJGYmUj20OoOaDLKU4XIZDP8ymtRMB00qluSJzh66JC35NHxxJzgyoOYNcMNEz+SKiEiBovIjIiJX3NKjS/np+E942byYdM0k/Lz8LOV8sOYIG44kEuDjxRv9muDt5YFfY9kX3Vtap8VBZD3o/SHYvfKeKyIiBY7Kj4iIXFHnMs4xcaN7JeWhRg9RP7y+pZx9sSlM+fEAAGNvrUfV0ta2x76EywULHoG4nRBYGu6cC/4hec8VEZECSeVHRESuGMMweGHdCyRnJVM3rC4PN3zYUk5mjpOhc6PJdrroUrcM/VtW9MyAv06AfYvByxf6/xdKVfZMroiIFEgqPyIicsUsOryIFadW4G33ZmKHifhYfFDolB9jiDmbSukSvrzc20PP84n+AtZMdR/3eBMqtcl7poiIFGgqPyIickXEXYzjlU2vADCoySBqlaplKWfdoXN8sOYoAK/0bkTpEtbuF7rEiQ2weIj7uMNT0Lh/3jNFRKTAU/kRERGPMwyDcevGkZqTSqPSjbiv/n2WcpLTcxj+1Q4A7mxVievrlsn7cEnHYe7d4MyGurfCdc/nPVNERAoFlR8REfG4rw58xboz6/Dz8mNih4l4270t5Ty/cDexyZlUCQ9kzM118z5YZgrM6Qfp5yCqMdz+Htj1q1BEpLjQT3wREfGok6knmbJlCgBPNnuSqqFVLeUsjD7Noh1n8LLbeKNfE4L8rBWoXC4nzH8AEvZBibLund18PbBjnIiIFBoqPyIi4jEuw8XYtWPJcGTQvExz7q57t6WcMxcyGPPtbgCe6FyDppVK5X24n8bAwZ/AOwDu/AJCyuU9U0REChWVHxER8Zg5++aw5ewWArwDmNB+Anab+V8zLpfB8C93kJrpoHHFkjxxXY28D7blY9jwjvv49nehfLO8Z4qISKGj8iMiIh5xNPko07ZNA2BEixFUDLb2LJ4P1xxl/ZHzBPh4Ma1fE3y88vir6shK+GGE+7jzGKh/W97yRESk0FL5ERGRPHO4HIxZO4YsZxZto9rSp1YfSzn7YlN47ccYAMbcUpeqpfN4T865Q/DlQHA5oGEfuHZE3vJERKRQU/kREZE8+2TPJ+xM2EkJnxK82P5FSw8hzcxxMmxeNNlOF9fXieSuVpXyNlR6IszpC5nJUKEl9HgLPPFwVBERKbRUfkREJE8OJh3knWj3/TQjW42kbFBZSzmv/xTD/rhUwoN8ebl3I0sFKpczB766FxIPQ2hF6D8HfPyt54mISJGg8iMiIpbluHIYvWY0Oa4cOlboSM/qPS3lrDt8jg/WHAXgld6NiAj2sz6UYbjv8Tm6CnxLuLe0LhFpPU9ERIoMlR8REbHs/Z3vsy9xH6F+oYxrO87Sak1yRg4jvtyBYcCdrSrSpV6ZvA218V3Y+glgg94fQNkGecsTEZEiQ+VHREQs2Xt+L+/vfB+A0a1HExEYYSln7MLdnEnOpEp4IGNurpe3oQ4ugx+fcx/fMAFqd89bnoiIFCkqPyIiYlq2M5vRa0bjMBx0rdyVblW6WcpZtOMMC6PP4GW3MbVfE4L8vK0PdXYvfPUfMFzQdCC0fcJ6loiIFEkqPyIiYtrb0W9z6MIhwvzDGNNmjKXL3c5cyGDMgl0ADOpcg2aVSlkfKC0BvugH2alQuQPcPFU7u4mIyJ+o/IiIiCnR8dF8sucTAMa2HUuYf5jpDJfLYMRXO0jJdNC4QiiDr6thfSBHFswbABdOQFg16Pc5ePtazxMRkSJL5UdERC5bhiODMWvH4DJc3FrtVq6vdL2lnI/WHmXd4fME+HjxRr8m+HhZ/HVkGLBoCJzcAH6hcOc8CDRfxkREpHhQ+RERkcs2Y9sMjqccJzIgkpGtRlrK2B+Xwqs/xgAw+ua6VIsoYX2gNVNh51yweUHfTyCilvUsEREp8lR+RETksmyO28zsfbMBeKH9C4T6hZrOyHI4GTo3mmyHi+vqRHJ360rWBzr0C/zyovu4+ytQ/TrrWSIiUiyo/IiIyL+6mHOR59c+D0Dvmr3pUL6DpZzXfzrA/rhUwoJ8ebl3Q0sbJQDuDQ4WPOo+bn4ftHrIWo6IiBQrKj8iIvKvXt/yOqfTTlMuqBxPt3zaUsb6w+d5f/URAF7u1ZDIYH9rwxgGLHwcLsZDRF3o9rK1HBERKXZUfkRE5B+tPb2Wrw58BcCE9hMI8gkynZGckcPwL6MxDOjfsiI31C9rfaCN78LBn8DLD+74EHwCrGeJiEixovIjIiJ/KyU7hbHrxgJwV527aBXVylLOuIW7OZOcSeXwQJ6/pZ71gWJ3wDL3PNw4CcrUt54lIiLFjsqPiIj8rVc2vUJ8ejyVgivxZLMnLWUs3nGGb6PPYLfB1L5NCPLztjZM9kX4+gFwZkPtm6Hlg9ZyRESk2FL5ERGRv7T8xHIWHV6E3WZnUodJBPoEms6ITc5g9IJdADzRuQbNK5eyPtDSZ+H8QQiOgh5vgtXNEkREpNhS+RERkT+5kHmBF9a/AMC99e6lSWQT0xkul8GIr3aQkumgcYVQBl9f0/pAe76FbZ8BNug1C4LCrWeJiEixpfIjIiJ/MmnjJM5nnqd6aHUGNR1kKePjdcdYe+g8/j52pvZrgo+XxV85F07C4iHu4w7DoOq11nJERKTYU/kREZFLLD22lKXHluJl82LSNZPw8/IznRETl8orS/cDMPrmelSPKGFtGKcDvnkIMpOhfAvo/Jy1HBEREVR+RETkf5zLOMekDZMAeLDhg9QPN7+bWpbDydB50WQ7XHSuHcGA1pWsD7TqNTixHnyDofcH4OVjPUtERIo9lR8REQHAMAxeWP8CF7IuUCesDo80esRSztRlB9gXm0JYkC+v3NEIm9WNCY6vg1Wvuo9veQPCqlrLERER+Y3Kj4iIALD4yGJWnFyBt92bSR0m4WNhlWXDkfPMWnUEgMm9GhIZ7G9tmIwkmP8QGC5ofCc06mMtR0RE5H+o/IiICHEX43h548sAPN74cWqVqmU6IyUzh+Ff7sAwoF+LitxYv6y1YQwDFj8JKacgrBrc9Jq1HBERkf9H5UdEpJgzDINx68aRmpNKw9IN+U+D/1jKGbdwD6cvZFApLJDnb61nfaBtn8HehWD3dt/n4xdsPUtEROR/qPyIiBRzXx/8mnVn1uHn5cfEDhPxtnubzvhu5xkWbD+N3QZv9GtCCT/zGQAkxLgfZgpw3fNQvrm1HBERkb+g8iMiUoydSj3FlM1TABjSdAjVQquZzohLzmT0gt0ADOpcg+aVS1kbJicTvn4ActKhWidoN8RajoiIyN9Q+RERKaZchovn1z5PuiOdZpHNGFBvgPkMl8GIr3aQnJFDowqhDLm+pvWBfh4PZ3dBYDjc/h7Y9StKREQ8S79ZRESKqS/2f8GWs1sI8A5gYvuJ2G3mfyV8su4Yaw6dw9/Hzhv9muDjZfHXyoGfYONM9/FtMyHY4mYJIiIi/0DlR0SkGDqWfIxpW6cBMLz5cCqGVDSdceBsKi8v3Q/A6JvqUj2ihLVhUuPg28fcx60fhVo3WssRERH5Fyo/IiLFjNPlZMzaMWQ6M2kT1Ya+tfuazsh2uBg6N5psh4tOtSMY0KaytWFcLljwKKSfgzINocsL1nJEREQug8qPiEgx8+neT9mRsIMSPiV4sd2L2Gw20xlTlx1gb2wKpQJ9eLV3I0sZAKx/C44sB+8AuOND8LH4UFQREZHLoPIjIlKMHEw6yFvb3wLgmZbPEFUiynTGxiPneW/VYQAm92pEZIjFwnJ6G/zy20pP95chora1HBERkcuk8iMiUkzkuHIYvWY0Oa4cOlboyG01bjOdkZKZw1Nf7sAwoE/zCnRrYHFjgqxUmP8AuBxQtwc0u9dajoiIiAkqPyIixcQHOz9gX+I+QnxDGNd2nKVL1cYv3MPpCxlUCgtkXI/61of54RlIPAIhFaDHDLB62ZyIiIgJKj8iIsXA3vN7mbVzFgCjW48mIjDCdMb3O2P5Zvtp7DZ4o19jSvh5Wxtm19ewYw7Y7ND7fQiw+FBUERERk1R+RESKuGxnNqPXjMZhOOhauSvdq3Y3nRGXnMlzC3YB8HinGjSvHGZtmKRj8N0w9/G1T0PldtZyRERELFD5EREp4t6JfodDFw4R5h/GmDZjTF/u5nIZPP31DpIzcmhYPpQnu9S0NogzB+Y/CFkpULENXPuMtRwRERGLVH5ERIqwHQk7+HjPxwCMbTOWMH/zKzafrj/G6oPn8Pex80a/Jvh4WfzVsWIynNoMfqHuy928LF42JyIiYpHKj4hIEZXhyGDMmjG4DBe3VLuF6ytfbzrj4NlUXl6yH4DnbqpLjcgS1oY5ugpWT3Uf95gOJStZyxEREckDlR8RkSJqxrYZHEs5RmRAJM+2etb0+dkOF0/OjSbL4aJjrQgGtqlsbZD0RPjmEcCApgOh/u3WckRERPJI5UdEpAjaHLeZ/+77LwDj240n1C/UdMYbPx9gb2wKpQJ9eO2ORpa2xsYwYOETkHoGwmtC91fMZ4iIiHiIyo+ISBGTnpPO82ufx8Cgd83eXFPhGtMZm44m8u7KwwBM7tWQyBB/a8Ns+RBivgcvX7jjQ/ANspYjIiLiASo/IiJFzOtbXud02mmigqIY0WKE6fNTM3MYNi8aw4A7mlegW4Moa4Oc3Qs/jnYfdxkPUY2t5YiIiHiIyo+ISBGy7vQ6vjzwJQAT2k+ghK/5DQrGL9rL6QsZVCgVwLhb61kbJCcDvr4fHJlQoyu0fsxajoiIiAep/IiIFBEp2SmMXTcWgDvr3EnrqNamM37YFcv8baew2+CNfk0I9vexNsxPYyBhHwRFwm0zwa5fNyIikv/020hEpIh4ddOrnE0/S6XgSgxtNtT0+WdTMnluwS4AHutUnZZVzD8TCID938PmD9zHt78LJSKs5YiIiHiYyo+ISBGw4uQKFh5eiA0bEztMJNAn0NT5LpfBiK92cCE9hwblQ3jy+lrWBkk5AwsHuY/bPgE1zD9bSERE5EpR+RERKeQuZF5g/LrxANxb/16aRjY1nfHZ+mOsPngOP2870/o1wdfbwq8HlxO+eRgyktybG1w/znyGiIjIFaTyIyJSyL208SXOZ56nWmg1nmj6hOnzD55NZfKS/QA8d1NdakQGWxtk7TQ4thp8gqD3R+Dtay1HRETkClH5EREpxH489iNLji3By+bFSx1ews/Lz9T52Q4XQ+dFk+VwcW2tCO5pW9naICc3w6+T3Mc3vQala1jLERERuYJUfkRECqlzGeeYuGEiAA80fID6peubzpj28wH2nEmhZKAPr93RCJvNZn6QzGSY/wAYTmjQG5rcZT5DRETkKlD5EREphAzDYML6CVzIukDtUrV5tNGjpjM2H0vk3ZWHAZh8e0PKhPhbGQS+Hw4XjkPJSnDLG2ClQImIiFwFKj8iIoXQd0e+49eTv+Jt92ZSh0n4eJl7Hk9qZg7D5kXjMqB3swp0bxhlbZAdc2HXV2Dzgt4fgn+otRwREZGrQOVHRKSQibsYx+SNkwF4rPFj1A6rbTrjhcV7OZWUQYVSAYzvUc/aIOcPww8j3MedRkHFVtZyRERErhKVHxGRQsQwDMavG09qTioNwhtwf4P7TWcs3R3L11tPYbPB1L5NCPY3t2oEgCPbfZ9PdhpU7gDXPGU+Q0RE5CpT+RERKUTmH5zP2jNr8bX7MqnDJLzt3qbOj0/JZNQ3uwB4rGN1WlUNszbI8olwZjsElIJes8DuZS1HRETkKlL5EREpJE6nnea1za8BMKTZEKqVrGbqfMMwGPH1TpLSc2hQPoShXWpZG+Twr7B2uvu4x1sQWt5ajoiIyFWm8iMiUgi4DBfPr32edEc6zSKbMaDuANMZn60/zqoDCfh525nWrwm+3hZ+BVw8Bwt+21muxf1Q9xbzGSIiIvlE5UdEpBD4Yv8XbI7bTIB3ABPbT8TL5GVmh+JTeemHfQCM6l6HGpHB5ocwDPj2cUg7CxF14IZJ5jNERETykcqPiEgBdzzlONO2TgPgqeZPUTGkoqnzsx0uhs6LJsvh4pqapbmnbRVrg2x8Dw7+CF5+cMdH4BtoLUdERCSfqPyIiBRgTpeT0WtGk+nMpHVUa/rW7ms6Y/ovB9h9OoWSgT5M6dMYu93CQ0jjdsGy593HN0yEMvXNZ4iIiOQzlR8RkQLss72fsSNhB0E+QUxoNwG7zdyP7S3HEpm54jAAL93ekDIh/uaHyL4IX98Pzmyo1R1aPWQ+Q0REpABQ+RERKaAOJR3ize1vAjCy5UiiSkSZOj81M4dhX0bjMqBXs/Lc1NDc+bmWjoJzByA4Cnq+DTYLK0ciIiIFgMqPiEgBlOPKYfTa0eS4crim/DXcVuM20xkvLt7LycQMypcMYHwPi5ep7fkWtn0K2OD29yAo3FqOiIhIAaDyIyJSAH2460P2nt9LiG8I49uNx2ZytWXp7li+2noKmw3e6NeEEH8f80NcOAmLh7iPOwyFah3NZ4iIiBQgKj8iIgXMvvP7eG/HewA81/o5IgMjTZ0fn5LJqG92AfDItdVpVTXM/BAuJ3zzMGQmQ/nm0Hm0+QwREZECRuVHRKQAyXZmM3rtaByGg66Vu3JT1ZtMnW8YBs/M30lSeg71okJ4qmsta4OsmgIn1oFvMPT+ALwsrByJiIgUMCo/IiIFyMwdMzmYdJAw/zDGtBlj+nK32RuOsyImAT9vO9P7N8HX28KP+RMbYOXL7uNbpkJYNfMZIiIiBZDKj4hIAbEzYScf7f4IgOfbPE+Yv7nL1Q7FpzHph30APNu9DjXLBJsfIiMJ5j8Ihgsa9YdG5p8rJCIiUlCp/IiIFACZjkxGrxmNy3Bxc7Wb6VK5i6nzsx0uhs2LJjPHxTU1S3Nv2yrmhzAMWDwUkk9Cqapw8xTzGSIiIgWYyo+ISAEwY/sMjqUcIyIgglGtRpk//5eD7DqdTGiAD6/d0Ri73cKzeLZ/Dnu/Bbs33PEh+FlYORIRESnAVH5ERPLZ1rNbmb13NgDj240n1C/U3PnHE3lnxSEAXrq9IWVD/c0PkXAAlox0H183xr3Dm4iISBGj8iMiko/Sc9IZs2YMBga9avbi2grXmjo/LcvBsHk7cBnQq2l5bm4UZX4IRxbMvx9y0qFqR2j3pPkMERGRQkDlR0QkH03dOpVTaaeICori6RZPmz7/xcV7OJGYTvmSAYzvWd/aED+/AHG7IDAcbn8P7PrVICIiRZN+w4mI5JN1Z9YxL2YeAC+2f5ESviVMnf/jnji+3HIKmw2m9m1MiL+FZ/EcXAYb3nYf93wHQiysHImIiBQSKj8iIvkgNTuVsWvHAtC/dn/aRLUxdX58aiajvtkFwMPXVqN1tXALQ5yFBY+6j1s9ArW7mc8QEREpRFR+RETywaubX+Vs+lkqBldkWPNhps41DINnvt5J4sVs6kaF8FTXWuYHcLng20ch/RyUaQBdXzSfISIiUsio/IiIXGUrT67k20PfYsPGxPYTCfQJNHX+7I0nWBGTgK+3nen9m+Dn7WV+iA1vw+FfwTsAen8IPhZ2iBMRESlkVH5ERK6iC5kXGL9+PAD31LuHZmWamTr/cEIak77fC8Cz3epQq4yFZ/Gc2e7e5ACg20sQWcd8hoiISCGk8iMichW9tOklzmWco1poNQY3G2zq3Byni2HzosnMcdGhRmnua1fF/ABZafD1A+DKgbq3QvP/mM8QEREppFR+RESukp+O/cSSo0vwsnkxqcMk/Lz8TJ3/5i8H2XkqmdAAH6b0aYzdbjM/xJJnIPEwhJSHW2eAzUKGiIhIIaXyIyJyFZzPOM/EDRMBuL/B/TQo3cDU+VuPJ/LW8kMATLq9AWVDLdyjs+triP4v2OzQ630IDDOfISIiUoip/IiIXGGGYfDi+hdJykqiVqlaPNb4MVPnp2U5GDZvBy4Dbm9anlsalTM/RNIx+O63XeWuGQFV2pvPEBERKeRUfkRErrDvjnzHryd/xdvuzUsdXsLHy9zDSCcs3suJxHTKlwzghZ71zQ/gdMD8hyArBSq2ho4jzWeIiIgUASo/IiJX0NmLZ5m8aTIAjzV+jNphtU2d/+OeOOZtOYnNBq/3bUyIv7niBMDKl+HUJvALdV/u5uVtPkNERKQIUPkREblCDMNg/PrxpGan0iC8Afc3uN/U+fGpmYz6ZhcAD19TjTbVws0PcXQ1rJriPr71DShV2XyGiIhIEaHyIyJyhXxz8BvWnF6Dr92XSR0m4W2//BUXwzAY+fVOEi9mUzcqhKduqGV+gPRE+OZhwICmA6BBb/MZIiIiRYjKj4jIFXA67TSvbn4VgCHNhlCtZDVT5/934wmWxyTg621nWr8m+Hl7mRvAMGDRYEg9A+E1oPur5s4XEREpglR+REQ8zGW4GLt2LOmOdJpGNmVA3QGmzj+SkMak7/cB8MyNtaldNtj8EFs+gv3fgd0Hen8IvkHmM0RERIoYlR8REQ+bu38um+I2EeAdwMT2E/GyX/6qTY7TxbB50WTkOGlfI5z721c1P0D8PvjxOfdxl/FQron5DBERkSJI5UdExIOOpxxn2rZpAAxrPoxKIZVMnf/mr4fYcSqZEH9vpvRpjN1uMzdATiZ8/QA4MqH69dDmcXPni4iIFGEqPyIiHuJ0ORmzZgwZjgxal21Nv9r9TJ2/7UQSby8/BMCk2xsSFRpgfohlz0P8HgiKgNvfBbt+zIuIiPxOvxVFRDzk872fE50QTZBPEC+2fxG77fJ/xF7McjBsXjROl8FtTcpxa+Ny5gfY/wNsmuU+vv1dKBFpPkNERKQIU/kREfGAwxcO8+b2NwF4puUzlCthrrxM+G4vx8+nUy7Unxd6NjA/QMoZWDjIfdz2CajRxXyGiIhIEafyIyKSRw6Xg9FrRpPtyuaa8tdwe43bTZ2/bO9Z5m4+ic0Gr/dtQmiAj7kBXE5Y8AhkJELZRnD9WHPni4iIFBMqPyIiefThrg/Zc34PIb4hjG83Hpvt8jcpSEjN4tn5OwF46JpqtK0ebn6AtdPh6CrwCYQ7PgJvP/MZIiIixYDKj4hIHuxP3M+7O94FYFTrUUQGXv59NoZhMHL+Ts5fzKZO2WCG31DL/ACntsLySe7j7q9C6ZrmM0RERIoJlR8REYtynDmMXjMah+GgS6Uu3Fz1ZlPnz9l0gl/3x+PrZWda/yb4eV/+84AAyEyB+feDywH1e0FTcw9TFRERKW5UfkRELJq5YyYHkg5Qyq8UY9qMMXW525GENCZ+tw+AZ7rVpk7ZEPMDfD8cko5BaCW45Q0w8fkiIiLFkcqPiIgFuxJ28eHuDwF4vu3zhAdc/r06OU4Xw77cQUaOk3bVw7m/fVXzA+yYC7u+BJsX9P4AAkqazxARESlmVH5EREzKdGQyeu1oXIaLm6reRNfKXU2d/9avh9hx8gIh/t5M6dMYu93kis35w+5VH4BOz0Kl1ubOFxERKaZUfkRETHpr+1scTT5KREAEz7V+ztS5208k8dbyQwBMvL0h5UoGmPtwRzbMfxCy06Bye7hmuLnzRUREijHT5ef06dMMGDCA8PBwAgMDadKkCVu3bs19PS0tjSeeeIIKFSoQEBBA3bp1mTlz5iUZWVlZDB48mNKlSxMUFESPHj04depU3r8aEZErbOvZrXy29zMAxrcbT6hf6GWfezHLwbB50ThdBj2blKNHY3MPQgXcO7ud2Qb+JaHXLLCb3CRBRESkGDNVfpKSkmjfvj0+Pj4sWbKEvXv38vrrr1OyZMnc9wwbNoylS5cye/Zs9u3bx7Bhwxg8eDALFy7Mfc/QoUNZsGABc+fOZc2aNaSlpXHLLbfgdDo99oWJiHhaek46Y9aMwcDg9hq3c22Fa02dP/H7fRw7n065UH9e7NnA/ABHVrif6QPQ400IrWA+Q0REpBjzNvPmV155hYoVK/Lxxx/n/l2VKlUuec/69eu599576dSpEwAPP/ww7733Hlu2bKFnz54kJyfz4Ycf8vnnn9OlSxcAZs+eTcWKFfn555+58cYb8/YViYhcIVO3TuVU2inKBpXl6ZZPmzr3571n+WLTCWw2mNK3MaEBPuY+/OI5+OYRwIDm/4F6PcydLyIiIuZWfhYtWkSLFi3o06cPkZGRNG3alPfff/+S93To0IFFixZx+vRpDMNg+fLlHDhwILfUbN26lZycHG644Ybcc8qVK0eDBg1Yt27dX35uVlYWKSkpl/wREbmaNsRuYF7MPABebPciwb7Bl31uQmoWI+fvBODBDlVpV720uQ83DPj2cUiLg4g6cONL5s4XERERwGT5OXLkCDNnzqRmzZr8+OOPPProowwZMoTPPvss9z0zZsygXr16VKhQAV9fX7p168Y777xDhw4dAIiLi8PX15dSpUpdkl2mTBni4uL+8nMnT55MaGho7p+KFSua/TpFRCxLzU5l7NqxAPSr3Y+25dpe9rmGYfDs/J2cv5hNnbLBjLixtvkBNs2Cgz+Clx/0/hB8A81niIiIiLnL3lwuFy1atOCll9z/1bFp06bs2bOHmTNncs899wDu8rNhwwYWLVpE5cqVWbVqFY8//jhRUVG5l7n9FcMw/vYBgaNGjeKpp57K/Z9TUlJUgETkqnlt82vEXoylQokKPNX8qX8/4X98sekkv+yPx9fLzrT+TfDzNrlBQdxu+Ol59/ENE6CshXuFREREBDBZfqKioqhXr94lf1e3bl3mz58PQEZGBs899xwLFizg5ptvBqBRo0ZER0czZcoUunTpQtmyZcnOziYpKemS1Z/4+HjatWv3l5/r5+eHn5+fqS9MRMQTVp1axYJDC7BhY2KHiQT6XP6qy9FzF5nw3V4Anr6xNnXKhpj78Ox0+Pp+cGZBrW7Q6mFz54uIiMglTF321r59e2JiYi75uwMHDlC5cmUAcnJyyMnJwW6/NNbLywuXywVA8+bN8fHxYdmyZbmvx8bGsnv37r8tPyIi+SE5K5lx68YBMLDeQJqXaX7Z5zqcLobNiyYjx0nbauE80KGq+QF+fA7OxUCJstDzbfib1XERERG5PKZWfoYNG0a7du146aWX6Nu3L5s2bWLWrFnMmjULgJCQEDp27MjTTz9NQEAAlStXZuXKlXz22WdMnToVgNDQUB544AGGDx9OeHg4YWFhjBgxgoYNG/7jZXEiIlfbSxtf4lzGOaqGVmVw08Gmzn1r+SGiT14g2N+b1/s2xm43WVz2LoKtHwM26PUeBJncJEFERET+xFT5admyJQsWLGDUqFG8+OKLVK1alWnTpnH33Xfnvmfu3LmMGjWKu+++m8TERCpXrsykSZN49NFHc9/zxhtv4O3tTd++fcnIyOD666/nk08+wctLD+sTkYJh2fFl/HD0B+w2O5PaT8Lf2/+yz91+Iok3fz0EwMTbGlCuZIC5D08+BYt+K1vtn4RqncydLyIiIn/JZhiGkd9DmJWSkkJoaCjJycmEhJi8hl5E5F+czzjP7QtvJykriYcaPsSQZkMu+9z0bAc3z1jD0XMX6dG4HDPubGruw11O+PRWOL4WyjWDB34CL5PPBBIRESlGzHQDU/f8iIgUdYZhMHHDRJKykqhVqhaPNn7030/6HxO/38fRcxeJCvVnQk8LO7Otft1dfHxLwB0fqviIiIh4kMqPiMj/+OHoD/x84me8bd5M6jAJXy/fyz73l31nmbPxBACv92lMaKDJ4nJiI6x42X188+sQVs3c+SIiIvKPVH5ERH4Tnx7PpI2TAHi08aPUCatz2eeeS8ti5PydADzYoSrtapjcoCDjAsx/EAwnNOoHjfubO19ERET+lcqPiAjuy93GrxtPanYq9cPr80DDB0yd++z8XZxLy6ZO2WBG3Fjb7IfDd8Mg+QSUqgI3TTF3voiIiFwWlR8REWDBoQWsPr0aX7svkzpMwtt++Zthzt18kp/3ncXXy84b/Zrg72Ny58rts2HPN2D3ht4fgb82chEREbkSVH5EpNg7k3aGVze/CsDgpoOpXrL6ZZ977NxFJny3F4ARN9aibpTJ4nLuICx5xn3ceTRUuPwHqYqIiIg5Kj8iUqy5DBdj147lYs5FmkY2ZWC9gZd9rsPpYui8aNKznbSpFsaDHUxuUODIgq/vh5x0qHottB9q7nwRERExReVHRIq1eTHz2Bi3EX8vfya0n4CX/fIvWXt7+WGiT14g2N+b1/s2wW63mfvwX16EuJ0QEAa3zwK7fiSLiIhcSfpNKyLF1omUE7yx9Q0AhjUfRuWQypd9bvTJC8z49SAAE3o2oHzJAHMffvBnWP+W+/i2dyAkytz5IiIiYprKj4gUS06XkzFrx5DhyKBV2Vb0r3P5W0unZzsYNi8ap8vglkZR9GxSztyHp8XDt789PLXVw1C7u7nzRURExBKVHxEplmbvm832+O0E+QTxYvsXsdsu/8fhpO/3cfTcRaJC/Zl0W0NsNhOXu7lcsOBRuJgAkfWh6wQL04uIiIgVKj8iUuwcuXCEGdtmAPB0i6cpX6L8ZZ/76/6z/HfjCQCm9GlMaKCPuQ/f8A4c/gW8/eGOj8DH39z5IiIiYpnKj4gUKw6Xg9FrRpPtyqZD+Q70qtnrss89n5bFM1/vAuCBDlVpX6O0uQ8/Ew0/j3cf3/gSRNYxd76IiIjkicqPiBQrH+3+iN3ndxPsG8z4tuMv+5I1wzB49ptdnEvLonaZYJ6+sba5D85Kg/kPgCsH6twCLe63ML2IiIjkhcqPiBQbMYkxzNwxE4BRrUZRJqjMZZ/75ZaTLNt7Fl8vO2/0a4K/z+VviQ3A0pFw/hCElIceb4KZ+4RERETEI1R+RKRYyHHm8Nya53C4HFxf6XpuqXbLZZ977NxFXli8F4DhN9SiXrkQcx++ez5snw3YoNcsCAwzd76IiIh4hMqPiBQLb25/kwNJByjlV4rn2zx/2Ze7OZwuhn0ZTXq2k9ZVw3jwmmrmPjjpOCwe6j6+dgRU6WDufBEREfEYlR8RKfK+P/I9H+/5GICxbccSHhB+2ee+s+Iw209cINjPm9f7NsbLbuJyNacD5j8IWSlQoRV0fNbs6CIiIuJBKj8iUqTtOb+HcevGAfBAgwfoUrnLZZ+74+QFpv9yEIAXb6tPhVKB5j585StwahP4hUDvD8DL29z5IiIi4lEqPyJSZJ3LOMeTvz5JljOLaytcy+Cmgy/73PRsB8PmReN0GdzcKIrbmlz+s4AAOLYWVk9xH9/yBpSqbO58ERER8TiVHxEpkrKd2QxbPoyz6WepGlqVl695GS/75e/Q9tIP+zhy7iJlQ/yZdFuDy75HCID0RPjmITBc0GQANLzDwlcgIiIinqbyIyJFjmEYTNo4ieiEaIJ9gpnReQbBvsGXff7y/fHM3nACgCl9GlMy0NfMh8PiIZByGsJrQPdXzI4vIiIiV4jKj4gUOV/s/4JvDn6D3WbntY6vUSW0ymWfez4ti6e/3gnA/e2r0qFmaXMfvvVj2LcY7D7Q+0PwK2HufBEREbliVH5EpEjZFLuJVze/CsCwZsNoX779ZZ9rGAajvtnFubQsapUpwTPdapv78Pj9sPQ593GXcVCuibnzRURE5IpS+RGRIuNU6imGrxyO03ByS7VbuLf+vabO/2rLKX7aexYfLxvT+jXF3+fy7xEiJxO+vh8cGVD9OmgzyOT0IiIicqWp/IhIkZCek86Q5UO4kHWBBuENGNd2nKlNCk6cT+eFxXsAGH5DbeqVCzE3wLKxEL8HgiLgtnfBrh+vIiIiBY1+O4tIoecyXDy35jkOJh2kdEBppnWehr+3/2Wf73C6GPZlNBeznbSqGsZD11QzN0DMUtj0nvv4tpkQXMbc+SIiInJVqPyISKH33o73+OXEL/jYfXij0xuUCTJXPmauOMzW40kE+3kztW9jvOwmtrVOiYWFj7uP2wyCml1NfbaIiIhcPSo/IlKo/Xz8Z97Z8Q4Az7d5niaRTUydv/PUBab/chCAF3rWp0KpwMs/2eWCBY9A+nko28i9yYGIiIgUWCo/IlJoHUg6wHNr3LurDag7gNtr3m7q/IxsJ0PnReNwGdzcMIrbm5Y3N8C66XB0JfgEwh0fgbefufNFRETkqlL5EZFCKSkziSG/DiHDkUHrqNYMbzHcdMZLP+zjSMJFyoT4Men2BqY2SODUVvh1ovu4+ytQuqbpzxcREZGrS+VHRAqdHFcOI1aO4HTaaSqUqMCUa6fgbfc2lbE8Jp7PNxwHYEqfxpQM9L38k7NSYf4D4HJAvdug6UBTny0iIiL5Q+VHRAqdKZunsCluE4Hegbx53ZuU9C9p6vzEi9k88/VOAP7TvgrX1IwwN8D3IyDpKIRWglung5kVIxEREck3Kj8iUqh8c/Ab5uyfA8DkayZTo1QNU+cbhsGob3aSkJpFzcgSjOxWx9wAO+bBzrlgs0Pv9yGgpLnzRUREJN+o/IhIoREdH82EDRMAGNRkENdVus50xldbT/HjnrP4eNmY1r8J/j5el39y4hH4/in3ccdnoVIb058vIiIi+UflR0QKhbiLcQxdPhSHy0HXyl15pNEjpjNOnE/nhUV7AHiqa23qlwu9/JOdOTD/QchOg0rt4NoRpj9fRERE8pfKj4gUeJmOTJ5c/iTnM89Tq1QtJrafaG5nNsDpMnjqy2guZjtpVSWMh6+tZm6I5ZPg9FbwD4Ves8BuYsVIRERECgSVHxEp0AzDYNy6cew9v5dSfqWYcd0MAn1MPIj0N2/9eogtx5Mo4efN630b42U3UZ6OrIQ109zHPd6EkhVNf76IiIjkP5UfESnQPt7zMT8c/QFvmzevd3qd8iVMPogU97bW0345AMCLPetTMcxEebp4Hr55GDCg+X1Qr6fpzxcREZGCQeVHRAqsVadWMW3rNABGthpJy7ItTWccP3+RJ7/YjmHA3a0r0atZhcs/2TBg4SBIi4PSteHGyaY/X0RERAoOlR8RKZCOJh/l2VXPYmBwR6076Fe7n+mM9GwHj3y+lZRMB00rlWTcrfXNBWz+AA4sAS9fuOND8DV/uZ2IiIgUHCo/IlLgpGSnMOTXIaTmpNIsshnPtXrO9AYHhmEwcv4u9selUrqEH+8OaI6vt4kfeXG74cfR7uOuE6BsQ1OfLyIiIgWPyo+IFChOl5ORq0ZyLOUYZYPKMrXTVHy8fEznfLjmKIt3nMHbbmPmgGaUCfG//JOz02H+A+DMgpo3Qmvz22qLiIhIwaPyIyIFyvTt01lzeg3+Xv5M7zyd8IBw0xnrDp9j8pL9ADx/Sz1aVgkzF/DTaEjYDyXKwG3vgMlVJxERESmYVH5EpMD4/sj3fLz7YwAmtJ9AvfB6pjPOXMhg8JztOF0GvZqW5562lc0F7FsMWz4CbHD7exBU2vQMIiIiUjCp/IhIgbDn3B7GrRsHwIMNH6Rb1W6mMzJznDw2eyvnL2ZTLyqEl3o1NHevUPJpWDTYfdx+CFTvbHoGERERKbhUfkQk353LOMeQ5UPIcmbRsUJHBjcdbDrDMAzGLdzDjlPJlAz04b2BzfH38br8AJfT/TyfjCQo1xQ6jzE9g4iIiBRsKj8ikq+yndkMWz6M+PR4qoZWZfI1k7HbzP9o+mLTSeZtOYndBm/e2dTcg0wBVk+F42vAtwT0/hC8fU3PICIiIgWbyo+I5BvDMJi0cRLRCdEE+wbz5nVvEuwbbDpn24kkxi3aDcDTN9bhmpoR5gJOboIVvz3A9KYpEF7d9AwiIiJS8Kn8iEi+mbN/Dt8c/Aa7zc5r175G5RCTmxMA8amZPDZ7KzlOg+4NyvJox2rmAjKT3dtaG05o2Aca9zc9g4iIiBQOKj8iki82xm7ktc2vAfBU86doX7696Ywcp4sn/rudsylZ1IgswWt9Gpvb4MAw4LthcOEElKwMN0/VttYiIiJFmMqPiFx1J1NPMnzlcJyGk1ur3co99e6xlDPp+31sOpZIsJ837w1sTgk/b3MB0XNg93ywe8MdH4F/iKU5REREpHBQ+RGRqyo9J50hvw4hOSuZBuENGNt2rLnVmt8s2H6KT9YdA2BqvyZUjyhhLuDcIfjhafdx5+egQgvTM4iIiEjhovIjIleNy3Dx3JrnOHThEBEBEUzrPA1/b3/TObtPJ/Ps/F0ADLmuBl3rlTEX4MiC+fdDzkWocg20H2p6BhERESl8VH5E5Kp5d8e7/HLiF3zsPrzR+Q3KBJksLUDSxWwenb2VLIeLTrUjeLJLLfOD/PIixO6AgDDoNQvsJp4HJCIiIoWWyo+IXBU/H/+ZmTtmAjC27VgaRzQ2neF0GQyZu51TSRlUDg9ker+meNlNXjJ36GdY/5b7uOdbEFLO9BwiIiJSOKn8iMgVdyDpAM+teQ6AAXUHcFuN2yzlvP5TDKsPniPAx4t3BzQnNNDHXEBaAix4zH3c8iGoc7OlOURERKRwUvkRkSsqKTOJIb8OIcORQZuoNgxvMdxSztLdsbyz4jAAr9zRiLpRJndmc7ng28fgYjxE1oMbJliaQ0RERAovlR8RuWJyXDmMWDmC02mnqRhckSkdp+BtN7kdNXAoPpXhX+4A4MEOVenR2MKlahvegUPLwNvfva21T4D5DBERESnUVH5E5Ip5bfNrbIrbRKB3IDM6zyDUL9R0RmpmDg9/vpWL2U7aVAvj2e51zA9yYgP8PM59fOMkiKxrPkNEREQKPZUfEbki5h+Yzxf7vwBg8jWTqVGqhukMl8vgqS93cCThIlGh/rx1VzO8vUz+2EpLgK/uA5cDGvSGFg+YnkNERESKBpUfEfG47fHbmbhxIgBPNHmC6ypdZynnnRWHWLb3LL5edt4d0JzSJfzMBbic7uf5pMZC6dpw6wyw8EBVERERKRpUfkTEo+IuxjF0+VAcLgc3VL6Bhxs9bClneUw8ry87AMCE2+rTuGJJCyGT4Ogq8AmCfp+DXwlLs4iIiEjRoPIjIh6T4chgyK9DSMxMpHap2kxoPwGbhZWW4+cv8uQX2zEMuKt1Jfq1rGR+mJilsPp193GPGRBR23yGiIiIFCkqPyLiEYZhMG7dOPYl7qOUXymmXzedQJ9A0znp2Q4e+XwrKZkOmlYqybhb65kfJukYLPhtxanVw9DwDvMZIiIiUuSo/IiIR3y852OWHF2Ct82b1zu9TvkS5U1nGIbBs/N3sT8uldIl/Jh5d3P8vL3MheRkwpf3QGYylG8BN0wyPYeIiIgUTSo/IpJnq06tYtrWaQA82+pZWpZtaSnno7XHWLTjDN52G+/c3Yyyof7mQ5Y+C7E7ICAM+nwC3r6WZhEREZGiR+VHRPLkSPIRRq4aiYFBn1p96Fenn6Wc9YfP89IP+wAYfXNdWlUNMx+yYy5s/RiwQe8PoGRFS7OIiIhI0aTyIyKWpWSn8OSvT5KWk0azyGaMajXKUk5scgZPzNmG02Vwe9Py3NeuivmQs3tg8VD3cadnocb1lmYRERGRokvlR0QscbqcPLPqGY6lHCMqKIqpnabi4+VjOifL4eTR2ds4fzGbelEhvHR7Q/M7xGWmwLyB4MiA6tfDtc+YnkNERESKPpUfEbFk+rbprD29Fn8vf6Z3nk54QLilnHEL97Dj5AVKBvrw3sDmBPia3ODAMGDhIEg8DCEVoNf7YNePNhEREfkz/QtBREz77sh3fLznYwAmtJ9A3fC6lnK+2HSCuZtPYrPBjP5NqRhmfmtsNrwD+xaB3Qf6fgZB1kqYiIiIFH0qPyJiyp5zexi/bjwADzV8iG5Vu1nK2X4iiXEL9wAw4obaXFsrwnzIiQ2wbKz7uNtkqNDc0iwiIiJSPKj8iMhlO5dxjiHLh5DlzKJjhY480fQJSzkJqVk8Nnsb2U4X3eqX5fFO1c2HpCXAV/eBywEN7oCWD1qaRURERIoPlR8RuSzZzmyGLh9KfHo81UKr8fI1L2O3mf8RkuN0MWjONuJSMqkeEcSUvo3Nb3DgcsL8+yE1FkrXhlung9kMERERKXZUfkTkXxmGwcQNE9mRsINg32BmXDeDEr4lLGW99MM+Nh1NpISfN7PuaUEJP2/zIcsnwdFV4BME/T4HP2uziIiISPGi8iMi/2rO/jksOLQAu83OlGunUDmksqWcb7ef5uO1xwB4vW9jqkdYKC0xS2H16+7jnm9CRG1Ls4iIiEjxo/IjIv9oQ+wGXtv8GgBPNX+KduXbWcrZcyaZZ7/ZCcATnWtwY/2y5kOSjsGCh93HrR6BBr0tzSIiIiLFk8qPiPytk6knGbFyBE7DSY/qPbin3j2Wci6kZ/Po7K1k5rjoWCuCYV1rmQ/JyYQv74HMZCjfAm6YaGkWERERKb5UfkTkL13MuciQX4eQnJVMw9INGdt2rPmNCQCny2DI3GhOJmZQKSyQ6f2b4GW3sDnB0pEQuwMCwqDPJ+Dtaz5DREREijWVHxH5E5fh4rnVz3HowiEiAiKY1nkafl5+lrKmLoth1YEE/H3svDugOSUDLZSW6C9g6yeADXp/ACUrWppFREREijeVHxH5k3d3vMuvJ3/Fx+7DG53fIDIw0lLO0t1xvL38MACv9G5EvXIh5kPO7oHvhrmPOz0LNa63NIuIiIiIyo+IXGLZ8WXM3DETgHFtx9E4orGlnEPxaYz4agcA97evSs8m5c2HZCbDvIHgyIDq18O1z1iaRURERARUfkTkf8QkxjB6zWgABtYbSM8aPS3lpGbm8PDnW0jLctC6ahijbqpjPsQwYOEgSDwMIRWg1/tg148sERERsU7/khARAJIyk3hy+ZNkODJoG9WWp5o/ZSnH5TIY/uUOjiRcpGyIP2/f3QwfLws/ata/DfsWg90H+n4GQeGW5hERERH5ncqPiJDjymH4yuGcTjtNxeCKvNbxNbzt3payZq48zE97z+LrZefdgc0pXcLCRgnH18Oyse7jbpOhQnNLs4iIiIj8L5UfEeG1za+xOW4zgd6BvHndm4T6hVrKWRETz5SfYgB4sWd9mlQsaT4kLQG+/g8YTmhwB7R80NIsIiIiIv+fyo9IMTf/wHy+2P8FNmy8fM3LVC9Z3VLOifPpPDk3GsOAO1tVon+rSuZDXE6Yfz+kxkLp2nDrdLDwbCERERGRv6LyI1KMbTu7jYkbJwLwRNMn6Fyps6WcjGwnj8zeSnJGDk0qlmR8j3rWBlo+CY6uAp8g6Pc5+JWwliMiIiLyF1R+RIqpuItxDFsxDIfLwQ2Vb+Chhg9ZyjEMg2e/2cm+2BRKl/Bl5oBm+Hl7mQ+KWQqrX3cf93wTImpbmkdERETk76j8iBRDGY4Mhvw6hMTMROqE1WFC+wnYLF5e9vHaYyyMPoOX3cZbdzUjKjTAfEjSMVjwsPu41SPQoLelWURERET+icqPSDFjGAbj1o1jX+I+SvmVYnrn6QT6BFrK2nDkPJN+2AfA6Jvq0qaahe2oczLhy3vcDzSt0BJumGhpFhEREZF/o/IjUsx8tPsjlhxdgrfNm6mdplKuRDlLObHJGTwxZxtOl8FtTcrxn/ZVrA20dCTE7oDAcOjzCXj7WssRERER+RcqPyLFyKpTq5i+bToAo1qPokXZFpZyshxOHpu9jXNp2dSNCmFyr0bWLpuL/gK2fgLYoPcHEFrB0jwiIiIil0PlR6SYOJJ8hJGrRmJg0KdWH/rW7ms5a/yiPUSfvEBogA/vDWhOgK+FDQ7O7oHvhrmPO42C6tdZnkdERETkcqj8iBQDKdkpPPnrk6TlpNEsshmjWo2ynPXFphN8sekkNhtM79+ESuEW7hfKTIZ5A8GRATW6wLVPW55HRERE5HKp/IgUcU6Xk2dWPcOxlGNEBUUxtdNUfLx8LGVtP5HEuIV7ABhxQ2061Y40H2IYsHAQJB6GkArQ632w60eRiIiIXHn6F4dIETd923TWnl6Lv5c/M66bQXiAhR3ZgITULB6bvY1sp4sb65fh8U7VrQ20/m3YtxjsPtD3MwgMs5YjIiIiYpLKj0gRtvjwYj7e8zEAEzpMoE5YHUs5OU4XT8zZRlxKJtUjgpjSp7G1DQ6Or4dlY93H3SZDheaW5hERERGxQuVHpIjac24P49eNB+Chhg/RrUo3y1mTf9jPxqOJlPDz5r2BLQj2t3DZXFo8fHUfGE5ocAe0fNDyPCIiIiJWqPyIFEEJ6QkMWT6EbFc2nSp04ommT1jOWhh9mo/WHgVgSp/G1IgsYT7E6YCv74e0OChdG26dDlZWjkRERETyQOVHpIjJdmYzbMUw4tPjqRZajcnXTMZus/b/6nvPpDBy/k4ABnWuTrcGZa0NtXwSHFsNPkHQ73Pws1CgRERERPJI5UekCDEMgwkbJrAjYQfBvsHMuG4GJXytFY0L6dk8MnsLmTkurq0VwVNda1sbKmYJrJnqPu75JkRYzBERERHJI5UfkSJkzv45fHvoW+w2O1OunULlkMqWcpwugyFzozmZmEHFsABm9G+Cl93CZWqJR2HBI+7jVo9Ag96W5hERERHxBJUfkSJiQ+wGXtv8GgDDmw+nXfl2lrPeWHaAVQcS8Pex896AFpQM9DUfkpMJX93rfqBphZZww0TL84iIiIh4gsqPSBFwMuUkw1cMx2k46VG9BwPrDbSc9eOeON5afgiAl3s1ol65EGtBS0dC7A4IDIc+n4C3hQIlIiIi4kEqPyKF3MWciwxZPoSU7BQalW7E2LZjrT2DBzgUn8bwL3cA8J/2VbitaXlrQ0V/AVs/AWzQ+wMIrWAtR0RERMSDVH5ECjGX4eK51c9x6MIhIgIieKPzG/h5+VnKSs3M4ZHPt5CW5aBV1TCeu6mutaHO7oHvhrmPO42C6tdZyxERERHxMJUfkUJs5o6Z/HryV3ztvkzrPI3IwEhLOYZhMOKrHRxOuEjZEH/evqsZPl4WfjxkJsO8geDIgBpd4NqnLc0jIiIiciWo/IgUUsuOL+PdHe8CMK7dOBpFNLKc9c6Kw/y45yy+XnZmDmhGRLCF1SPDgIWDIPEwhFaEXu+DXT9iREREpODQv0xECqGYxBhGrxkNwMB6A+lRvYflrFUHEpjyUwwAL/SsT9NKpawFrX8b9i0Guw/0+RQCwyzPJCIiInIlqPyIFDJJmUk8ufxJMhwZtI1qy1PNn7KcdTIxncFfbMcwoH/LitzZqpK1oOPrYdlY93G3yVChueWZRERERK4UlR+RQiTHlcPwlcM5nXaaSsGVeK3ja3jbvS1lZWQ7efjzrSRn5NC4Ykle6Fnf2lBp8fDVfWA4oWEfaPmgtRwRERGRK0zlR6QQeXXTq2yO20yQTxAzrptBqF+opRzDMBj1zU72xaYQHuTLzLub4eftZT7I6YCv74e0OIioA7dOB4vbbIuIiIhcaSo/IoXE1we+Zm7MXGzYePmal6lesrrlrE/WHePb6DN42W28fXczypUMsBa0fBIcWw2+JaDv5+AbZHkmERERkStN5UekENh2dhuTNk4CYHDTwXSq2Mly1sYj55n4/T4AnrupLm2qhVsLilkCa6a6j3u8CRG1LM8kIiIicjWo/IgUcLFpsQxbMQyHy8GNVW7kwYbW76mJS85k0JxtOF0GPZuU4/72VawFJR6FBY+4j1s/Cg16WZ5JRERE5GpR+REpwDIcGTy5/EkSMxOpE1aHF9u9iM3iPTVZDiePzt7KubRs6pQN5uVejaxl5WTCV/e6H2haoSV0nWBpHhEREZGrTeVHpIAyDINxa8exL3EfYf5hTO88nUCfQMt5LyzeS/TJC4T4ezNrYAsCfC1scACw5BmI3QGB4dDnE/D2tTyTiIiIyNWk8iNSQH24+0OWHFuCt82bqZ2mUq5EOctZ8zafYM7GE9hsMOPOplQKt1iioufAtk8BG/T+AEIrWJ5JRERE5GpT+REpgFadWsWMbTMAGNV6FM3LWH9oaPTJCzz/7R4AhnetRafakdaC4nbDd8Pcx51GQfXrLM8kIiIikh9UfkQKmCMXjjBy1UgMDPrW6kvf2n0tZ51Ly+Kx2VvJdrroWq8Mj3eqYS0oMxm+HAiOTKjRBa592vJMIiIiIvlF5UekAEnOSmbI8iGk5aTRvExznm31rOUsh9PFE3O2EZucSbWIIKb2bYzdbmGDA8OAhYMg8QiEVoRe74NdPzpERESk8NG/YEQKCKfLychVIzmecpyooCimdpqKj5eP5bzJS/az4UgiQb5ezBrYnGB/i1nr34Z9i8HuA30+hcAwyzOJiIiI5CeVH5ECYtq2aaw9s5YA7wBmXDeDMH/rJWNh9Gk+XHMUgNf7NqZGZLC1oOPrYdlY93G3yVDB+r1HIiIiIvlN5UekAFh8eDGf7PkEgAntJ1AnrI7lrH2xKYycvxOAxztVp1uDKGtBafHw1X1gOKFhH2hp/eGqIiIiIgWByo9IPtt9bjfj140H4KGGD3FjlRstZyWn5/DI51vJzHFxTc3SDL+htrUgpwO+vh/S4iCiDtw6HSw+XFVERESkoDBdfk6fPs2AAQMIDw8nMDCQJk2asHXr1kves2/fPnr06EFoaCjBwcG0adOGEydO5L6elZXF4MGDKV26NEFBQfTo0YNTp07l/asRKWQS0hN48tcnyXZl06liJ55o+oTlLKfL4Ml52zmRmE6FUgHM6N8ULysbHAAsnwTHVoNvCej7OfgGWZ5LREREpKAwVX6SkpJo3749Pj4+LFmyhL179/L6669TsmTJ3PccPnyYDh06UKdOHVasWMGOHTt4/vnn8ff3z33P0KFDWbBgAXPnzmXNmjWkpaVxyy234HQ6PfaFXS3nM84THR+Nw+XI71GkkMl2ZjN0xVDiM+KpHlqdyR0mY7dZX4yd9vMBVsQk4Odt572BzSkV5GstKGYJrJnqPu7xJkTUsjyTiIiISEFiMwzDuNw3P/vss6xdu5bVq1f/7Xv69++Pj48Pn3/++V++npycTEREBJ9//jn9+vUD4MyZM1SsWJEffviBG2/890t+UlJSCA0NJTk5mZCQkMsd/4r4MuZLJmyYQAmfErQo24I2UW1oG9WWqqFVsekyIfkbhmEwdt1Yvj30LSG+IXxx8xdUCqlkOe+nPXE8/Ll7BfaNfo25vWkFa0GJR2FWR/dzfVo/Ct1fsTyTiIiIyNVgphuY+s/MixYtokWLFvTp04fIyEiaNm3K+++/n/u6y+Xi+++/p1atWtx4441ERkbSunVrvv3229z3bN26lZycHG644YbcvytXrhwNGjRg3bp1f/m5WVlZpKSkXPKnoMhwZBDiG0JaThorTq7g5U0v03NhT7p81YXRa0az+PBi4tPj83tMKWD+u++/fHvoW+w2O691fC1PxedwQhpPfbkDgPvaVbFefHIy4at73cWnQivoOsHyTCIiIiIFkanyc+TIEWbOnEnNmjX58ccfefTRRxkyZAifffYZAPHx8aSlpfHyyy/TrVs3fvrpJ26//XZ69erFypUrAYiLi8PX15dSpUpdkl2mTBni4uL+8nMnT55MaGho7p+KFSta+VqviHvr38uqfquYe8tchjYbSpuoNvjafYnPiGfR4UU8t+Y5rv/qem779jZe3vQyK06uIC07Lb/Hlny0/sx6pmyZAsDw5sNpV66d5ay0LAePfL6VtCwHraqEMfrmutYHW/IMxO6AwHDo8wl4W7xsTkRERKSAMnXZm6+vLy1atLhkhWbIkCFs3ryZ9evXc+bMGcqXL8+dd97JnDlzct/To0cPgoKC+OKLL5gzZw7/+c9/yMrKuiS7a9euVK9enXffffdPn5uVlXXJ+1NSUqhYsWKBuOztr2Q6MolOiGbDmQ1siN3A3vN7Mfjjf81eNi8alm5Im3JtaBPVhkalG+XpYZZSeJxMOUn/7/uTkp1Cj+o9mNh+ouXLIw3D4PH/bmPJ7jjKhPixeHAHIoP9//3EvxI9B759DLDBwG+g+nXWckRERESuMjOXvXmbCY6KiqJevXqX/F3dunWZP38+AKVLl8bb2/sv37NmzRoAypYtS3Z2NklJSZes/sTHx9Ou3V//F3A/Pz/8/PzMjJqv/L39aRPlLjYAyVnJbIrblFuGTqSeIDohmuiEaN7d8S4B3gG0KOO+X6hNuTbULFlT9wsVQRdzLjJk+RBSslNoVLoRY9uOzdP3eebKwyzZHYePl42ZA5pbLz5xu+G7Ye7jzs+p+IiIiEiRZar8tG/fnpiYmEv+7sCBA1SuXBlwrwy1bNnyH9/TvHlzfHx8WLZsGX379gUgNjaW3bt38+qrr1r+QgqyUL9QulbuStfKXQE4nXaajbEbc8tQUlYSq0+vZvVp90YS4f7htI5q7d48oVxbygaVzc/xxQNchotRq0dx6MIhIgIieKPzG/h5WS/0qw4kMOVH9/+fje9Rn2aVSv3LGX8jMxm+HAiOTKjRFa4ZYXkmERERkYLOVPkZNmwY7dq146WXXqJv375s2rSJWbNmMWvWrNz3PP300/Tr149rr72Wzp07s3TpUhYvXsyKFSsACA0N5YEHHmD48OGEh4cTFhbGiBEjaNiwIV26dPHoF1dQlS9Rnl41e9GrZi9chouDSQfZELuB9bHr2Rq3lfOZ5/nh6A/8cPQHAKqEVKF1VGvaRrWlZVRLQnwL3qV+8s/eiX6H5SeX42v3ZXrn6UQGRlrOOpmYzpC523EZ0K9FRe5qZXGzBMOAhYMg8QiEVoRes8Cu5x6LiIhI0WXqnh+A7777jlGjRnHw4EGqVq3KU089xUMPPXTJez766CMmT57MqVOnqF27Ni+88AI9e/bMfT0zM5Onn36aOXPmkJGRwfXXX88777xz2RsZFKStrj0t25nNjoQdbIh1rwrtPrcbl+HKfd1us1M/vH7uZXVNIpvg66Ub0wuyn479xPCVwwGY1GESPar3sJyVke2k98x17I1NoXGFUOY90hZ/Hy9rYevehJ/GgN0H7v8RKjS3PJeIiIhIfjHTDUyXn4KgKJef/y8lO4UtcVtyy9DR5KOXvO7v5U+zMs1yy1DtsNp5elCmeFZMYgwDlwwkw5HBPfXu4emWT1vOMgyD4V/u4JvtpwkP8mXx4A6UKxlgLez4OvjkFjCccNMUaPXQv58jIiIiUgCp/BRhcRfj3PcL/VaGzmWcu+T1Un6laBXVKrcMVQi2+MwXybPEzETu/O5Ozlw8Q7ty7Xj7+rfxtpu60vQSn6w9yvjFe/Gy2/j8gVa0q17aWlDqWXjvWkiLg4Z9oNf7oA02REREpJBS+SkmDMPg8IXDuUVoc9xm0h3pl7ynQokKuVtqty7bmpL+JfNn2GImx5XDwz89zJazW6gUXIk5N88h1C/Uct6mo4nc9f4GHC6DMTfX5cFrqlkLcjrg89vg2GqIqAMP/Qq+QZbnEhEREclvKj/FVI4rh10Ju9gQu4GNsRvZmbATh+HIfd2GjbrhdXNXhZpGNsXf2+L2yPKPJm6YyLyYeQT5BDHnpjlUK2mxrABxyZnc8uYazqVlcWvjcszo38T6Ftk/j4c1b4BvCXhoOUTUsjyXiIiISEGg8iOA+7kyW89uZf2Z9WyI3cChC4cued3X7kvTMk3dW2pHtaVOWB287BZvnpdcXx34ihfXv4gNGzOum0Gnip0sZ2U5nPSftYHtJy5Qp2ww3zzejkBfi5fO7f8B5t7pPr7jY2jQy/JcIiIiIgWFyo/8pYT0hNxL5DbEbiA+Pf6S10N8Q3KfL9Qmqg0VgyvqYasmbTu7jQd+egCHy8GQpkN4qFHeNhIYvWAX/914ghB/bxYP7kDlcIuXqCUehVkd3c/1af0odH8lT3OJiIiIFBQqP/KvDMPgaMrR3Aetbo7bTFpO2iXvKRdULvd+oVZlWxEeEJ5P0xYOsWmx9P++P4mZiXSr0o1Xr301T+Xxy80neWb+Tmw2+Oi+lnSubfHZQDmZ8NENELsDKrSC+74Hb22PLiIiIkWDyo+Y5nA52HN+T24Zik6IxuFyXPKe2qVqu1eFyrWhWWQzAn0C82nagifDkcG9S+5lX+I+6obV5dPunxLgbXEbamDHyQv0eXc92U4XT3WtxZDra1ofbtEQ2PYpBIbDI6shtLz1LBEREZECRuVH8iw9J51t8dtyy1BMUswlr3vbvWkS0SS3DNUPr5+nbZwLM8MweGbVMyw9tpQw/zDm3jyXqBJRlvPOpWVx65triE3OpEvdMswa2By73eIKUvQc+PYxwAYDv4Hq11meS0RERKQgUvkRjzufcZ5NcZvYELuB9WfWE3sx9pLXS/iUoGXZlrllqGpI1WJzv9AHuz5g+rbpeNu8+eDGD2heprnlLIfTxYAPN7LhSCLVSgfx7RPtCfH3sRYWtxs+uB4cmdB5NHR8xvJcIiIiIgWVyo9cUYZhcDL1ZO7GCRtjN5KSnXLJeyIDI3M3TmgT1YaIwIh8mvbKWnlyJYN/HYyBwfNtnqdv7b55ypv0/V7eX32UIF8vvh3Unpplgq0FZSbDrE6QeARqdIW7vgS7PU+ziYiIiBREKj9yVTldTvYn7md9rHtL7e1nt5Ptyr7kPTVK1sgtQi3KtiDIp/A/WPPIhSPc9cNdXMy5SL/a/RjTZkye8hbtOMOQL7YDMPPuZnRvaPHSOcOALwfCvsUQWhEeWQWBYXmaTURERKSgUvmRfJXpyGR7/PbclaF95/dh8Mf/mXnbvGkY0TC3DDWMaIiP3eKlXfkkOSuZu3+4m+Mpx2lepjnv3/B+nr6GfbEp9HpnHRk5Th7rVJ2R3epYH27dm/DTGPDyhfuXQnnrl+GJiIiIFHQqP1KgXMi8kHu/0IbYDZxMPXnJ64HegbQo2yK3DNUoWaNA3y/kdDkZ9Msg1p5ZS7mgcnxxyxeE+VtfWUlOz6HH22s4fj6da2qW5pP/tMLL6gYHx9fBJ7eA4YSbX4eWD1qeS0RERKQwUPm5is6mZLLzVDLtqocT5Fc8dzsz61TqKTbGbsy9XygpK+mS10sHlL7kYatlg8rm06R/bcrmKXy6172V9efdP6d2WG3LWS6XwQOfbmZ5TALlSwbw3eAOlAqy+Aye1LPw3rWQFgcN+0KvWVCAS6SIiIiIJ6j8XEWfrD3K+MV78fWy06pqGJ1qR9CpdgTVI0oU6NWLgsJluDiQdCB3S+2tZ7eS6cy85D1VQqrk7iLXsmxLQnzz73u++PBinlvzHABTOk7hxio35ilv6k8xzPj1EH7eduY/1o4G5UOtBTkd8PltcGw1RNSFh34B38J/X5WIiIjIv1H5uYpmbzjOe6sOczIx45K/L18ygM51IuhUK5J2NcIJ9NWq0OXIdmazI2EH68+sZ2PsRnaf343LcOW+brfZaRDegNZRrWlbri2NIxrj62VxpcSkXQm7uG/pfWS7snm40cMMbjo4T3nL9p7loc+2ADC1b2N6NatgPezn8bDmDfAtAQ+vgNJ5eCiqiIiISCGi8nOVGYbBkXMXWb4/npUHEth4JJFs5x//YL90VSiS6hFBWhW6TCnZKWyO25y7MnQs5dglr/t7+dO8TPPclaFapWpht3l+S+eE9AT6f9ef+Ix4OlXsxPTO0/P0OYcT0rjtrbWkZjm4r10Vxveob324/T/A3Dvdx3d8DA16Wc8SERERKWRUfvJZeraD9YfPsyImgeUx8ZxKunRVqEKpADrVjqBz7UjaVteqkBlxF+NyN07YcGYD5zPPX/J6Kb9Sf9wvVK4N5UuUz/NnZjmzuP/H+9mZsJPqodWZfdNsSviWsJyXluXg9rfXcjA+jZZVSjHnoTb4eFksUolH4b2OkJUMrR+F7q9YnktERESkMFL5KUAMw+BwwkVWxPz9qlDramF0rKVVIbMMw+DQhUO5ZWhz3GYyHJcWzYrBFXM3TmhVthUl/Uua/ozn1z7PwsMLCfENYe7Nc6kYUjFPMw+as40fdsURGezHd0M6EBnsby0sJxM+7ApxO6FCK7jve/C+OpcAioiIiBQUKj8F2MWs31aFDsSzIibhT6tCFcMC6FQrkk61I7QqZFKOM4dd53bllqGdCTtxGs7c123YqBteN7cMNSvTDD8vv3/MnL13Nq9sfgW7zc67Xd6lbbm2eZpx5orDvLJ0Pz5eNuY+3JbmlUtZD1s0GLZ9BoHh8MhqCM37KpeIiIhIYaPyU0i4V4XSWBGTwIqYBDYd/X+rQt52WlcNo1NtdxmqVlqrQmakZaex9ezW3DJ06MKhS1738/KjaWTT3Evk6pSqg5fdK/f19WfW89jPj+E0nDzT8hkG1huYp3lWH0zg3o824TJg4m0NGNCmsvWw7f+FhY8DNhj4DVS/Lk+ziYiIiBRWKj+F1O+rQstj3KtCpy/8eVWo829FqG210gT4ev1NkvyVhPSEP+4Xit1AfHr8Ja+H+oXSqmwr2kS1oWpoVYYuH0pKdgo9q/dkQvsJeSqeJxPTufWtNVxIz6Fviwq80ruR9by4XfBBF3BkQufR0PEZy3OJiIiIFHYqP0XA/64KLY+JZ9PRRHKcf3yr/ndVqHPtCKpqVcgUwzA4mnI0dxe5zXGbSctJ+9P7GpVuxEfdPvrXy+P+SWaOk94z17HnTAqNKoTy5SNt8fexWFwzk2FWJ0g8AjW6wl1fgt3zu9uJiIiIFBYqP0XQxSwH6w6fZ8XfrApVCgvM3UGuTbVwrQqZ5HA52HN+T24Zik6IpkxgGT7v/jkRgRGWcw3DYPhXO/hm22nCgnxZPLgD5UsGWA2DeQNg/3cQWhEeWQWBYZZnExERESkKVH6KOMMwOBT/271CB/56VahNtXA61Yqgc51IqpYOysdpC6dMRyZ2mz3PD1D9dN0xxi3ag90Gsx9oTbsapa2HrXsTfhoDXr5w/1Io3zxPs4mIiIgUBSo/xUxaloN1h86x4kACK/9iVahyeCCdfttKW6tCV8/mY4ncOWsDDpfB6Jvq8tC11ayHHV8Hn9wChhNufh1aPui5QUVEREQKMZWfYswwDA7Gp+VeHrf52KWrQn6/rwrVdpchrQpdGWdTMrnlzTUkpGZxS6Mo3ryzqfV7slLPwnvXQlocNOwLvWaB7u8SERERAVR+5H/8viq0PCaBlTHxnEnOvOT1yuGBdK4dScfaEbStFm79RnzJle1w0X/WeraduEDtMsEsGNTO+vOanA74/DY4thoi6sJDv4CvCquIiIjI71R+5C/976rQ8v0JbDn+96tCnWtHUkWrQpaM+XYXszecIMTfm0VPdMjb/x5/Hg9r3gDfEvDwCihd01NjioiIiBQJKj9yWdKyHKw9dI4Vf7MqVCU8MPcBq220KnRZvtxykme+3onNBh/d25LOdSKth+3/Aebe6T7u8wnUv90jM4qIiIgUJSo/YpphGBw4e+m9Qg7XpatCbauH526coFWhP9t56gJ3vLuebIeLYV1q8WSXPKzSJB6F9zpCVjK0fgy6v+y5QUVERESKEJUfybPUzBzWHjrPygPuMhT7/1aFqpYOomOtCK0K/eZ8Wha3vrmGM8mZdKkbyayBLbDbLW5KkJMJH3aFuJ1QoRXc9z14523LbREREZGiSuVHPMowDGLOprqfKxQTz5ZjSZesCvn72GlbLTz3ErnK4cVrVcjhdHHPR5tYd/g8VUsHsfCJ9oT4+1gPXDQYtn0GgeHwyGoILe+5YUVERESKGJUfuaJ+XxX6/RK5uJQ/rwr9vpV266phRX5V6KUf9jFr1RECfb34dlB7apUJth62/b+w8HHABgMXQPXOHptTREREpChS+ZGr5n9XhZbvj2fr8b9fFepcO5JK4YH5OK3nLd5xhsFfbAfgnbubcVPDKOthcbvggy7gyITOY6Dj0x6aUkRERKToUvmRfONeFTr32yVyf14VqlY6iI6/baXdqpCvCu2PS+H2t9eRkePkkY7VGNW9rvWwzGSY1QkSj0CNrnDXl2C3e2xWERERkaJK5edqunASjiyHWt2gRB62NS6CDMNgf9wf9wr9/1WhAB8v9w5ytSPoVKtwrQolZ+TQ4601HD+fTocapfnkPy3x9rJYVgwD5g2A/d9BaEV4ZBUEhnl2YBEREZEiSuXnalr3Jvw0BrBBhZZQuzvUuRlK1wKbxd2+iqiUzBzWHvxtVehAPGdTsi55vVpEEJ1quTdNKMirQi6XwQOfbmZ5TALlSwaweHAHwoLysBvb2hmw7Hnw8oX7l0L55p4bVkRERKSIU/m5mnbMg40z4cz2S/8+rBrUvsn9p2Jr8PLOn/kKKMMw2BebyorfttLeejwJ5/9bFWr3+6pQ7UgqhhWcVaE3lh1g+i8H8fO2M/+xdjQoH2o97Nha+PRWMJxw8+vQ8kHPDSoiIiJSDKj85IeUMxCzxP3n6EpwZv/xWkAY1LrRXYSqXwd+JfJvzgLq91Wh5b/tIBef+udVoc61/1gV8vPOn1Whn/ee5cHPtgAwpU9j7mhewXpY6ll47xpIOwsN+0KvWVotFBERETFJ5Se/ZaXC4V9h/w9w8EfISPrjNS8/qNbRfXlcre4QkofdwYqoS1aF9iew9UTBWBU6kpBGz7fWkprl4J62lXmxZwPrYU4HfNYTjq+BiLrw0C/gW7yejyQiIiLiCSo/BYnTASc3uFeE9n8PSUcvfb1cM6jz2+VxkfX0X/7/QnLG7zvI/fWqUPWIoNwHrF6pVaGLWQ5ue3stB+PTaFG5FHMeaoOvdx52Y1s2DtZOA98S8PAKKF3TU6OKiIiIFCsqPwWVYUBCDMR87y5DpzZf+nrJyr/dJ9QdKrcDL5/8mbMAMwyDvbEprIhJYGXMn1eFAn3dq0Ida0fSqVaER1aFDMNg0Jxt/LArjshgP74b3IHIEH/rgft/gLl3uo/7fAL1b8/zjCIiIiLFlcpPYZF6Fg4shZgf4MgK98Mtf+cfCjVvcJehGl3AvxB/nVdQckYOaw66V4VWHvjzqlCNyBJ0quW+PK5l1VKWVoXeW3mYyUv24+NlY+7DbWheOQ/bUCcehfc6QlYytH4Mur9sPUtEREREVH4KpeyLcHi5e0XowBJIP//Ha3YfqHrNH6tCoXm4yb4I+99VoRUx8Ww7ceEvVoVK/3avUAQVSv37qtCag+e456ONuAyYcFsDBrapbH3AnEz4sCvE7YQKreC+78E7D1tki4iIiIjKT6HncroviYv5wX2J1PmDl75etpH7WUK1u7uPdZ/QX0pOz2HNIfcOcisPJJDwF6tCnX/bNKFFlT+vCp1MTKfHW2tISs/hjuYVeO2ORtjy8r/rRYNh22cQGA6PrIbQ8tazRERERARQ+Sl6zh10F6GYJXBiA/A/37KQCr89WPUmqNxBKwl/w+VyrwqtPJDA8v3xbDuRxP8sCv1pVah0CT/ueHcdu0+n0LB8KF892jZvD13d/l9Y+Dhgg4ELoHrnPH9NIiIiIqLyU7RdPAcHfnSXocO/Qk76H6/5hbjvD6p9E9TsCgEl823Mgi45PYfVhxLcGyf8xapQeJAv5y9mExbky+LBHShfMsD6h8Xtgg+6uO/p6jwGOj6dx+lFRERE5HcqP8VFTgYcWfnHqtDF+D9es3u7d4yr/ds22qXycK9KEff7qtDvW2n/vipkt8HsB1rTrkZp6+GZyTCrEyQecW9gcec8sOdhi2wRERERuYTKT3HkcsGZbe5nCcUsgYR9l74eWf+35wl1h6im+gf4P7iQns26w+eJCPajZZU87OxmGDBvAOz/DkIrwSMrITAPeSIiIiLyJyo/4l5piFni3jDhxDowXH+8FhwFtbq5N02ocg345OGZNfL31s6AZc+Dly/c/yOUb5bfE4mIiIgUOSo/cqn0RDj4k/vyuEO/QHbaH6/5BEGN692XxtW6USsTnnJsLXx6KxhOuHkqtHwgvycSERERKZJUfuTvObLg6GqI+e3yuNTYP16z2aFS2z+eJxRePf/mLMxSz8J710DaWWjUD25/T9uRi4iIiFwhKj9yeQwDYqPdl8bFLIGzuy59vXTt3+4TugnKt9B9QpfD6YDPesLxNRBRFx76BXyD8nsqERERkSJL5UesSToOB5a6N004vhZcjj9eC4p0XxZX52ao1gl88rD1c1G2bBysnQa+JeDhFVC6Zn5PJCIiIlKkqfxI3mVcgEM/u+8TOrgMslL+eM07AKpf5740rlY3KBGRb2MWKPt/gLl3uo/7fAL1b8/XcURERESKA5Uf8SxHtnsl6PfnCSWf/J8XbVCx1R/PE4qolW9j5qvEI/BeJ8hKhtaPQfeX83siERERkWJB5UeuHMOAuF3uEhTzPcTuuPT18BruFaHaN7tLkd0rf+a8mnIy4MOu7v+9VGgF930P3r75PZWIiIhIsaDyI1dP8uk/VoSOrgJXzh+vBYa7L4ur3d19mVxRvfF/4ROw/XP31/vIaggtn98TiYiIiBQbKj+SPzJT4PAv7iJ04EfIvPDHa15+7o0S6tzkLkTBZfNrSs/aPhsWDgJsMHABVO+c3xOJiIiIFCsqP5L/nDlwYoN7VWj/93Dh+KWvl2/+x31CkXUL53NwYne6L3dzZELnMdDx6fyeSERERKTYUfmRgsUwIH7fb5fH/QCnt176eqkqfxShSm3ByztfxjQlMxne6whJR6HmDXDnPD0HSURERCQfqPxIwZYa99uGCUvgyApwZv3xmn9J9/OEaneHGl3ALzi/pvx7hgHzBsD+7yC0EjyyEgLD8nsqERERkWJJ5UcKj6w0OLL8t/uElkL6+T9e8/KFKtf8dp9Q94KzkcDaGbDsefd89/8I5Zvl90QiIiIixZbKjxROLiec3OTeQnv/D5B4+NLXo5q4L42rcxOUaZA/9wkdWwuf3gqGE26eCi0fuPoziIiIiEgulR8pGhIO/HGf0MlNwP/8n2popd+eJ9QdqnQAL58rP0/qWXjvGkg7C436we3vFc6NGkRERESKEJUfKXrSEtyXxcUsgcO/giPjj9f8QqFmF/eqUI0uEFDS85/vdMBnPeH4GoioCw/9UnSfWyQiIiJSiKj8SNGWnQ5HV7q30D6wFC4m/PGa3du9ElT7JveqUMlKnvnMZeNg7TTwDYaHl0Ppmp7JFREREZE8UfmR4sPlgtNbfrs8bgkk7L/09TIN3SWozk3ue4asXKa2/weYe6f7uM+nUP+2vE4tIiIiIh6i8iPF1/nDv22j/QOcWA+G64/Xgsv9dp/QTVD1GvD2+/e8xCPwXifISoY2j0O3yVdsdBERERExT+VHBCA9EQ786C5Ch36BnIt/vOZbAmpcD7Vvhppd//o5PTkZ8GFXiNsFFVvDfd9fnY0VREREROSyqfyI/H85mXBstfs+oZglkBb3x2s2L6jc7o9VobCq7r9f+ARs/xwCS8OjqyGkXP7MLiIiIiJ/S+VH5J+4XBC73V2C9v8A8XsufT2iLpRtALu+ApsdBi6Aap3yZVQRERER+WcqPyJmJB374z6hY2vdDzD93XVj4Nqn8200EREREflnZrqB91WaSaTgKlUF2jzm/pORBAd/hoM/QnBZ6DA8v6cTEREREQ9R+RH5XwGloFEf9x8RERERKVLs+T2AiIiIiIjI1aDyIyIiIiIixYLKj4iIiIiIFAsqPyIiIiIiUiyo/IiIiIiISLGg8iMiIiIiIsWCyo+IiIiIiBQLKj8iIiIiIlIsqPyIiIiIiEixoPIjIiIiIiLFgsqPiIiIiIgUCyo/IiIiIiJSLKj8iIiIiIhIsaDyIyIiIiIixYLKj4iIiIiIFAsqPyIiIiIiUiyo/IiIiIiISLGg8iMiIiIiIsWCyo+IiIiIiBQLKj8iIiIiIlIsqPyIiIiIiEixoPIjIiIiIiLFgsqPiIiIiIgUCyo/IiIiIiJSLKj8iIiIiIhIsaDyIyIiIiIixYLKj4iIiIiIFAsqPyIiIiIiUiyo/IiIiIiISLGg8iMiIiIiIsWCyo+IiIiIiBQLKj8iIiIiIlIseOf3AFYYhgFASkpKPk8iIiIiIiL56fdO8HtH+CeFsvykpqYCULFixXyeRERERERECoLU1FRCQ0P/8T0243IqUgHjcrk4c+YMwcHB2Gy2/B6HlJQUKlasyMmTJwkJCcnvccQD9D0tevQ9LZr0fS169D0tmvR9LXoK0vfUMAxSU1MpV64cdvs/39VTKFd+7HY7FSpUyO8x/iQkJCTfv/niWfqeFj36nhZN+r4WPfqeFk36vhY9BeV7+m8rPr/ThgciIiIiIlIsqPyIiIiIiEixoPLjAX5+fowbNw4/P7/8HkU8RN/Tokff06JJ39eiR9/Toknf16KnsH5PC+WGByIiIiIiImZp5UdERERERIoFlR8RERERESkWVH5ERERERKRYUPkREREREZFiQeUnD1atWsWtt95KuXLlsNlsfPvtt/k9kuTR5MmTadmyJcHBwURGRnLbbbcRExOT32NJHsycOZNGjRrlPoStbdu2LFmyJL/HEg+aPHkyNpuNoUOH5vcokgfjx4/HZrNd8qds2bL5PZbk0enTpxkwYADh4eEEBgbSpEkTtm7dmt9jiQn/9O/dnJwcRo4cScOGDQkKCqJcuXLcc889nDlzJv8G/hcqP3lw8eJFGjduzFtvvZXfo4iHrFy5kkGDBrFhwwaWLVuGw+Hghhtu4OLFi/k9mlhUoUIFXn75ZbZs2cKWLVu47rrr6NmzJ3v27Mnv0cQDNm/ezKxZs2jUqFF+jyIeUL9+fWJjY3P/7Nq1K79HkjxISkqiffv2+Pj4sGTJEvbu3cvrr79OyZIl83s0MeGf/r2bnp7Otm3beP7559m2bRvffPMNBw4coEePHvkw6eXRVtceYrPZWLBgAbfddlt+jyIelJCQQGRkJCtXruTaa6/N73HEQ8LCwnjttdd44IEH8nsUyYO0tDSaNWvGO++8w8SJE2nSpAnTpk3L77HEovHjx/Ptt98SHR2d36OIhzz77LOsXbuW1atX5/co4iGX8+/dzZs306pVK44fP06lSpWu3nCXSSs/Iv8gOTkZcP9jWQo/p9PJ3LlzuXjxIm3bts3vcSSPBg0axM0330yXLl3yexTxkIMHD1KuXDmqVq1K//79OXLkSH6PJHmwaNEiWrRoQZ8+fYiMjKRp06a8//77+T2WXGHJycnYbLYCu8Kn8iPyNwzD4KmnnqJDhw40aNAgv8eRPNi1axclSpTAz8+PRx99lAULFlCvXr38HkvyYO7cuWzbto3Jkyfn9yjiIa1bt+azzz7jxx9/5P333ycuLo527dpx/vz5/B5NLDpy5AgzZ86kZs2a/Pjjjzz66KMMGTKEzz77LL9HkyskMzOTZ599lrvuuouQkJD8Hucveef3ACIF1RNPPMHOnTtZs2ZNfo8ieVS7dm2io6O5cOEC8+fP595772XlypUqQIXUyZMnefLJJ/npp5/w9/fP73HEQ7p375573LBhQ9q2bUv16tX59NNPeeqpp/JxMrHK5XLRokULXnrpJQCaNm3Knj17mDlzJvfcc08+TyeelpOTQ//+/XG5XLzzzjv5Pc7f0sqPyF8YPHgwixYtYvny5VSoUCG/x5E88vX1pUaNGrRo0YLJkyfTuHFjpk+fnt9jiUVbt24lPj6e5s2b4+3tjbe3NytXrmTGjBl4e3vjdDrze0TxgKCgIBo2bMjBgwfzexSxKCoq6k//kalu3bqcOHEinyaSKyUnJ4e+ffty9OhRli1bVmBXfUArPyKXMAyDwYMHs2DBAlasWEHVqlXzeyS5AgzDICsrK7/HEIuuv/76P+0C9p///Ic6deowcuRIvLy88mky8aSsrCz27dvHNddck9+jiEXt27f/0+MiDhw4QOXKlfNpIrkSfi8+Bw8eZPny5YSHh+f3SP9I5ScP0tLSOHToUO7/fPToUaKjowkLCyuQu1vIvxs0aBBz5sxh4cKFBAcHExcXB0BoaCgBAQH5PJ1Y8dxzz9G9e3cqVqxIamoqc+fOZcWKFSxdujS/RxOLgoOD/3QfXlBQEOHh4bo/rxAbMWIEt956K5UqVSI+Pp6JEyeSkpLCvffem9+jiUXDhg2jXbt2vPTSS/Tt25dNmzYxa9YsZs2ald+jiQn/9O/dcuXKcccdd7Bt2za+++47nE5n7r+dwsLC8PX1za+x/54hli1fvtwA/vTn3nvvze/RxKK/+n4Cxscff5zfo4lF999/v1G5cmXD19fXiIiIMK6//nrjp59+yu+xxMM6duxoPPnkk/k9huRBv379jKioKMPHx8coV66c0atXL2PPnj35PZbk0eLFi40GDRoYfn5+Rp06dYxZs2bl90hi0j/9e/fo0aN/+2+n5cuX5/fof0nP+RERERERkWJBGx6IiIiIiEixoPIj8n/t3F1IVFsbB/D/PjYqo6N9WGY1VjaGQ1SmllhCdJOagoiUQYWmXWiI0ZcGNqmYIZJEF3ZjzoyIOoSZRSJGUUSJ0FAWlESaH11ITdmN+TXoei/O66bt6NFzXk/Gu/8/2DB7rWc961mXj2sjEREREakCmx8iIiIiIlIFNj9ERERERKQKbH6IiIiIiEgV2PwQEREREZEqsPkhIiIiIiJVYPNDRERERESqwOaHiIh+S5IkoampacHzWq1WLF26dMHzzkdhYSFCQ0MXZW8iImLzQ0REP0lLS4MkScjMzHSZO3nyJCRJQlpa2oLu+W80BHV1dXBzc5vxHEREpF5sfoiISEGv18Nms2FkZEQeGx0dRX19PQIDAxexsvkzm83Izc2FzWbD8PDwYpdDRES/CTY/RESkEBYWhsDAQDQ2NspjjY2N0Ov12LFjhyJ2bGwMOTk5WLVqFTw9PREdHY0XL17I80+ePIEkSXj06BEiIiKg1Wqxe/duvH//HsCfn6AVFRXh9evXkCQJkiTBarXK679+/YqkpCRotVoEBwfj3r17c9bf29uLtrY2XLhwASEhIWhoaJgxrrW1FUajEd7e3oiNjcXAwIBi3mKxwGg0wtPTEyEhIbhx44ZiPi8vD5s3b4ZWq0VQUBBMJhOcTqciprS0FP7+/tDpdMjIyMDo6Oic9RMR0b+HzQ8REbk4fvw4LBaL/G42m5Genu4Sl5ubi9u3b6O6uhovX76EwWBATEwMBgcHFXH5+fkoLy+H3W7HkiVL5FwpKSk4e/YstmzZgoGBAQwMDCAlJUVeV1RUhEOHDuHNmzc4cOAAjhw54pJ7OrPZjPj4ePj6+uLo0aOoqqpyiRkeHsbVq1dRU1ODp0+for+/H+fOnZPnKysrkZ+fj5KSEnR2duLKlSswmUyorq6WY3Q6HaxWK969e4fr16+jsrIS165dk+dv3bqFgoIClJSUwG63IyAgwKWBIiKiX0wQERH9V2pqqkhMTBQOh0N4eHiInp4e0dvbKzw9PYXD4RCJiYkiNTVVCCHE0NCQ0Gg0ora2Vl4/Pj4u1qxZI8rKyoQQQjx+/FgAEA8fPpRjmpubBQAxMjIihBCioKBAbN++3aUWAOLixYvy+9DQkJAkSbS0tMxa/8TEhNDr9aKpqUkIIYTD4RAajUZ8+PBBjrFYLAKA6OrqkscqKiqEv7+//K7X60VdXZ0id3FxsYiKipp177KyMhEeHi6/R0VFiczMTEVMZGTkjGclIqJfgzc/RETkws/PD/Hx8aiurobFYkF8fDz8/PwUMd3d3XA6ndizZ488ptFosGvXLnR2dipit23bJv8OCAgAAHz58mXOOn5e5+XlBZ1O95frHjx4gB8/fiAuLk4+x/79+2E2mxVxWq0WmzZtUtQ0ldfhcODTp0/IyMiAt7e3/Fy+fBnd3d3ymoaGBkRHR2P16tXw9vaGyWRCf3+/PN/Z2YmoqCjFvtPfiYjo11qy2AUQEdHvKT09HdnZ2QCAiooKl3khBIA//yX19PHpYxqNRv49NTc5OTlnDT+vm1r7V+vMZjMGBweh1WrlscnJSbx69QrFxcVwc3ObNe/UeabyV1ZWIjIyUhE3tb69vR2HDx9GUVERYmJi4OvrC5vNhvLy8jnPREREi4c3P0RENKPY2FiMj49jfHwcMTExLvMGgwHu7u549uyZPOZ0OmG322E0Gue9j7u7OyYmJv7ner99+4a7d+/CZrOho6ND8QwNDaGlpWVeefz9/bF27Vp8/PgRBoNB8WzcuBEA8Pz5c6xfvx75+fmIiIhAcHAw+vr6FHmMRiPa29sVY9PfiYjo1+LNDxERzcjNzU3+fG3qxuNnXl5eyMrKwvnz57F8+XIEBgairKwMw8PDyMjImPc+GzZsQE9PDzo6OrBu3TrodDp4eHj87XpramqwYsUKHDx4EH/8ofzbXkJCAqqqqpCQkDCvXIWFhcjJyYGPjw/i4uIwNjYGu92O79+/48yZMzAYDOjv74fNZsPOnTvR3NyMO3fuKHKcOnUKqampiIiIQHR0NGpra/H27VsEBQX97bMREdHC4M0PERHNysfHBz4+PrPOl5aWIjk5GceOHUNYWBi6urrQ2tqKZcuWzXuP5ORkxMbGYt++fVi5ciXq6+v/Ua1msxlJSUkujc/UHvfv38fnz5/nlevEiRO4efMmrFYrtm7dir1798Jqtco3P4mJiTh9+jSys7MRGhqKtrY2mEwmRY6UlBRcunQJeXl5CA8PR19fH7Kysv7R2YiIaGFIYuojZyIiIiIiov9jvPkhIiIiIiJVYPNDRERERESqwOaHiIiIiIhUgc0PERERERGpApsfIiIiIiJSBTY/RERERESkCmx+iIiIiIhIFdj8EBERERGRKrD5ISIiIiIiVWDzQ0REREREqsDmh4iIiIiIVOE/gGFJpS7zdyoAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Concatenate all dataframes by identical columns\n",
    "\n",
    "df=pd.concat([outcome1, outcome2,outcome3,outcome4,outcome5,outcome6,outcome12])\n",
    "# df=pd.concat([outcome6,outcome12])\n",
    "\n",
    "insert_index = 0\n",
    "insert_colname = 'Asset'\n",
    "insert_values = ['Options','Options','Options','Options','Options','Options','Options'] # this can be a numpy array too\n",
    "# insert_values = ['Options','Options'] # this can be a numpy array too\n",
    "df.insert(loc=insert_index, column=insert_colname, value=insert_values)\n",
    "\n",
    "\n",
    "insert_index = 1\n",
    "insert_colname = 'Product'\n",
    "insert_values = [sheet,sheet,sheet,sheet,sheet,sheet,sheet] # this can be a numpy array too\n",
    "# insert_values = [sheet,sheet] # this can be a numpy array too\n",
    "df.insert(loc=insert_index, column=insert_colname, value=insert_values)\n",
    "\n",
    "insert_index = 2\n",
    "insert_colname = 'Month Ahead'\n",
    "insert_values = ['1','2','3','4','5','6','12'] # this can be a numpy array too\n",
    "# insert_values = ['6','12'] # this can be a numpy array too\n",
    "df.insert(loc=insert_index, column=insert_colname, value=insert_values)\n",
    "\n",
    "globals()[sheet] = df\n",
    "\n",
    "import matplotlib.pyplot as mp\n",
    "df.plot(title=sheet,x='Month Ahead',y=[\"Prediction\",\"95%CI.Min\",\"95%CI.Max\"],kind=\"line\",figsize=(10,10))\n",
    "mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'__name__': '__main__',\n '__doc__': 'Automatically created module for IPython interactive environment',\n '__package__': None,\n '__loader__': None,\n '__spec__': None,\n '__builtin__': <module 'builtins' (built-in)>,\n '__builtins__': <module 'builtins' (built-in)>,\n '_ih': ['',\n  \"# sheet='C1'\\n# sheet='C2'\\n# sheet='BYX'\\n# sheet='BZX'\\n# sheet='EDGA'\\n# sheet='EDGX_Equities'\\nsheet='EXO_EDGX_Options'\\n# sheet='OPT_BZX_BATS'\\n# sheet='CFE'\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\n\\nimport io\\nimport datetime\\n\\n# sheet='C1'\\n# sheet='C2'\\n# sheet='BYX'\\n# sheet='BZX'\\n# sheet='EDGA'\\n# sheet='EDGX_Equities'\\n# sheet='EXO_EDGX Options'\\n# sheet='OPT_BZX BATS'\\n# sheet='CFE'\\n\\n#load ensemble\\nimport os\\nfrom keras.models import load_model\\n\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # encoder = LabelEncoder()\\n# # # # print(values[:,0]) #PortQyt Value\\n# # values[:,0]=encoder.fit_transform(values[:,0])\\n# # print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1))* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+5):-n_features*(1+5)+1]\\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+5):-n_features*(1+5)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n\\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\n\\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble, model\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n\\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0]\\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome1= pd.DataFrame(outcome)\\noutcome1\",\n  \"from os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '1',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '1','model_corr.h5'))\",\n  \"from math import sqrt\\nimport numpy as np\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1))* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+4):-n_features*(1+4)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+4):-n_features*(1+4)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome2= pd.DataFrame(outcome)\\noutcome2\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '2',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '2','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+3):-n_features*(1+3)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+3):-n_features*(1+3)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome3= pd.DataFrame(outcome)\\noutcome3\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '3',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '3','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n# #\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+2):-n_features*(1+2)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+2):-n_features*(1+2)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome4= pd.DataFrame(outcome)\\noutcome4\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '4',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '4','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\nm=6-5\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome5= pd.DataFrame(outcome)\\noutcome5\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '5',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '5','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\nm=6-6\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome6= pd.DataFrame(outcome)\\noutcome6\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '6',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '6','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='OPT_BZX BATS'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # encoder = LabelEncoder()\\n# # # # print(values[:,0]) #PortQyt Value\\n# # values[:,0]=encoder.fit_transform(values[:,0])\\n# # print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\n# n_months = 11\\nn_months = 23\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\nm=6-6\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months =17\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1)//2)* n_features #the following 12\\n# n_obs = (n_months+1)* n_features #the following \\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1)//2, n_features))\\n# train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1)//2, n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome12= pd.DataFrame(outcome)\\noutcome12\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '12',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '12','model_corr.h5'))\",\n  '#Concatenate all dataframes by identical columns\\n\\ndf=pd.concat([outcome1, outcome2,outcome3,outcome4,outcome5,outcome6,outcome12])\\n# df=pd.concat([outcome6,outcome12])\\n\\ninsert_index = 0\\ninsert_colname = \\'Asset\\'\\ninsert_values = [\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\'] # this can be a numpy array too\\n# insert_values = [\\'Options\\',\\'Options\\'] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\n\\ninsert_index = 1\\ninsert_colname = \\'Product\\'\\ninsert_values = [sheet,sheet,sheet,sheet,sheet,sheet,sheet] # this can be a numpy array too\\n# insert_values = [sheet,sheet] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\ninsert_index = 2\\ninsert_colname = \\'Month Ahead\\'\\ninsert_values = [\\'1\\',\\'2\\',\\'3\\',\\'4\\',\\'5\\',\\'6\\',\\'12\\'] # this can be a numpy array too\\n# insert_values = [\\'6\\',\\'12\\'] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\nglobals()[sheet] = df\\n\\nimport matplotlib.pyplot as mp\\ndf.plot(title=sheet,x=\\'Month Ahead\\',y=[\"Prediction\",\"95%CI.Min\",\"95%CI.Max\"],kind=\"line\",figsize=(10,10))\\nmp.show()',\n  'globals()'],\n '_oh': {2:    Prediction   95%CI.Min   95%CI.Max\n  0  656.793579  653.470549  660.116609},\n '_dh': [PosixPath('/Users/issacsmacbookpro/Desktop/ModelPrediction/Train & Predicition')],\n 'In': ['',\n  \"# sheet='C1'\\n# sheet='C2'\\n# sheet='BYX'\\n# sheet='BZX'\\n# sheet='EDGA'\\n# sheet='EDGX_Equities'\\nsheet='EXO_EDGX_Options'\\n# sheet='OPT_BZX_BATS'\\n# sheet='CFE'\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\n\\nimport io\\nimport datetime\\n\\n# sheet='C1'\\n# sheet='C2'\\n# sheet='BYX'\\n# sheet='BZX'\\n# sheet='EDGA'\\n# sheet='EDGX_Equities'\\n# sheet='EXO_EDGX Options'\\n# sheet='OPT_BZX BATS'\\n# sheet='CFE'\\n\\n#load ensemble\\nimport os\\nfrom keras.models import load_model\\n\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # encoder = LabelEncoder()\\n# # # # print(values[:,0]) #PortQyt Value\\n# # values[:,0]=encoder.fit_transform(values[:,0])\\n# # print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1))* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+5):-n_features*(1+5)+1]\\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+5):-n_features*(1+5)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n\\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\n\\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble, model\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n\\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0]\\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome1= pd.DataFrame(outcome)\\noutcome1\",\n  \"from os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '1',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '1','model_corr.h5'))\",\n  \"from math import sqrt\\nimport numpy as np\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1))* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+4):-n_features*(1+4)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+4):-n_features*(1+4)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome2= pd.DataFrame(outcome)\\noutcome2\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '2',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '2','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+3):-n_features*(1+3)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+3):-n_features*(1+3)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome3= pd.DataFrame(outcome)\\noutcome3\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '3',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '3','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n# #\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+2):-n_features*(1+2)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+2):-n_features*(1+2)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome4= pd.DataFrame(outcome)\\noutcome4\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '4',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '4','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\nm=6-5\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome5= pd.DataFrame(outcome)\\noutcome5\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '5',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '5','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\nm=6-6\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome6= pd.DataFrame(outcome)\\noutcome6\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '6',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '6','model_corr.h5'))\",\n  \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='OPT_BZX BATS'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # encoder = LabelEncoder()\\n# # # # print(values[:,0]) #PortQyt Value\\n# # values[:,0]=encoder.fit_transform(values[:,0])\\n# # print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\n# n_months = 11\\nn_months = 23\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\nm=6-6\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months =17\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1)//2)* n_features #the following 12\\n# n_obs = (n_months+1)* n_features #the following \\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1)//2, n_features))\\n# train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1)//2, n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome12= pd.DataFrame(outcome)\\noutcome12\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '12',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '12','model_corr.h5'))\",\n  '#Concatenate all dataframes by identical columns\\n\\ndf=pd.concat([outcome1, outcome2,outcome3,outcome4,outcome5,outcome6,outcome12])\\n# df=pd.concat([outcome6,outcome12])\\n\\ninsert_index = 0\\ninsert_colname = \\'Asset\\'\\ninsert_values = [\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\'] # this can be a numpy array too\\n# insert_values = [\\'Options\\',\\'Options\\'] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\n\\ninsert_index = 1\\ninsert_colname = \\'Product\\'\\ninsert_values = [sheet,sheet,sheet,sheet,sheet,sheet,sheet] # this can be a numpy array too\\n# insert_values = [sheet,sheet] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\ninsert_index = 2\\ninsert_colname = \\'Month Ahead\\'\\ninsert_values = [\\'1\\',\\'2\\',\\'3\\',\\'4\\',\\'5\\',\\'6\\',\\'12\\'] # this can be a numpy array too\\n# insert_values = [\\'6\\',\\'12\\'] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\nglobals()[sheet] = df\\n\\nimport matplotlib.pyplot as mp\\ndf.plot(title=sheet,x=\\'Month Ahead\\',y=[\"Prediction\",\"95%CI.Min\",\"95%CI.Max\"],kind=\"line\",figsize=(10,10))\\nmp.show()',\n  'globals()'],\n 'Out': {2:    Prediction   95%CI.Min   95%CI.Max\n  0  656.793579  653.470549  660.116609},\n 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x1055ed7f0>>,\n 'exit': <IPython.core.autocall.ZMQExitAutocall at 0x105604520>,\n 'quit': <IPython.core.autocall.ZMQExitAutocall at 0x105604520>,\n '_':    Prediction   95%CI.Min   95%CI.Max\n 0  656.793579  653.470549  660.116609,\n '__': '',\n '___': '',\n '_i': '#Concatenate all dataframes by identical columns\\n\\ndf=pd.concat([outcome1, outcome2,outcome3,outcome4,outcome5,outcome6,outcome12])\\n# df=pd.concat([outcome6,outcome12])\\n\\ninsert_index = 0\\ninsert_colname = \\'Asset\\'\\ninsert_values = [\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\'] # this can be a numpy array too\\n# insert_values = [\\'Options\\',\\'Options\\'] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\n\\ninsert_index = 1\\ninsert_colname = \\'Product\\'\\ninsert_values = [sheet,sheet,sheet,sheet,sheet,sheet,sheet] # this can be a numpy array too\\n# insert_values = [sheet,sheet] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\ninsert_index = 2\\ninsert_colname = \\'Month Ahead\\'\\ninsert_values = [\\'1\\',\\'2\\',\\'3\\',\\'4\\',\\'5\\',\\'6\\',\\'12\\'] # this can be a numpy array too\\n# insert_values = [\\'6\\',\\'12\\'] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\nglobals()[sheet] = df\\n\\nimport matplotlib.pyplot as mp\\ndf.plot(title=sheet,x=\\'Month Ahead\\',y=[\"Prediction\",\"95%CI.Min\",\"95%CI.Max\"],kind=\"line\",figsize=(10,10))\\nmp.show()',\n '_ii': \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='OPT_BZX BATS'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # encoder = LabelEncoder()\\n# # # # print(values[:,0]) #PortQyt Value\\n# # values[:,0]=encoder.fit_transform(values[:,0])\\n# # print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\n# n_months = 11\\nn_months = 23\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\nm=6-6\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months =17\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1)//2)* n_features #the following 12\\n# n_obs = (n_months+1)* n_features #the following \\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1)//2, n_features))\\n# train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1)//2, n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome12= pd.DataFrame(outcome)\\noutcome12\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '12',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '12','model_corr.h5'))\",\n '_iii': \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\nm=6-6\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome6= pd.DataFrame(outcome)\\noutcome6\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '6',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '6','model_corr.h5'))\",\n '_i1': \"# sheet='C1'\\n# sheet='C2'\\n# sheet='BYX'\\n# sheet='BZX'\\n# sheet='EDGA'\\n# sheet='EDGX_Equities'\\nsheet='EXO_EDGX_Options'\\n# sheet='OPT_BZX_BATS'\\n# sheet='CFE'\",\n 'sheet': 'EXO_EDGX_Options',\n '_i2': \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\n\\nimport io\\nimport datetime\\n\\n# sheet='C1'\\n# sheet='C2'\\n# sheet='BYX'\\n# sheet='BZX'\\n# sheet='EDGA'\\n# sheet='EDGX_Equities'\\n# sheet='EXO_EDGX Options'\\n# sheet='OPT_BZX BATS'\\n# sheet='CFE'\\n\\n#load ensemble\\nimport os\\nfrom keras.models import load_model\\n\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # encoder = LabelEncoder()\\n# # # # print(values[:,0]) #PortQyt Value\\n# # values[:,0]=encoder.fit_transform(values[:,0])\\n# # print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1))* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+5):-n_features*(1+5)+1]\\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+5):-n_features*(1+5)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n\\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\n\\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble, model\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n\\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0]\\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome1= pd.DataFrame(outcome)\\noutcome1\",\n 'sqrt': <function math.sqrt(x, /)>,\n 'concatenate': <function numpy.concatenate>,\n 'pyplot': <module 'matplotlib.pyplot' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/pyplot.py'>,\n 'pd': <module 'pandas' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/pandas/__init__.py'>,\n 'read_csv': <function pandas.io.parsers.readers.read_csv(filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', sep=<no_default>, delimiter=None, header='infer', names=<no_default>, index_col=None, usecols=None, squeeze=None, prefix=<no_default>, mangle_dupe_cols=True, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=None, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression: 'CompressionOptions' = 'infer', thousands=None, decimal: 'str' = '.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors: 'str | None' = 'strict', dialect=None, error_bad_lines=None, warn_bad_lines=None, on_bad_lines=None, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None, storage_options: 'StorageOptions' = None)>,\n 'DataFrame': pandas.core.frame.DataFrame,\n 'concat': <function pandas.core.reshape.concat.concat(objs: 'Iterable[NDFrame] | Mapping[Hashable, NDFrame]', axis: 'Axis' = 0, join: 'str' = 'outer', ignore_index: 'bool' = False, keys=None, levels=None, names=None, verify_integrity: 'bool' = False, sort: 'bool' = False, copy: 'bool' = True) -> 'DataFrame | Series'>,\n 'MinMaxScaler': sklearn.preprocessing._data.MinMaxScaler,\n 'LabelEncoder': sklearn.preprocessing._label.LabelEncoder,\n 'mean_squared_error': <function sklearn.metrics._regression.mean_squared_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average', squared=True)>,\n 'Sequential': keras.engine.sequential.Sequential,\n 'Dense': keras.layers.core.dense.Dense,\n 'LSTM': keras.layers.rnn.lstm.LSTM,\n 'io': <module 'io' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/io.py'>,\n 'datetime': <module 'datetime' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/datetime.py'>,\n 'os': <module 'os' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/os.py'>,\n 'load_model': <function keras.saving.save.load_model(filepath, custom_objects=None, compile=True, options=None)>,\n 'df':      Asset           Product Month Ahead  Prediction   95%CI.Min   95%CI.Max\n 0  Options  EXO_EDGX_Options           1  656.793579  653.470549  660.116609\n 0  Options  EXO_EDGX_Options           2  651.924194  648.253465  655.594924\n 0  Options  EXO_EDGX_Options           3  673.428772  670.377063  676.480481\n 0  Options  EXO_EDGX_Options           4  697.759155  693.907809  701.610501\n 0  Options  EXO_EDGX_Options           5  718.015015  714.183098  721.846931\n 0  Options  EXO_EDGX_Options           6  727.055725  723.884459  730.226991\n 0  Options  EXO_EDGX_Options          12  744.631409  739.547320  749.715497,\n 'dt': datetime.datetime,\n 'last_date': '2022-06-01',\n 'first_column': 0     344.0\n 1     348.0\n 2     359.0\n 3     297.0\n 4     313.0\n 5     298.0\n 6     299.0\n 7     319.0\n 8     361.0\n 9     376.0\n 10    378.0\n 11    376.0\n 12    379.0\n 13    385.0\n 14    390.0\n 15    409.0\n 16    422.0\n 17    414.0\n 18    419.0\n 19    430.0\n 20    436.0\n 21    447.0\n 22    452.0\n 23    456.0\n 24    475.0\n 25    481.0\n 26    472.0\n 27    473.0\n 28    474.0\n 29    478.0\n 30    485.0\n 31    515.0\n 32    529.0\n 33    605.0\n 34    626.0\n 35    629.0\n 36    632.0\n 37    677.0\n 38    699.0\n 39    719.0\n 40    728.0\n 41    729.0\n Name: PortQyt, dtype: float64,\n 'second_column': 0     01\n 1     02\n 2     03\n 3     04\n 4     05\n 5     06\n 6     07\n 7     08\n 8     09\n 9     10\n 10    11\n 11    12\n 12    01\n 13    02\n 14    03\n 15    04\n 16    05\n 17    06\n 18    07\n 19    08\n 20    09\n 21    10\n 22    11\n 23    12\n 24    01\n 25    02\n 26    03\n 27    04\n 28    05\n 29    06\n 30    07\n 31    08\n 32    09\n 33    10\n 34    11\n 35    12\n 36    01\n 37    02\n 38    03\n 39    04\n 40    05\n 41    06\n Name: Month, dtype: object,\n 'values': array([[0.1087963 , 0.        , 0.        , ..., 0.4583851 , 0.44488525,\n         0.48822892],\n        [0.11805558, 0.        , 0.09090909, ..., 0.5630332 , 0.4909358 ,\n         0.6587075 ],\n        [0.14351851, 0.        , 0.18181819, ..., 0.6072968 , 0.5387666 ,\n         0.70309675],\n        ...,\n        [0.28935188, 0.33337402, 0.36363637, ..., 0.86509264, 0.8762548 ,\n         0.86667085],\n        [0.2708333 , 0.33337402, 0.45454547, ..., 0.89914   , 0.8762548 ,\n         0.8879397 ],\n        [0.2824074 , 0.33337402, 0.5454545 , ..., 0.7744826 , 0.86528945,\n         0.7815199 ]], dtype=float32),\n 'n_months': 23,\n 'n_features': 18,\n 'StandardScaler': sklearn.preprocessing._data.StandardScaler,\n 'scaler2': MinMaxScaler(),\n 'scaler': MinMaxScaler(),\n 'scaled': array([[0.1087963 , 0.        , 0.        , 0.0429873 , 0.02975523,\n         0.16666667, 0.9915612 , 0.3731799 , 0.70162773, 0.04464287,\n         0.020715  , 0.28285038, 0.04011428, 0.04996401, 0.27791953,\n         0.11227739, 0.09802651, 0.1975385 ],\n        [0.11805558, 0.        , 0.09090909, 0.        , 0.        ,\n         0.15555556, 0.9915612 , 0.3750794 , 0.70033026, 0.02678573,\n         0.        , 0.21070914, 0.        , 0.04996401, 0.21913278,\n         0.08742058, 0.03534746, 0.1975385 ],\n        [0.14351851, 0.        , 0.18181819, 0.04749545, 0.05582905,\n         0.2       , 0.99578047, 0.38428617, 0.7043867 , 0.02678573,\n         0.07219589, 0.10183777, 0.04648733, 0.17379719, 0.12860835,\n         0.19935238, 0.11985159, 0.35666084],\n        [0.        , 0.        , 0.27272728, 0.05083369, 0.09918505,\n         0.21111111, 0.9999999 , 0.40834856, 0.7258506 , 0.00892857,\n         0.10949242, 0.        , 0.07686973, 0.22221011, 0.        ,\n         0.23823011, 0.13353515, 0.42333317],\n        [0.03703701, 0.        , 0.36363637, 0.14548609, 0.23102856,\n         0.18888889, 0.98734176, 0.41960502, 0.7418542 , 0.00892857,\n         0.14768398, 0.0585347 , 0.11449599, 0.24650651, 0.05149254,\n         0.2696849 , 0.16624737, 0.42654777],\n        [0.00231481, 0.        , 0.45454547, 0.0729869 , 0.16864121,\n         0.16666667, 0.98312235, 0.4352913 , 0.76984644, 0.00892857,\n         0.14414358, 0.09176397, 0.11449599, 0.22616059, 0.12138042,\n         0.24566638, 0.16624737, 0.384125  ],\n        [0.00462961, 0.        , 0.5454545 , 0.09102282, 0.18512172,\n         0.18888889, 0.9915612 , 0.44721437, 0.7750597 , 0.01785716,\n         0.14209187, 0.11330256, 0.12334752, 0.22281641, 0.13166799,\n         0.2499249 , 0.17420244, 0.384125  ],\n        [0.05092591, 0.        , 0.6363636 , 0.12840933, 0.169123  ,\n         0.17777778, 0.8776371 , 0.45330143, 0.7817178 , 0.01785716,\n         0.19468462, 0.01333527, 0.15278733, 0.29722625, 0.02660958,\n         0.32702887, 0.22401357, 0.48977077],\n        [0.14814818, 0.        , 0.72727275, 0.10943267, 0.22815675,\n         0.17777778, 0.8396623 , 0.46074677, 0.7950897 , 0.        ,\n         0.16901636, 0.10107473, 0.15278733, 0.26506835, 0.12081984,\n         0.27764666, 0.22319388, 0.4251343 ],\n        [0.18287039, 0.        , 0.8181819 , 0.16132674, 0.27410424,\n         0.18888889, 0.75105476, 0.47176075, 0.7930312 , 0.00892857,\n         0.18276179, 0.06524628, 0.14499319, 0.26792902, 0.09222741,\n         0.30184162, 0.21253538, 0.43436098],\n        [0.1875    , 0.        , 0.9090909 , 0.10723191, 0.22806567,\n         0.22222221, 0.6329113 , 0.48590398, 0.8196373 , 0.00892857,\n         0.1946361 , 0.05895106, 0.17242813, 0.28572625, 0.03555194,\n         0.3134662 , 0.22304344, 0.46212018],\n        [0.18287039, 0.        , 1.        , 0.1304847 , 0.25626093,\n         0.24444443, 0.6329113 , 0.48966837, 0.81795835, 0.00892857,\n         0.24023414, 0.06725377, 0.21392035, 0.32905024, 0.08321251,\n         0.37143624, 0.29016948, 0.50591326],\n        [0.1898148 , 0.33337402, 0.        , 0.23502329, 0.3094129 ,\n         0.26666668, 0.6329113 , 0.4956298 , 0.8132987 , 0.        ,\n         0.28087628, 0.06577682, 0.25525475, 0.37606996, 0.04722276,\n         0.41704214, 0.34810257, 0.55002916],\n        [0.2037037 , 0.33337402, 0.09090909, 0.2753762 , 0.3270557 ,\n         0.24444443, 0.64556956, 0.5139892 , 0.8519869 , 0.        ,\n         0.32841444, 0.03668831, 0.2981249 , 0.41910845, 0.02973676,\n         0.4652685 , 0.3874998 , 0.5965221 ],\n        [0.21527779, 0.33337402, 0.18181819, 0.3422292 , 0.31822687,\n         0.15555556, 0.25316453, 0.34090137, 0.5455413 , 0.08035716,\n         0.33860707, 0.27365232, 0.3251723 , 0.31499714, 0.3120027 ,\n         0.45126545, 0.40421224, 0.42080975],\n        [0.25925928, 0.33337402, 0.27272728, 0.33610344, 0.4272716 ,\n         0.02222222, 0.        , 0.        , 0.        , 1.        ,\n         0.09183645, 0.99999994, 0.3189906 , 0.        , 1.        ,\n         0.07502329, 0.37696862, 0.        ],\n        [0.28935188, 0.33337402, 0.36363637, 0.39783233, 0.55063796,\n         0.        , 0.        , 0.12985659, 0.21781254, 0.86607146,\n         0.05599785, 0.52171844, 0.11147213, 0.        , 0.45775196,\n         0.        , 0.        , 0.        ],\n        [0.2708333 , 0.33337402, 0.45454547, 0.50973326, 0.48805773,\n         0.05555556, 0.01265822, 0.31022882, 0.5061407 , 0.66964287,\n         0.15689254, 0.17815025, 0.16707897, 0.21934932, 0.16272569,\n         0.11384857, 0.07516241, 0.27325606],\n        [0.2824074 , 0.33337402, 0.5454545 , 0.4434234 , 0.49684095,\n         0.1       , 0.01687764, 0.35478806, 0.5537133 , 0.59821427,\n         0.24199486, 0.14992893, 0.25160396, 0.3124879 , 0.1951356 ,\n         0.23755145, 0.24154449, 0.36252856],\n        [0.3078704 , 0.33337402, 0.6363636 , 0.4675647 , 0.5364528 ,\n         0.13333333, 0.02109705, 0.39829922, 0.6250224 , 0.4375    ,\n         0.28668964, 0.15176159, 0.2724793 , 0.33909148, 0.09702724,\n         0.2707826 , 0.19497132, 0.39650166],\n        [0.32175922, 0.33337402, 0.72727275, 0.50692934, 0.5127573 ,\n         0.14444445, 0.01687764, 0.44169307, 0.6902609 , 0.3928572 ,\n         0.37404346, 0.20862569, 0.3923962 , 0.4298702 , 0.19074494,\n         0.36871612, 0.3304355 , 0.4766276 ],\n        [0.3472222 , 0.33337402, 0.8181819 , 0.35866046, 0.33456182,\n         0.12222223, 0.01687764, 0.47107363, 0.7287164 , 0.30357146,\n         0.38947988, 0.18499596, 0.41832423, 0.43922585, 0.11860386,\n         0.39704788, 0.36714768, 0.504372  ],\n        [0.35879636, 0.33337402, 0.9090909 , 0.44555986, 0.40897435,\n         0.12222223, 0.01687764, 0.4347813 , 0.66398525, 0.28571427,\n         0.38875413, 0.18880485, 0.39601827, 0.43922585, 0.17475377,\n         0.39076865, 0.34553123, 0.48822892],\n        [0.36805558, 0.33337402, 1.        , 0.54285043, 0.43702435,\n         0.14444445, 0.01687764, 0.4429524 , 0.6581874 , 0.28571427,\n         0.4434067 , 0.2978257 , 0.45737135, 0.45374483, 0.31791314,\n         0.4583851 , 0.44488525, 0.48822892],\n        [0.41203701, 0.666687  , 0.        , 0.49533612, 0.28464818,\n         0.14444445, 0.01687764, 0.5287795 , 0.7782254 , 0.2589286 ,\n         0.5231676 , 0.07958345, 0.5021651 , 0.5801181 , 0.02924518,\n         0.5630332 , 0.4909358 , 0.6587075 ],\n        [0.42592597, 0.666687  , 0.09090909, 0.5336548 , 0.34568745,\n         0.17777778, 0.01265822, 0.4840567 , 0.6895318 , 0.2410714 ,\n         0.569304  , 0.09094588, 0.54967153, 0.63712186, 0.06721534,\n         0.6072968 , 0.5387666 , 0.70309675],\n        [0.4050926 , 0.666687  , 0.18181819, 0.56496716, 0.30994463,\n         0.27777776, 0.00843882, 0.5906794 , 0.8362694 , 0.22321427,\n         0.61288667, 0.10897304, 0.587695  , 0.6489778 , 0.08854641,\n         0.6461569 , 0.60234475, 0.70309675],\n        [0.4074074 , 0.666687  , 0.27272728, 0.37698543, 0.26502687,\n         0.45555553, 0.00843882, 0.6181233 , 0.8489523 , 0.22321427,\n         0.63565445, 0.10683896, 0.6283834 , 0.67280847, 0.18145236,\n         0.7299007 , 0.70176387, 0.7612127 ],\n        [0.4097222 , 0.666687  , 0.36363637, 0.38178146, 0.2676543 ,\n         0.54444444, 0.00421941, 0.6386466 , 0.85729647, 0.2053572 ,\n         0.71840847, 0.25840592, 0.72005665, 0.72583526, 0.11363742,\n         0.8318263 , 0.78637004, 0.85354924],\n        [0.41898143, 0.666687  , 0.45454547, 0.5232415 , 0.29174894,\n         0.5888889 , 0.01265822, 0.6660156 , 0.8725085 , 0.21428573,\n         0.7617185 , 0.02667331, 0.73016655, 0.8022534 , 0.0297526 ,\n         0.88052046, 0.83380556, 0.9256201 ],\n        [0.4351852 , 0.666687  , 0.5454545 , 0.4898517 , 0.33200133,\n         0.5888889 , 0.02109705, 0.67224216, 0.85185194, 0.16964287,\n         0.7892654 , 0.04584745, 0.7719554 , 0.84304184, 0.03882231,\n         0.89024675, 0.8320489 , 0.9072516 ],\n        [0.5046296 , 0.666687  , 0.6363636 , 0.5134151 , 0.34742588,\n         0.5777778 , 0.01687764, 0.7190578 , 0.904757  , 0.1517857 ,\n         0.838115  , 0.12253393, 0.8208972 , 0.84769565, 0.06227407,\n         0.91501606, 0.86393476, 0.94330907],\n        [0.537037  , 0.666687  , 0.72727275, 0.52545214, 0.36017263,\n         0.5888889 , 0.01265822, 0.7411051 , 0.91937447, 0.10714284,\n         0.8919294 , 0.05567923, 0.8718823 , 0.9360356 , 0.00957834,\n         0.9576973 , 0.90347934, 1.        ],\n        [0.712963  , 0.666687  , 0.8181819 , 0.62255335, 0.46487874,\n         0.6777777 , 0.01265822, 0.81965184, 1.        , 0.0982143 ,\n         0.89690375, 0.12378119, 0.87578666, 0.9096957 , 0.09886928,\n         0.9314288 , 0.88953876, 0.94143796],\n        [0.76157403, 0.666687  , 0.9090909 , 0.74600077, 0.46549892,\n         0.74444443, 0.01265822, 0.8281257 , 0.98006487, 0.0625    ,\n         0.89305687, 0.23451863, 0.91249406, 0.90658444, 0.15427528,\n         0.935989  , 0.92718863, 0.94143796],\n        [0.76851857, 0.666687  , 1.        , 0.66684836, 0.4972949 ,\n         0.76666665, 0.01265822, 0.84830236, 0.9836626 , 0.0357143 ,\n         0.98276114, 0.1141559 , 0.9569768 , 0.99999994, 0.11171626,\n         0.9999999 , 0.9697981 , 0.95243216],\n        [0.775463  , 1.        , 0.        , 0.7647647 , 0.5547458 ,\n         0.8222222 , 0.01265822, 0.8631928 , 0.96680546, 0.04464287,\n         1.        , 0.1604218 , 0.99832547, 0.99999994, 0.15070492,\n         0.98922145, 0.9823611 , 0.95243216],\n        [0.8796296 , 1.        , 0.09090909, 0.7261382 , 0.62372184,\n         0.8666667 , 0.01265822, 0.8886876 , 0.9672837 , 0.02678573,\n         0.97517633, 0.41241896, 1.0000001 , 0.91802746, 0.22036314,\n         0.9905764 , 1.        , 0.96099615],\n        [0.9305556 , 1.        , 0.18181819, 0.95779973, 0.70850277,\n         0.93333334, 0.06329113, 0.91869044, 0.9608803 , 0.00892857,\n         0.8861549 , 0.22862779, 0.9008435 , 0.8736443 , 0.17828198,\n         0.9120101 , 0.9152057 , 0.8974793 ],\n        [0.9768518 , 1.        , 0.27272728, 0.7920462 , 0.74845695,\n         0.9111111 , 0.11814345, 0.92966914, 0.94785404, 0.00892857,\n         0.8623464 , 0.35667688, 0.92107284, 0.849528  , 0.19914177,\n         0.86509264, 0.8762548 , 0.86667085],\n        [0.9976852 , 1.        , 0.36363637, 0.9594247 , 0.8399497 ,\n         0.9444445 , 0.30379745, 0.9532075 , 0.9464812 , 0.00892857,\n         0.8885429 , 0.3353126 , 0.92107284, 0.83252627, 0.14473031,\n         0.89914   , 0.8762548 , 0.8879397 ],\n        [1.        , 1.        , 0.45454547, 0.99999994, 1.0000001 ,\n         1.        , 0.48945144, 1.        , 0.9581876 , 0.00892857,\n         0.7303034 , 0.40828454, 0.83870566, 0.7309548 , 0.27033213,\n         0.7744826 , 0.86528945, 0.7815199 ]], dtype=float32),\n 'series_to_supervised': <function __main__.series_to_supervised(data, n_in=1, n_out=1, dropnan=True)>,\n 'reframed':     var1(t-23)  var2(t-23)  var3(t-23)  var4(t-23)  var5(t-23)  var6(t-23)  \\\n 23    0.108796    0.000000    0.000000    0.042987    0.029755    0.166667   \n 24    0.118056    0.000000    0.090909    0.000000    0.000000    0.155556   \n 25    0.143519    0.000000    0.181818    0.047495    0.055829    0.200000   \n 26    0.000000    0.000000    0.272727    0.050834    0.099185    0.211111   \n 27    0.037037    0.000000    0.363636    0.145486    0.231029    0.188889   \n 28    0.002315    0.000000    0.454545    0.072987    0.168641    0.166667   \n 29    0.004630    0.000000    0.545455    0.091023    0.185122    0.188889   \n 30    0.050926    0.000000    0.636364    0.128409    0.169123    0.177778   \n 31    0.148148    0.000000    0.727273    0.109433    0.228157    0.177778   \n 32    0.182870    0.000000    0.818182    0.161327    0.274104    0.188889   \n 33    0.187500    0.000000    0.909091    0.107232    0.228066    0.222222   \n 34    0.182870    0.000000    1.000000    0.130485    0.256261    0.244444   \n 35    0.189815    0.333374    0.000000    0.235023    0.309413    0.266667   \n 36    0.203704    0.333374    0.090909    0.275376    0.327056    0.244444   \n 37    0.215278    0.333374    0.181818    0.342229    0.318227    0.155556   \n 38    0.259259    0.333374    0.272727    0.336103    0.427272    0.022222   \n 39    0.289352    0.333374    0.363636    0.397832    0.550638    0.000000   \n 40    0.270833    0.333374    0.454545    0.509733    0.488058    0.055556   \n 41    0.282407    0.333374    0.545455    0.443423    0.496841    0.100000   \n \n     var7(t-23)  var8(t-23)  var9(t-23)  var10(t-23)  ...   var9(t)  var10(t)  \\\n 23    0.991561    0.373180    0.701628     0.044643  ...  0.658187  0.285714   \n 24    0.991561    0.375079    0.700330     0.026786  ...  0.778225  0.258929   \n 25    0.995780    0.384286    0.704387     0.026786  ...  0.689532  0.241071   \n 26    1.000000    0.408349    0.725851     0.008929  ...  0.836269  0.223214   \n 27    0.987342    0.419605    0.741854     0.008929  ...  0.848952  0.223214   \n 28    0.983122    0.435291    0.769846     0.008929  ...  0.857296  0.205357   \n 29    0.991561    0.447214    0.775060     0.017857  ...  0.872509  0.214286   \n 30    0.877637    0.453301    0.781718     0.017857  ...  0.851852  0.169643   \n 31    0.839662    0.460747    0.795090     0.000000  ...  0.904757  0.151786   \n 32    0.751055    0.471761    0.793031     0.008929  ...  0.919374  0.107143   \n 33    0.632911    0.485904    0.819637     0.008929  ...  1.000000  0.098214   \n 34    0.632911    0.489668    0.817958     0.008929  ...  0.980065  0.062500   \n 35    0.632911    0.495630    0.813299     0.000000  ...  0.983663  0.035714   \n 36    0.645570    0.513989    0.851987     0.000000  ...  0.966805  0.044643   \n 37    0.253165    0.340901    0.545541     0.080357  ...  0.967284  0.026786   \n 38    0.000000    0.000000    0.000000     1.000000  ...  0.960880  0.008929   \n 39    0.000000    0.129857    0.217813     0.866071  ...  0.947854  0.008929   \n 40    0.012658    0.310229    0.506141     0.669643  ...  0.946481  0.008929   \n 41    0.016878    0.354788    0.553713     0.598214  ...  0.958188  0.008929   \n \n     var11(t)  var12(t)  var13(t)  var14(t)  var15(t)  var16(t)  var17(t)  \\\n 23  0.443407  0.297826  0.457371  0.453745  0.317913  0.458385  0.444885   \n 24  0.523168  0.079583  0.502165  0.580118  0.029245  0.563033  0.490936   \n 25  0.569304  0.090946  0.549672  0.637122  0.067215  0.607297  0.538767   \n 26  0.612887  0.108973  0.587695  0.648978  0.088546  0.646157  0.602345   \n 27  0.635654  0.106839  0.628383  0.672808  0.181452  0.729901  0.701764   \n 28  0.718408  0.258406  0.720057  0.725835  0.113637  0.831826  0.786370   \n 29  0.761719  0.026673  0.730167  0.802253  0.029753  0.880520  0.833806   \n 30  0.789265  0.045847  0.771955  0.843042  0.038822  0.890247  0.832049   \n 31  0.838115  0.122534  0.820897  0.847696  0.062274  0.915016  0.863935   \n 32  0.891929  0.055679  0.871882  0.936036  0.009578  0.957697  0.903479   \n 33  0.896904  0.123781  0.875787  0.909696  0.098869  0.931429  0.889539   \n 34  0.893057  0.234519  0.912494  0.906584  0.154275  0.935989  0.927189   \n 35  0.982761  0.114156  0.956977  1.000000  0.111716  1.000000  0.969798   \n 36  1.000000  0.160422  0.998325  1.000000  0.150705  0.989221  0.982361   \n 37  0.975176  0.412419  1.000000  0.918027  0.220363  0.990576  1.000000   \n 38  0.886155  0.228628  0.900844  0.873644  0.178282  0.912010  0.915206   \n 39  0.862346  0.356677  0.921073  0.849528  0.199142  0.865093  0.876255   \n 40  0.888543  0.335313  0.921073  0.832526  0.144730  0.899140  0.876255   \n 41  0.730303  0.408285  0.838706  0.730955  0.270332  0.774483  0.865289   \n \n     var18(t)  \n 23  0.488229  \n 24  0.658707  \n 25  0.703097  \n 26  0.703097  \n 27  0.761213  \n 28  0.853549  \n 29  0.925620  \n 30  0.907252  \n 31  0.943309  \n 32  1.000000  \n 33  0.941438  \n 34  0.941438  \n 35  0.952432  \n 36  0.952432  \n 37  0.960996  \n 38  0.897479  \n 39  0.866671  \n 40  0.887940  \n 41  0.781520  \n \n [19 rows x 432 columns],\n 'n_train_months': 17,\n 'train': array([[0.1087963 , 0.        , 0.        , ..., 0.4583851 , 0.44488525,\n         0.48822892],\n        [0.11805558, 0.        , 0.09090909, ..., 0.5630332 , 0.4909358 ,\n         0.6587075 ],\n        [0.14351851, 0.        , 0.18181819, ..., 0.6072968 , 0.5387666 ,\n         0.70309675],\n        ...,\n        [0.21527779, 0.33337402, 0.18181819, ..., 0.9905764 , 1.        ,\n         0.96099615],\n        [0.25925928, 0.33337402, 0.27272728, ..., 0.9120101 , 0.9152057 ,\n         0.8974793 ],\n        [0.28935188, 0.33337402, 0.36363637, ..., 0.86509264, 0.8762548 ,\n         0.86667085]], dtype=float32),\n 'test': array([[0.2708333 , 0.33337402, 0.45454547, 0.50973326, 0.48805773,\n         0.05555556, 0.01265822, 0.31022882, 0.5061407 , 0.66964287,\n         0.15689254, 0.17815025, 0.16707897, 0.21934932, 0.16272569,\n         0.11384857, 0.07516241, 0.27325606, 0.2824074 , 0.33337402,\n         0.5454545 , 0.4434234 , 0.49684095, 0.1       , 0.01687764,\n         0.35478806, 0.5537133 , 0.59821427, 0.24199486, 0.14992893,\n         0.25160396, 0.3124879 , 0.1951356 , 0.23755145, 0.24154449,\n         0.36252856, 0.3078704 , 0.33337402, 0.6363636 , 0.4675647 ,\n         0.5364528 , 0.13333333, 0.02109705, 0.39829922, 0.6250224 ,\n         0.4375    , 0.28668964, 0.15176159, 0.2724793 , 0.33909148,\n         0.09702724, 0.2707826 , 0.19497132, 0.39650166, 0.32175922,\n         0.33337402, 0.72727275, 0.50692934, 0.5127573 , 0.14444445,\n         0.01687764, 0.44169307, 0.6902609 , 0.3928572 , 0.37404346,\n         0.20862569, 0.3923962 , 0.4298702 , 0.19074494, 0.36871612,\n         0.3304355 , 0.4766276 , 0.3472222 , 0.33337402, 0.8181819 ,\n         0.35866046, 0.33456182, 0.12222223, 0.01687764, 0.47107363,\n         0.7287164 , 0.30357146, 0.38947988, 0.18499596, 0.41832423,\n         0.43922585, 0.11860386, 0.39704788, 0.36714768, 0.504372  ,\n         0.35879636, 0.33337402, 0.9090909 , 0.44555986, 0.40897435,\n         0.12222223, 0.01687764, 0.4347813 , 0.66398525, 0.28571427,\n         0.38875413, 0.18880485, 0.39601827, 0.43922585, 0.17475377,\n         0.39076865, 0.34553123, 0.48822892, 0.36805558, 0.33337402,\n         1.        , 0.54285043, 0.43702435, 0.14444445, 0.01687764,\n         0.4429524 , 0.6581874 , 0.28571427, 0.4434067 , 0.2978257 ,\n         0.45737135, 0.45374483, 0.31791314, 0.4583851 , 0.44488525,\n         0.48822892, 0.41203701, 0.666687  , 0.        , 0.49533612,\n         0.28464818, 0.14444445, 0.01687764, 0.5287795 , 0.7782254 ,\n         0.2589286 , 0.5231676 , 0.07958345, 0.5021651 , 0.5801181 ,\n         0.02924518, 0.5630332 , 0.4909358 , 0.6587075 , 0.42592597,\n         0.666687  , 0.09090909, 0.5336548 , 0.34568745, 0.17777778,\n         0.01265822, 0.4840567 , 0.6895318 , 0.2410714 , 0.569304  ,\n         0.09094588, 0.54967153, 0.63712186, 0.06721534, 0.6072968 ,\n         0.5387666 , 0.70309675, 0.4050926 , 0.666687  , 0.18181819,\n         0.56496716, 0.30994463, 0.27777776, 0.00843882, 0.5906794 ,\n         0.8362694 , 0.22321427, 0.61288667, 0.10897304, 0.587695  ,\n         0.6489778 , 0.08854641, 0.6461569 , 0.60234475, 0.70309675,\n         0.4074074 , 0.666687  , 0.27272728, 0.37698543, 0.26502687,\n         0.45555553, 0.00843882, 0.6181233 , 0.8489523 , 0.22321427,\n         0.63565445, 0.10683896, 0.6283834 , 0.67280847, 0.18145236,\n         0.7299007 , 0.70176387, 0.7612127 , 0.4097222 , 0.666687  ,\n         0.36363637, 0.38178146, 0.2676543 , 0.54444444, 0.00421941,\n         0.6386466 , 0.85729647, 0.2053572 , 0.71840847, 0.25840592,\n         0.72005665, 0.72583526, 0.11363742, 0.8318263 , 0.78637004,\n         0.85354924, 0.41898143, 0.666687  , 0.45454547, 0.5232415 ,\n         0.29174894, 0.5888889 , 0.01265822, 0.6660156 , 0.8725085 ,\n         0.21428573, 0.7617185 , 0.02667331, 0.73016655, 0.8022534 ,\n         0.0297526 , 0.88052046, 0.83380556, 0.9256201 , 0.4351852 ,\n         0.666687  , 0.5454545 , 0.4898517 , 0.33200133, 0.5888889 ,\n         0.02109705, 0.67224216, 0.85185194, 0.16964287, 0.7892654 ,\n         0.04584745, 0.7719554 , 0.84304184, 0.03882231, 0.89024675,\n         0.8320489 , 0.9072516 , 0.5046296 , 0.666687  , 0.6363636 ,\n         0.5134151 , 0.34742588, 0.5777778 , 0.01687764, 0.7190578 ,\n         0.904757  , 0.1517857 , 0.838115  , 0.12253393, 0.8208972 ,\n         0.84769565, 0.06227407, 0.91501606, 0.86393476, 0.94330907,\n         0.537037  , 0.666687  , 0.72727275, 0.52545214, 0.36017263,\n         0.5888889 , 0.01265822, 0.7411051 , 0.91937447, 0.10714284,\n         0.8919294 , 0.05567923, 0.8718823 , 0.9360356 , 0.00957834,\n         0.9576973 , 0.90347934, 1.        , 0.712963  , 0.666687  ,\n         0.8181819 , 0.62255335, 0.46487874, 0.6777777 , 0.01265822,\n         0.81965184, 1.        , 0.0982143 , 0.89690375, 0.12378119,\n         0.87578666, 0.9096957 , 0.09886928, 0.9314288 , 0.88953876,\n         0.94143796, 0.76157403, 0.666687  , 0.9090909 , 0.74600077,\n         0.46549892, 0.74444443, 0.01265822, 0.8281257 , 0.98006487,\n         0.0625    , 0.89305687, 0.23451863, 0.91249406, 0.90658444,\n         0.15427528, 0.935989  , 0.92718863, 0.94143796, 0.76851857,\n         0.666687  , 1.        , 0.66684836, 0.4972949 , 0.76666665,\n         0.01265822, 0.84830236, 0.9836626 , 0.0357143 , 0.98276114,\n         0.1141559 , 0.9569768 , 0.99999994, 0.11171626, 0.9999999 ,\n         0.9697981 , 0.95243216, 0.775463  , 1.        , 0.        ,\n         0.7647647 , 0.5547458 , 0.8222222 , 0.01265822, 0.8631928 ,\n         0.96680546, 0.04464287, 1.        , 0.1604218 , 0.99832547,\n         0.99999994, 0.15070492, 0.98922145, 0.9823611 , 0.95243216,\n         0.8796296 , 1.        , 0.09090909, 0.7261382 , 0.62372184,\n         0.8666667 , 0.01265822, 0.8886876 , 0.9672837 , 0.02678573,\n         0.97517633, 0.41241896, 1.0000001 , 0.91802746, 0.22036314,\n         0.9905764 , 1.        , 0.96099615, 0.9305556 , 1.        ,\n         0.18181819, 0.95779973, 0.70850277, 0.93333334, 0.06329113,\n         0.91869044, 0.9608803 , 0.00892857, 0.8861549 , 0.22862779,\n         0.9008435 , 0.8736443 , 0.17828198, 0.9120101 , 0.9152057 ,\n         0.8974793 , 0.9768518 , 1.        , 0.27272728, 0.7920462 ,\n         0.74845695, 0.9111111 , 0.11814345, 0.92966914, 0.94785404,\n         0.00892857, 0.8623464 , 0.35667688, 0.92107284, 0.849528  ,\n         0.19914177, 0.86509264, 0.8762548 , 0.86667085, 0.9976852 ,\n         1.        , 0.36363637, 0.9594247 , 0.8399497 , 0.9444445 ,\n         0.30379745, 0.9532075 , 0.9464812 , 0.00892857, 0.8885429 ,\n         0.3353126 , 0.92107284, 0.83252627, 0.14473031, 0.89914   ,\n         0.8762548 , 0.8879397 ],\n        [0.2824074 , 0.33337402, 0.5454545 , 0.4434234 , 0.49684095,\n         0.1       , 0.01687764, 0.35478806, 0.5537133 , 0.59821427,\n         0.24199486, 0.14992893, 0.25160396, 0.3124879 , 0.1951356 ,\n         0.23755145, 0.24154449, 0.36252856, 0.3078704 , 0.33337402,\n         0.6363636 , 0.4675647 , 0.5364528 , 0.13333333, 0.02109705,\n         0.39829922, 0.6250224 , 0.4375    , 0.28668964, 0.15176159,\n         0.2724793 , 0.33909148, 0.09702724, 0.2707826 , 0.19497132,\n         0.39650166, 0.32175922, 0.33337402, 0.72727275, 0.50692934,\n         0.5127573 , 0.14444445, 0.01687764, 0.44169307, 0.6902609 ,\n         0.3928572 , 0.37404346, 0.20862569, 0.3923962 , 0.4298702 ,\n         0.19074494, 0.36871612, 0.3304355 , 0.4766276 , 0.3472222 ,\n         0.33337402, 0.8181819 , 0.35866046, 0.33456182, 0.12222223,\n         0.01687764, 0.47107363, 0.7287164 , 0.30357146, 0.38947988,\n         0.18499596, 0.41832423, 0.43922585, 0.11860386, 0.39704788,\n         0.36714768, 0.504372  , 0.35879636, 0.33337402, 0.9090909 ,\n         0.44555986, 0.40897435, 0.12222223, 0.01687764, 0.4347813 ,\n         0.66398525, 0.28571427, 0.38875413, 0.18880485, 0.39601827,\n         0.43922585, 0.17475377, 0.39076865, 0.34553123, 0.48822892,\n         0.36805558, 0.33337402, 1.        , 0.54285043, 0.43702435,\n         0.14444445, 0.01687764, 0.4429524 , 0.6581874 , 0.28571427,\n         0.4434067 , 0.2978257 , 0.45737135, 0.45374483, 0.31791314,\n         0.4583851 , 0.44488525, 0.48822892, 0.41203701, 0.666687  ,\n         0.        , 0.49533612, 0.28464818, 0.14444445, 0.01687764,\n         0.5287795 , 0.7782254 , 0.2589286 , 0.5231676 , 0.07958345,\n         0.5021651 , 0.5801181 , 0.02924518, 0.5630332 , 0.4909358 ,\n         0.6587075 , 0.42592597, 0.666687  , 0.09090909, 0.5336548 ,\n         0.34568745, 0.17777778, 0.01265822, 0.4840567 , 0.6895318 ,\n         0.2410714 , 0.569304  , 0.09094588, 0.54967153, 0.63712186,\n         0.06721534, 0.6072968 , 0.5387666 , 0.70309675, 0.4050926 ,\n         0.666687  , 0.18181819, 0.56496716, 0.30994463, 0.27777776,\n         0.00843882, 0.5906794 , 0.8362694 , 0.22321427, 0.61288667,\n         0.10897304, 0.587695  , 0.6489778 , 0.08854641, 0.6461569 ,\n         0.60234475, 0.70309675, 0.4074074 , 0.666687  , 0.27272728,\n         0.37698543, 0.26502687, 0.45555553, 0.00843882, 0.6181233 ,\n         0.8489523 , 0.22321427, 0.63565445, 0.10683896, 0.6283834 ,\n         0.67280847, 0.18145236, 0.7299007 , 0.70176387, 0.7612127 ,\n         0.4097222 , 0.666687  , 0.36363637, 0.38178146, 0.2676543 ,\n         0.54444444, 0.00421941, 0.6386466 , 0.85729647, 0.2053572 ,\n         0.71840847, 0.25840592, 0.72005665, 0.72583526, 0.11363742,\n         0.8318263 , 0.78637004, 0.85354924, 0.41898143, 0.666687  ,\n         0.45454547, 0.5232415 , 0.29174894, 0.5888889 , 0.01265822,\n         0.6660156 , 0.8725085 , 0.21428573, 0.7617185 , 0.02667331,\n         0.73016655, 0.8022534 , 0.0297526 , 0.88052046, 0.83380556,\n         0.9256201 , 0.4351852 , 0.666687  , 0.5454545 , 0.4898517 ,\n         0.33200133, 0.5888889 , 0.02109705, 0.67224216, 0.85185194,\n         0.16964287, 0.7892654 , 0.04584745, 0.7719554 , 0.84304184,\n         0.03882231, 0.89024675, 0.8320489 , 0.9072516 , 0.5046296 ,\n         0.666687  , 0.6363636 , 0.5134151 , 0.34742588, 0.5777778 ,\n         0.01687764, 0.7190578 , 0.904757  , 0.1517857 , 0.838115  ,\n         0.12253393, 0.8208972 , 0.84769565, 0.06227407, 0.91501606,\n         0.86393476, 0.94330907, 0.537037  , 0.666687  , 0.72727275,\n         0.52545214, 0.36017263, 0.5888889 , 0.01265822, 0.7411051 ,\n         0.91937447, 0.10714284, 0.8919294 , 0.05567923, 0.8718823 ,\n         0.9360356 , 0.00957834, 0.9576973 , 0.90347934, 1.        ,\n         0.712963  , 0.666687  , 0.8181819 , 0.62255335, 0.46487874,\n         0.6777777 , 0.01265822, 0.81965184, 1.        , 0.0982143 ,\n         0.89690375, 0.12378119, 0.87578666, 0.9096957 , 0.09886928,\n         0.9314288 , 0.88953876, 0.94143796, 0.76157403, 0.666687  ,\n         0.9090909 , 0.74600077, 0.46549892, 0.74444443, 0.01265822,\n         0.8281257 , 0.98006487, 0.0625    , 0.89305687, 0.23451863,\n         0.91249406, 0.90658444, 0.15427528, 0.935989  , 0.92718863,\n         0.94143796, 0.76851857, 0.666687  , 1.        , 0.66684836,\n         0.4972949 , 0.76666665, 0.01265822, 0.84830236, 0.9836626 ,\n         0.0357143 , 0.98276114, 0.1141559 , 0.9569768 , 0.99999994,\n         0.11171626, 0.9999999 , 0.9697981 , 0.95243216, 0.775463  ,\n         1.        , 0.        , 0.7647647 , 0.5547458 , 0.8222222 ,\n         0.01265822, 0.8631928 , 0.96680546, 0.04464287, 1.        ,\n         0.1604218 , 0.99832547, 0.99999994, 0.15070492, 0.98922145,\n         0.9823611 , 0.95243216, 0.8796296 , 1.        , 0.09090909,\n         0.7261382 , 0.62372184, 0.8666667 , 0.01265822, 0.8886876 ,\n         0.9672837 , 0.02678573, 0.97517633, 0.41241896, 1.0000001 ,\n         0.91802746, 0.22036314, 0.9905764 , 1.        , 0.96099615,\n         0.9305556 , 1.        , 0.18181819, 0.95779973, 0.70850277,\n         0.93333334, 0.06329113, 0.91869044, 0.9608803 , 0.00892857,\n         0.8861549 , 0.22862779, 0.9008435 , 0.8736443 , 0.17828198,\n         0.9120101 , 0.9152057 , 0.8974793 , 0.9768518 , 1.        ,\n         0.27272728, 0.7920462 , 0.74845695, 0.9111111 , 0.11814345,\n         0.92966914, 0.94785404, 0.00892857, 0.8623464 , 0.35667688,\n         0.92107284, 0.849528  , 0.19914177, 0.86509264, 0.8762548 ,\n         0.86667085, 0.9976852 , 1.        , 0.36363637, 0.9594247 ,\n         0.8399497 , 0.9444445 , 0.30379745, 0.9532075 , 0.9464812 ,\n         0.00892857, 0.8885429 , 0.3353126 , 0.92107284, 0.83252627,\n         0.14473031, 0.89914   , 0.8762548 , 0.8879397 , 1.        ,\n         1.        , 0.45454547, 0.99999994, 1.0000001 , 1.        ,\n         0.48945144, 1.        , 0.9581876 , 0.00892857, 0.7303034 ,\n         0.40828454, 0.83870566, 0.7309548 , 0.27033213, 0.7744826 ,\n         0.86528945, 0.7815199 ]], dtype=float32),\n 'n_obs': 216,\n 'train_X': array([[[0.1087963 , 0.        , 0.        , ..., 0.11227739,\n          0.09802651, 0.1975385 ],\n         [0.11805558, 0.        , 0.09090909, ..., 0.08742058,\n          0.03534746, 0.1975385 ],\n         [0.14351851, 0.        , 0.18181819, ..., 0.19935238,\n          0.11985159, 0.35666084],\n         ...,\n         [0.18287039, 0.        , 0.8181819 , ..., 0.30184162,\n          0.21253538, 0.43436098],\n         [0.1875    , 0.        , 0.9090909 , ..., 0.3134662 ,\n          0.22304344, 0.46212018],\n         [0.18287039, 0.        , 1.        , ..., 0.37143624,\n          0.29016948, 0.50591326]],\n \n        [[0.11805558, 0.        , 0.09090909, ..., 0.08742058,\n          0.03534746, 0.1975385 ],\n         [0.14351851, 0.        , 0.18181819, ..., 0.19935238,\n          0.11985159, 0.35666084],\n         [0.        , 0.        , 0.27272728, ..., 0.23823011,\n          0.13353515, 0.42333317],\n         ...,\n         [0.1875    , 0.        , 0.9090909 , ..., 0.3134662 ,\n          0.22304344, 0.46212018],\n         [0.18287039, 0.        , 1.        , ..., 0.37143624,\n          0.29016948, 0.50591326],\n         [0.1898148 , 0.33337402, 0.        , ..., 0.41704214,\n          0.34810257, 0.55002916]],\n \n        [[0.14351851, 0.        , 0.18181819, ..., 0.19935238,\n          0.11985159, 0.35666084],\n         [0.        , 0.        , 0.27272728, ..., 0.23823011,\n          0.13353515, 0.42333317],\n         [0.03703701, 0.        , 0.36363637, ..., 0.2696849 ,\n          0.16624737, 0.42654777],\n         ...,\n         [0.18287039, 0.        , 1.        , ..., 0.37143624,\n          0.29016948, 0.50591326],\n         [0.1898148 , 0.33337402, 0.        , ..., 0.41704214,\n          0.34810257, 0.55002916],\n         [0.2037037 , 0.33337402, 0.09090909, ..., 0.4652685 ,\n          0.3874998 , 0.5965221 ]],\n \n        ...,\n \n        [[0.21527779, 0.33337402, 0.18181819, ..., 0.45126545,\n          0.40421224, 0.42080975],\n         [0.25925928, 0.33337402, 0.27272728, ..., 0.07502329,\n          0.37696862, 0.        ],\n         [0.28935188, 0.33337402, 0.36363637, ..., 0.        ,\n          0.        , 0.        ],\n         ...,\n         [0.36805558, 0.33337402, 1.        , ..., 0.4583851 ,\n          0.44488525, 0.48822892],\n         [0.41203701, 0.666687  , 0.        , ..., 0.5630332 ,\n          0.4909358 , 0.6587075 ],\n         [0.42592597, 0.666687  , 0.09090909, ..., 0.6072968 ,\n          0.5387666 , 0.70309675]],\n \n        [[0.25925928, 0.33337402, 0.27272728, ..., 0.07502329,\n          0.37696862, 0.        ],\n         [0.28935188, 0.33337402, 0.36363637, ..., 0.        ,\n          0.        , 0.        ],\n         [0.2708333 , 0.33337402, 0.45454547, ..., 0.11384857,\n          0.07516241, 0.27325606],\n         ...,\n         [0.41203701, 0.666687  , 0.        , ..., 0.5630332 ,\n          0.4909358 , 0.6587075 ],\n         [0.42592597, 0.666687  , 0.09090909, ..., 0.6072968 ,\n          0.5387666 , 0.70309675],\n         [0.4050926 , 0.666687  , 0.18181819, ..., 0.6461569 ,\n          0.60234475, 0.70309675]],\n \n        [[0.28935188, 0.33337402, 0.36363637, ..., 0.        ,\n          0.        , 0.        ],\n         [0.2708333 , 0.33337402, 0.45454547, ..., 0.11384857,\n          0.07516241, 0.27325606],\n         [0.2824074 , 0.33337402, 0.5454545 , ..., 0.23755145,\n          0.24154449, 0.36252856],\n         ...,\n         [0.42592597, 0.666687  , 0.09090909, ..., 0.6072968 ,\n          0.5387666 , 0.70309675],\n         [0.4050926 , 0.666687  , 0.18181819, ..., 0.6461569 ,\n          0.60234475, 0.70309675],\n         [0.4074074 , 0.666687  , 0.27272728, ..., 0.7299007 ,\n          0.70176387, 0.7612127 ]]], dtype=float32),\n 'train_y': array([[0.36805558],\n        [0.41203701],\n        [0.42592597],\n        [0.4050926 ],\n        [0.4074074 ],\n        [0.4097222 ],\n        [0.41898143],\n        [0.4351852 ],\n        [0.5046296 ],\n        [0.537037  ],\n        [0.712963  ],\n        [0.76157403],\n        [0.76851857],\n        [0.775463  ],\n        [0.8796296 ],\n        [0.9305556 ],\n        [0.9768518 ]], dtype=float32),\n 'test_X': array([[[0.2708333 , 0.33337402, 0.45454547, 0.50973326, 0.48805773,\n          0.05555556, 0.01265822, 0.31022882, 0.5061407 , 0.66964287,\n          0.15689254, 0.17815025, 0.16707897, 0.21934932, 0.16272569,\n          0.11384857, 0.07516241, 0.27325606],\n         [0.2824074 , 0.33337402, 0.5454545 , 0.4434234 , 0.49684095,\n          0.1       , 0.01687764, 0.35478806, 0.5537133 , 0.59821427,\n          0.24199486, 0.14992893, 0.25160396, 0.3124879 , 0.1951356 ,\n          0.23755145, 0.24154449, 0.36252856],\n         [0.3078704 , 0.33337402, 0.6363636 , 0.4675647 , 0.5364528 ,\n          0.13333333, 0.02109705, 0.39829922, 0.6250224 , 0.4375    ,\n          0.28668964, 0.15176159, 0.2724793 , 0.33909148, 0.09702724,\n          0.2707826 , 0.19497132, 0.39650166],\n         [0.32175922, 0.33337402, 0.72727275, 0.50692934, 0.5127573 ,\n          0.14444445, 0.01687764, 0.44169307, 0.6902609 , 0.3928572 ,\n          0.37404346, 0.20862569, 0.3923962 , 0.4298702 , 0.19074494,\n          0.36871612, 0.3304355 , 0.4766276 ],\n         [0.3472222 , 0.33337402, 0.8181819 , 0.35866046, 0.33456182,\n          0.12222223, 0.01687764, 0.47107363, 0.7287164 , 0.30357146,\n          0.38947988, 0.18499596, 0.41832423, 0.43922585, 0.11860386,\n          0.39704788, 0.36714768, 0.504372  ],\n         [0.35879636, 0.33337402, 0.9090909 , 0.44555986, 0.40897435,\n          0.12222223, 0.01687764, 0.4347813 , 0.66398525, 0.28571427,\n          0.38875413, 0.18880485, 0.39601827, 0.43922585, 0.17475377,\n          0.39076865, 0.34553123, 0.48822892],\n         [0.36805558, 0.33337402, 1.        , 0.54285043, 0.43702435,\n          0.14444445, 0.01687764, 0.4429524 , 0.6581874 , 0.28571427,\n          0.4434067 , 0.2978257 , 0.45737135, 0.45374483, 0.31791314,\n          0.4583851 , 0.44488525, 0.48822892],\n         [0.41203701, 0.666687  , 0.        , 0.49533612, 0.28464818,\n          0.14444445, 0.01687764, 0.5287795 , 0.7782254 , 0.2589286 ,\n          0.5231676 , 0.07958345, 0.5021651 , 0.5801181 , 0.02924518,\n          0.5630332 , 0.4909358 , 0.6587075 ],\n         [0.42592597, 0.666687  , 0.09090909, 0.5336548 , 0.34568745,\n          0.17777778, 0.01265822, 0.4840567 , 0.6895318 , 0.2410714 ,\n          0.569304  , 0.09094588, 0.54967153, 0.63712186, 0.06721534,\n          0.6072968 , 0.5387666 , 0.70309675],\n         [0.4050926 , 0.666687  , 0.18181819, 0.56496716, 0.30994463,\n          0.27777776, 0.00843882, 0.5906794 , 0.8362694 , 0.22321427,\n          0.61288667, 0.10897304, 0.587695  , 0.6489778 , 0.08854641,\n          0.6461569 , 0.60234475, 0.70309675],\n         [0.4074074 , 0.666687  , 0.27272728, 0.37698543, 0.26502687,\n          0.45555553, 0.00843882, 0.6181233 , 0.8489523 , 0.22321427,\n          0.63565445, 0.10683896, 0.6283834 , 0.67280847, 0.18145236,\n          0.7299007 , 0.70176387, 0.7612127 ],\n         [0.4097222 , 0.666687  , 0.36363637, 0.38178146, 0.2676543 ,\n          0.54444444, 0.00421941, 0.6386466 , 0.85729647, 0.2053572 ,\n          0.71840847, 0.25840592, 0.72005665, 0.72583526, 0.11363742,\n          0.8318263 , 0.78637004, 0.85354924]],\n \n        [[0.2824074 , 0.33337402, 0.5454545 , 0.4434234 , 0.49684095,\n          0.1       , 0.01687764, 0.35478806, 0.5537133 , 0.59821427,\n          0.24199486, 0.14992893, 0.25160396, 0.3124879 , 0.1951356 ,\n          0.23755145, 0.24154449, 0.36252856],\n         [0.3078704 , 0.33337402, 0.6363636 , 0.4675647 , 0.5364528 ,\n          0.13333333, 0.02109705, 0.39829922, 0.6250224 , 0.4375    ,\n          0.28668964, 0.15176159, 0.2724793 , 0.33909148, 0.09702724,\n          0.2707826 , 0.19497132, 0.39650166],\n         [0.32175922, 0.33337402, 0.72727275, 0.50692934, 0.5127573 ,\n          0.14444445, 0.01687764, 0.44169307, 0.6902609 , 0.3928572 ,\n          0.37404346, 0.20862569, 0.3923962 , 0.4298702 , 0.19074494,\n          0.36871612, 0.3304355 , 0.4766276 ],\n         [0.3472222 , 0.33337402, 0.8181819 , 0.35866046, 0.33456182,\n          0.12222223, 0.01687764, 0.47107363, 0.7287164 , 0.30357146,\n          0.38947988, 0.18499596, 0.41832423, 0.43922585, 0.11860386,\n          0.39704788, 0.36714768, 0.504372  ],\n         [0.35879636, 0.33337402, 0.9090909 , 0.44555986, 0.40897435,\n          0.12222223, 0.01687764, 0.4347813 , 0.66398525, 0.28571427,\n          0.38875413, 0.18880485, 0.39601827, 0.43922585, 0.17475377,\n          0.39076865, 0.34553123, 0.48822892],\n         [0.36805558, 0.33337402, 1.        , 0.54285043, 0.43702435,\n          0.14444445, 0.01687764, 0.4429524 , 0.6581874 , 0.28571427,\n          0.4434067 , 0.2978257 , 0.45737135, 0.45374483, 0.31791314,\n          0.4583851 , 0.44488525, 0.48822892],\n         [0.41203701, 0.666687  , 0.        , 0.49533612, 0.28464818,\n          0.14444445, 0.01687764, 0.5287795 , 0.7782254 , 0.2589286 ,\n          0.5231676 , 0.07958345, 0.5021651 , 0.5801181 , 0.02924518,\n          0.5630332 , 0.4909358 , 0.6587075 ],\n         [0.42592597, 0.666687  , 0.09090909, 0.5336548 , 0.34568745,\n          0.17777778, 0.01265822, 0.4840567 , 0.6895318 , 0.2410714 ,\n          0.569304  , 0.09094588, 0.54967153, 0.63712186, 0.06721534,\n          0.6072968 , 0.5387666 , 0.70309675],\n         [0.4050926 , 0.666687  , 0.18181819, 0.56496716, 0.30994463,\n          0.27777776, 0.00843882, 0.5906794 , 0.8362694 , 0.22321427,\n          0.61288667, 0.10897304, 0.587695  , 0.6489778 , 0.08854641,\n          0.6461569 , 0.60234475, 0.70309675],\n         [0.4074074 , 0.666687  , 0.27272728, 0.37698543, 0.26502687,\n          0.45555553, 0.00843882, 0.6181233 , 0.8489523 , 0.22321427,\n          0.63565445, 0.10683896, 0.6283834 , 0.67280847, 0.18145236,\n          0.7299007 , 0.70176387, 0.7612127 ],\n         [0.4097222 , 0.666687  , 0.36363637, 0.38178146, 0.2676543 ,\n          0.54444444, 0.00421941, 0.6386466 , 0.85729647, 0.2053572 ,\n          0.71840847, 0.25840592, 0.72005665, 0.72583526, 0.11363742,\n          0.8318263 , 0.78637004, 0.85354924],\n         [0.41898143, 0.666687  , 0.45454547, 0.5232415 , 0.29174894,\n          0.5888889 , 0.01265822, 0.6660156 , 0.8725085 , 0.21428573,\n          0.7617185 , 0.02667331, 0.73016655, 0.8022534 , 0.0297526 ,\n          0.88052046, 0.83380556, 0.9256201 ]]], dtype=float32),\n 'test_y': array([[0.9976852],\n        [1.       ]], dtype=float32),\n 'asarray': <function numpy.asarray>,\n 'train_test_split': <function sklearn.model_selection._split.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)>,\n 'mean_absolute_error': <function sklearn.metrics._regression.mean_absolute_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')>,\n 'Adam': keras.optimizers.optimizer_v2.adam.Adam,\n 'tf': <module 'tensorflow' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/__init__.py'>,\n 'math': <module 'math' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/lib-dynload/math.cpython-39-darwin.so'>,\n 'np': <module 'numpy' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/__init__.py'>,\n 'fit_model': <function __main__.fit_model(X_train, y_train)>,\n 'fit_ensemble': <function __main__.fit_ensemble(n_members, X_train, X_test, y_train, y_test)>,\n 'n_members': 20,\n 'ensemble': [<keras.engine.sequential.Sequential at 0x2d95b1dc0>,\n  <keras.engine.sequential.Sequential at 0x35173fc40>,\n  <keras.engine.sequential.Sequential at 0x133ed6ca0>,\n  <keras.engine.sequential.Sequential at 0x2f99a8340>,\n  <keras.engine.sequential.Sequential at 0x2ccf7a7f0>,\n  <keras.engine.sequential.Sequential at 0x2b2f69520>,\n  <keras.engine.sequential.Sequential at 0x2aa765070>,\n  <keras.engine.sequential.Sequential at 0x2ab7c6d30>,\n  <keras.engine.sequential.Sequential at 0x15036f640>,\n  <keras.engine.sequential.Sequential at 0x15c63cd60>,\n  <keras.engine.sequential.Sequential at 0x2c1100e20>,\n  <keras.engine.sequential.Sequential at 0x2e40130d0>,\n  <keras.engine.sequential.Sequential at 0x157ebd550>,\n  <keras.engine.sequential.Sequential at 0x2e2f1be80>,\n  <keras.engine.sequential.Sequential at 0x14ff17940>,\n  <keras.engine.sequential.Sequential at 0x2a2a67fa0>,\n  <keras.engine.sequential.Sequential at 0x353edea90>,\n  <keras.engine.sequential.Sequential at 0x2c6cb6e50>,\n  <keras.engine.sequential.Sequential at 0x2bda57cd0>,\n  <keras.engine.sequential.Sequential at 0x15c67ac10>],\n 'i': 19,\n 'model': <keras.engine.sequential.Sequential at 0x15c67ac10>,\n 'yhat': array([[0.99555445],\n        [1.0358776 ]], dtype=float32),\n 'mae': 0.019004166,\n 'predict_with_pi': <function __main__.predict_with_pi(ensemble, X, n_members)>,\n 'newX': array([[[0.2708333 , 0.33337402, 0.45454547, 0.50973326, 0.48805773,\n          0.05555556, 0.01265822, 0.31022882, 0.5061407 , 0.66964287,\n          0.15689254, 0.17815025, 0.16707897, 0.21934932, 0.16272569,\n          0.11384857, 0.07516241, 0.27325606],\n         [0.2824074 , 0.33337402, 0.5454545 , 0.4434234 , 0.49684095,\n          0.1       , 0.01687764, 0.35478806, 0.5537133 , 0.59821427,\n          0.24199486, 0.14992893, 0.25160396, 0.3124879 , 0.1951356 ,\n          0.23755145, 0.24154449, 0.36252856],\n         [0.3078704 , 0.33337402, 0.6363636 , 0.4675647 , 0.5364528 ,\n          0.13333333, 0.02109705, 0.39829922, 0.6250224 , 0.4375    ,\n          0.28668964, 0.15176159, 0.2724793 , 0.33909148, 0.09702724,\n          0.2707826 , 0.19497132, 0.39650166],\n         [0.32175922, 0.33337402, 0.72727275, 0.50692934, 0.5127573 ,\n          0.14444445, 0.01687764, 0.44169307, 0.6902609 , 0.3928572 ,\n          0.37404346, 0.20862569, 0.3923962 , 0.4298702 , 0.19074494,\n          0.36871612, 0.3304355 , 0.4766276 ],\n         [0.3472222 , 0.33337402, 0.8181819 , 0.35866046, 0.33456182,\n          0.12222223, 0.01687764, 0.47107363, 0.7287164 , 0.30357146,\n          0.38947988, 0.18499596, 0.41832423, 0.43922585, 0.11860386,\n          0.39704788, 0.36714768, 0.504372  ],\n         [0.35879636, 0.33337402, 0.9090909 , 0.44555986, 0.40897435,\n          0.12222223, 0.01687764, 0.4347813 , 0.66398525, 0.28571427,\n          0.38875413, 0.18880485, 0.39601827, 0.43922585, 0.17475377,\n          0.39076865, 0.34553123, 0.48822892],\n         [0.36805558, 0.33337402, 1.        , 0.54285043, 0.43702435,\n          0.14444445, 0.01687764, 0.4429524 , 0.6581874 , 0.28571427,\n          0.4434067 , 0.2978257 , 0.45737135, 0.45374483, 0.31791314,\n          0.4583851 , 0.44488525, 0.48822892],\n         [0.41203701, 0.666687  , 0.        , 0.49533612, 0.28464818,\n          0.14444445, 0.01687764, 0.5287795 , 0.7782254 , 0.2589286 ,\n          0.5231676 , 0.07958345, 0.5021651 , 0.5801181 , 0.02924518,\n          0.5630332 , 0.4909358 , 0.6587075 ],\n         [0.42592597, 0.666687  , 0.09090909, 0.5336548 , 0.34568745,\n          0.17777778, 0.01265822, 0.4840567 , 0.6895318 , 0.2410714 ,\n          0.569304  , 0.09094588, 0.54967153, 0.63712186, 0.06721534,\n          0.6072968 , 0.5387666 , 0.70309675],\n         [0.4050926 , 0.666687  , 0.18181819, 0.56496716, 0.30994463,\n          0.27777776, 0.00843882, 0.5906794 , 0.8362694 , 0.22321427,\n          0.61288667, 0.10897304, 0.587695  , 0.6489778 , 0.08854641,\n          0.6461569 , 0.60234475, 0.70309675],\n         [0.4074074 , 0.666687  , 0.27272728, 0.37698543, 0.26502687,\n          0.45555553, 0.00843882, 0.6181233 , 0.8489523 , 0.22321427,\n          0.63565445, 0.10683896, 0.6283834 , 0.67280847, 0.18145236,\n          0.7299007 , 0.70176387, 0.7612127 ],\n         [0.4097222 , 0.666687  , 0.36363637, 0.38178146, 0.2676543 ,\n          0.54444444, 0.00421941, 0.6386466 , 0.85729647, 0.2053572 ,\n          0.71840847, 0.25840592, 0.72005665, 0.72583526, 0.11363742,\n          0.8318263 , 0.78637004, 0.85354924]]], dtype=float32),\n 'lower': 739.5473201098606,\n 'mean': 744.6314,\n 'upper': 749.7154972729519,\n 'outcome': {'Prediction': [744.6314],\n  '95%CI.Min': [739.5473201098606],\n  '95%CI.Max': [749.7154972729519]},\n 'outcome1':    Prediction   95%CI.Min   95%CI.Max\n 0  656.793579  653.470549  660.116609,\n '_2':    Prediction   95%CI.Min   95%CI.Max\n 0  656.793579  653.470549  660.116609,\n '_i3': \"from os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '1',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '1','model_corr.h5'))\",\n 'path': <module 'posixpath' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/posixpath.py'>,\n 'i_model': <keras.engine.sequential.Sequential at 0x15c67ac10>,\n '_i4': \"from math import sqrt\\nimport numpy as np\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1))* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+4):-n_features*(1+4)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+4):-n_features*(1+4)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1) , n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome2= pd.DataFrame(outcome)\\noutcome2\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '2',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '2','model_corr.h5'))\",\n 'outcome2':    Prediction   95%CI.Min   95%CI.Max\n 0  651.924194  648.253465  655.594924,\n '_i5': \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+3):-n_features*(1+3)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+3):-n_features*(1+3)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome3= pd.DataFrame(outcome)\\noutcome3\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '3',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '3','model_corr.h5'))\",\n 'outcome3':    Prediction   95%CI.Min   95%CI.Max\n 0  673.428772  670.377063  676.480481,\n '_i6': \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n# #\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+2):-n_features*(1+2)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+2):-n_features*(1+2)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome4= pd.DataFrame(outcome)\\noutcome4\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '4',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '4','model_corr.h5'))\",\n 'outcome4':    Prediction   95%CI.Min   95%CI.Max\n 0  697.759155  693.907809  701.610501,\n '_i7': \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\nm=6-5\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome5= pd.DataFrame(outcome)\\noutcome5\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '5',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '5','model_corr.h5'))\",\n 'm': 0,\n 'outcome5':    Prediction   95%CI.Min   95%CI.Max\n 0  718.015015  714.183098  721.846931,\n '_i8': \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='BYX'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# encoder = LabelEncoder()\\n# # # print(values[:,0]) #PortQyt Value\\n# values[:,0]=encoder.fit_transform(values[:,0])\\n# print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\nn_months = 5\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\n\\n\\nm=6-6\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months = 36\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = (n_months+1)* n_features #the following fourth month\\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1), n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome6= pd.DataFrame(outcome)\\noutcome6\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '6',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '6','model_corr.h5'))\",\n 'outcome6':    Prediction   95%CI.Min   95%CI.Max\n 0  727.055725  723.884459  730.226991,\n '_i9': \"from math import sqrt\\nfrom numpy import concatenate\\nfrom matplotlib import pyplot\\nimport pandas as pd\\nfrom pandas import read_csv\\nfrom pandas import DataFrame\\nfrom pandas import concat\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.metrics import mean_squared_error\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import LSTM\\n\\nimport io\\nimport datetime\\n\\n# sheet='OPT_BZX BATS'\\ndf= pd.read_excel(r'../Logical Ports Prediction.xlsx',sheet_name=sheet,header=0)\\n# df= pd.read_excel(r'Logical Ports Prediction.xlsx',sheet_name='C2',header=0)\\ndf.dropna(subset=['Date'],inplace=True)\\n\\nfrom datetime import datetime as dt\\nlast_date=df.loc[:,'Date']\\nlast_date=last_date.iat[-1]\\nlast_date=last_date.strftime('%Y-%m-%d')\\nlast_date\\n\\ndf=df[df['Date']<=last_date].reset_index(drop=True)\\ndf.tail()\\ndf['Year'] = pd.to_datetime(df['Date']).dt.strftime('%Y')\\ndf['Month'] = pd.to_datetime(df['Date']).dt.strftime('%m')\\n\\ndf.drop(['Date','Logical Ports','Asset'],axis=1,inplace=True)\\nfirst_column = df.pop('Year')\\ndf.insert(0, 'Year', first_column)\\nsecond_column = df.pop('Month')\\ndf.insert(1, 'Month', second_column)\\nfirst_column = df.pop('PortQyt')\\ndf.insert(0, 'PortQyt', first_column)\\n\\ndf.shape\\nprint(len(list(df)[:]))\\n# # df=df.drop(['D&J_Close30d_Avg.','D&J_Close30d_Min','Monthly Real GDP Index','TCV','FEDFUNDS','Unemployement Rate','SPX_Price30d_Std.','D&J_Close30d_Std.','VIX_Close30d_Max.','VIX_Close30d_Avg.','VIX_Close30d_Std.','VIX_Close30d_Min.'],axis=1)\\n\\n\\nvalues=df.values\\n#\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # encoder = LabelEncoder()\\n# # # # print(values[:,0]) #PortQyt Value\\n# # values[:,0]=encoder.fit_transform(values[:,0])\\n# # print(values[:,0])\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(values[:,0])\\n# pp.show()\\n\\n# # print(values[:,4].shape)\\n# # print(values[:,4])\\nvalues = values.astype('float32')\\n\\n# specify the number of lag hours\\n# n_months = 11\\nn_months = 23\\nn_features = len(list(df)[:])\\n\\n#Normalize the first feature\\nfrom sklearn.preprocessing import StandardScaler\\nscaler2 = MinMaxScaler(feature_range=(0, 1)).fit(values[:,0:1])\\n# train_y = scaler2.transform(values[:,-n_features])\\n# scaled2 = scaler2.fit_transform(values) #try\\n\\n\\n# # normalize features\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled = scaler.fit_transform(values)\\n\\n\\n# len(list(dataset.columns))-3\\n\\n# convert series to supervised learning\\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\\n\\tn_vars = 1 if type(data) is list else data.shape[1]\\n\\tdf = DataFrame(data)\\n\\tcols, names = list(), list()\\n\\t# input sequence (t-n, ... t-1)\\n\\tfor i in range(n_in, 0, -1):\\n\\t\\tcols.append(df.shift(i))\\n\\t\\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# forecast sequence (t, t+1, ... t+n)\\n\\tfor i in range(0, n_out):\\n\\t\\tcols.append(df.shift(-i))\\n\\t\\tif i == 0:\\n\\t\\t\\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\\n\\t\\telse:\\n\\t\\t\\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\\n\\t# put it all together\\n\\tagg = concat(cols, axis=1)\\n\\tagg.columns = names\\n\\t# drop rows with NaN values\\n\\tif dropnan:\\n\\t\\tagg.dropna(inplace=True)\\n\\treturn agg\\n\\n# frame as supervised learning\\nreframed = series_to_supervised(scaled, n_months, 1)\\n# print(reframed.shape)\\n\\n\\n# print(reframed.tail())\\n\\n\\n\\nm=6-6\\n# split into train and test sets\\nvalues = reframed.values\\nn_train_months =17\\ntrain = values[:n_train_months, :]\\ntest = values[n_train_months:, :]\\nprint(values.shape)\\n# split into input and outputs\\nn_obs = ((n_months+1)//2)* n_features #the following 12\\n# n_obs = (n_months+1)* n_features #the following \\ntrain.shape\\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntrain_X, train_y = train[:, :n_obs], train[:, -n_features*(1+m):-n_features*(1+m)+1] \\ntest_X, test_y = test[:, :n_obs], test[:, -n_features*(1+m):-n_features*(1+m)+1]\\nprint(test.shape)\\n\\n\\n# import matplotlib.pyplot as pp\\n# pp.plot(train_y)\\n# pp.show()\\n\\ntrain_X = train_X.reshape((train_X.shape[0], (n_months+1)//2, n_features))\\n# train_X = train_X.reshape((train_X.shape[0], (n_months+1), n_features))\\ntest_X = test_X.reshape((test_X.shape[0], (n_months+1)//2, n_features))\\nprint(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\\n\\n# prediction interval for mlps on the housing regression dataset\\nfrom numpy import asarray\\nfrom pandas import read_csv\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nimport tensorflow as tf\\nimport math\\nimport numpy as np\\n\\n \\n# define and fit the model\\ndef fit_model(X_train, y_train):\\n    features = X_train.shape[1]\\n    model = Sequential()\\n    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\\n    model.add(Dense(1))\\n    model.compile(loss='mse', optimizer='adam')\\n    model.fit(X_train, y_train, verbose=0, epochs=50, batch_size=16)\\n    return model\\n\\n\\t\\n \\n# fit an ensemble of models\\ndef fit_ensemble(n_members, X_train, X_test, y_train, y_test):\\n    ensemble = list()\\n    for i in range(n_members):\\n        model = fit_model(X_train, y_train) # define and fit the model on the training set\\n        yhat = model.predict(X_test, verbose=0) # evaluate model on the test set\\n        print(y_test.shape,yhat.shape)\\n        mae = mean_absolute_error(y_test, yhat)\\n        print('>%d, MAE: %.3f' % (i+1, mae))\\n        ensemble.append(model) # store the model\\n    return ensemble\\n\\nn_members = 20\\nensemble = list()\\nfor i in range(n_members):\\n  model = fit_model(train_X, train_y) # define and fit the model on the training set\\n  yhat = model.predict(test_X, verbose=0) # evaluate model on the test set\\n  print(test_y,yhat.shape)\\n  mae = mean_absolute_error(test_y, yhat)\\n  print('>%d, MAE: %.3f' % (i+1, mae))\\n  ensemble.append(model) # store the model\\n    \\n# make predictions with the ensemble and calculate a prediction interval\\ndef predict_with_pi(ensemble, X,n_members):\\n    yhat = [model.predict(X, verbose=0) for model in ensemble]\\n    yhat = asarray(yhat)\\n    yhat = np.reshape(yhat,[n_members,1])\\n    print(yhat.shape)\\n    # yhat = scaled2.inverse_transform(yhat)\\n    yhat = scaler2.inverse_transform(yhat) # invert scaling for actual\\n    yhat = yhat[:,0] \\n    interval = 1.96 * yhat.std()/math.sqrt(len(yhat))\\n    lower, upper = yhat.mean() - interval, yhat.mean() + interval\\n    return lower, yhat.mean(), upper\\n\\nn_members=len(ensemble)\\n# make predictions with prediction interval\\nnewX = asarray([test_X[0, :]])\\nlower, mean, upper = predict_with_pi(ensemble, newX,n_members)\\n# print(test_y)\\n# print('Point prediction: %.1f' % mean)\\nprint('95%% prediction interval: [%.1f, %.1f]' % (lower, upper))\\nprint('True value: %.1f' % test_y[0])\\noutcome = {'Prediction': [mean],\\n           '95%CI.Min': [lower],\\n           '95%CI.Max': [upper]\\n           }\\n\\n\\noutcome12= pd.DataFrame(outcome)\\noutcome12\\n\\nfrom os import path\\n#save ensemble\\nfor i,i_model in enumerate(ensemble):\\n    i_model.save(path.join(sheet, '12',f'ensemble_corr_{i}.h5'))\\n#   i_model.save(f'BYX/1/ensemble_corr_{i}.h5')\\n\\n\\n\\n#save model\\n# model.save(f'/1/model_corr.h5')\\nmodel.save(path.join(sheet, '12','model_corr.h5'))\",\n 'outcome12':    Prediction  95%CI.Min   95%CI.Max\n 0  744.631409  739.54732  749.715497,\n '_i10': '#Concatenate all dataframes by identical columns\\n\\ndf=pd.concat([outcome1, outcome2,outcome3,outcome4,outcome5,outcome6,outcome12])\\n# df=pd.concat([outcome6,outcome12])\\n\\ninsert_index = 0\\ninsert_colname = \\'Asset\\'\\ninsert_values = [\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\',\\'Options\\'] # this can be a numpy array too\\n# insert_values = [\\'Options\\',\\'Options\\'] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\n\\ninsert_index = 1\\ninsert_colname = \\'Product\\'\\ninsert_values = [sheet,sheet,sheet,sheet,sheet,sheet,sheet] # this can be a numpy array too\\n# insert_values = [sheet,sheet] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\ninsert_index = 2\\ninsert_colname = \\'Month Ahead\\'\\ninsert_values = [\\'1\\',\\'2\\',\\'3\\',\\'4\\',\\'5\\',\\'6\\',\\'12\\'] # this can be a numpy array too\\n# insert_values = [\\'6\\',\\'12\\'] # this can be a numpy array too\\ndf.insert(loc=insert_index, column=insert_colname, value=insert_values)\\n\\nglobals()[sheet] = df\\n\\nimport matplotlib.pyplot as mp\\ndf.plot(title=sheet,x=\\'Month Ahead\\',y=[\"Prediction\",\"95%CI.Min\",\"95%CI.Max\"],kind=\"line\",figsize=(10,10))\\nmp.show()',\n 'insert_index': 2,\n 'insert_colname': 'Month Ahead',\n 'insert_values': ['1', '2', '3', '4', '5', '6', '12'],\n 'EXO_EDGX_Options':      Asset           Product Month Ahead  Prediction   95%CI.Min   95%CI.Max\n 0  Options  EXO_EDGX_Options           1  656.793579  653.470549  660.116609\n 0  Options  EXO_EDGX_Options           2  651.924194  648.253465  655.594924\n 0  Options  EXO_EDGX_Options           3  673.428772  670.377063  676.480481\n 0  Options  EXO_EDGX_Options           4  697.759155  693.907809  701.610501\n 0  Options  EXO_EDGX_Options           5  718.015015  714.183098  721.846931\n 0  Options  EXO_EDGX_Options           6  727.055725  723.884459  730.226991\n 0  Options  EXO_EDGX_Options          12  744.631409  739.547320  749.715497,\n 'mp': <module 'matplotlib.pyplot' from '/Users/issacsmacbookpro/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/matplotlib/pyplot.py'>,\n '_i11': 'globals()'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMPKlAUyfdXJ6MI50xs5ME3",
   "name": "C2_1m_Corr_Train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}